{"Job_ID":"85848016","Role":"Senior Data engineer","Company":"Flintex Consulting Pte Ltd","Location":"City Hall","Publish_Time":"2025-07-17 22:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85848016","country":"singapore","job_desc":"Benefits: 13th Month Salary; Responsibilities; Integrate data from multiple sources, such as databases, APIs, or streaming platforms, to provide a unified view of the data; Implement data quality checks and validation processes to ensure the accuracy, completeness, and consistency of data; Identify and resolve data quality issues, monitor data pipelines for errors, and implement data governance and data quality frameworks; Enforce data security and compliance with relevant regulations and industry-specific standards; Implement data access controls, encryption mechanisms, and monitor data privacy and security risks; Optimise data processing and query performance by tuning database configurations, implementing indexing strategies, and leveraging distributed computing frameworks; Optimize data structures for efficient querying and develop data dictionaries and metadata repositories; Identify and resolve performance bottlenecks in data pipelines and systems; Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders; Document data pipelines, data schemas, and system configurations, making it easier for others to understand and work with the data infrastructure; Monitor data pipelines, databases, and data infrastructure for errors, performance issues, and system failures; Set up monitoring tools, alerts, and logging mechanisms to proactively identify and resolve issues to ensure the availability and reliability of data; It would be a plus if he has software engineering background; Requirements; Bachelor's or master's degree in computer science, information technology, data engineering, or a related field; Strong knowledge of databases, data structures, algorithms; Proficiency in working with data engineering tools and technologies including knowledge of data integration tools (e.g., Apache Kafka, Azure IoTHub, Azure EventHub), ETL\/ELT frameworks (e.g., Apache Spark, Azure Synapse), big data platforms (e.g., Apache Hadoop), and cloud platforms (e.g., Amazon Web Services, Google Cloud Platform, Microsoft Azure); Expertise in working with relational databases (e.g., MySQL, PostgreSQL, Azure SQL, Azure Data Explorer) and data warehousing concepts.; Familiarity with data modeling, schema design, indexing, and optimization techniques is valuable for building efficient and scalable data systems; Proficiency in languages such as Python, SQL, KQL, Java, and Scala; Experience with scripting languages like Bash or PowerShell for automation and system administration tasks; Strong knowledge of data processing frameworks like Apache Spark, Apache Flink, or Apache Beam for efficiently handling large-scale data processing and transformation tasks; Understanding of data serialization formats (e.g., JSON, Avro, Parquet) and data serialization libraries (e.g., Apache Avro, Apache Parquet) is valuable; Having experience in CI\/CD and GitHub that demonstrates ability to work in a collaborative and iterative development environment; Having experience in visualization tools (e.g. Power BI, Plotly, Grafana, Redash) is beneficial; Preferred Skills & Characteristics; Consistently display dynamic independent work habits, goal oriented, passionate in growth mindsets and self-motivated professional. Self-driven and proactive in keeping up with new technologies and programming","salary":"$6,000 \u2013 $9,000 per month (SGD)","work_type":"Full time"}
{"Job_ID":"85845116","Role":"Data Engineer & Reporting Developer","Company":"ALMR CONSULTING PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-17 20:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85845116","country":"singapore","job_desc":"Job Description; We are looking for a skilled Data Engineer & Reporting Developer with 3 to 10 years of experience in big data engineering and analytics. The ideal candidate will have a strong background in Python, PySpark, ETL, and reporting tools. You will be responsible for designing and building data pipelines, improving data collection, and delivering analytical solutions for business users.; Key Responsibilities; Analyse data needs and document business requirements.; Refine and migrate data collection to more efficient sources.; Plan, design, and implement data engineering jobs and reporting solutions.; Develop test plans, execute system testing, and support UAT.; Work closely with technical teams for deployment and adoption.; Ensure smooth operations and service levels.; Provide support for production issues.; Requirements; Degree in Computer Science, Information Systems, or related field preferred.; 3\u201310 years of experience in big data engineering.; Experience in Cloudera Data Platform is a plus.; Proficient in Python, PySpark, Linux, and ETL tools like Informatica.; Strong SQL and data analysis skills.; Experience with data virtualisation tools (e.g., Denodo) is a bonus.; Hands-on with reporting tools like SAP BO, Tableau.; Familiarity with Agile and Waterfall methodologies.; Strong communication and stakeholder management skills.; Self-driven, collaborative team player.","salary":"","work_type":"Kontrak\/Temporer"}
{"Job_ID":"85871904","Role":"Financial Data Engineer","Company":"BICHEER TECHNOLOGY PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-18 02:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85871904","country":"singapore","job_desc":"Key Responsibilities:; Design, develop, and maintain high-performance data processing platforms to support the ingestion, storage, and analysis of high-frequency real-time financial data.; Build scalable and resilient data architectures to ensure system stability and high availability under large-scale data loads.; Manage and integrate data from multiple sources, including fundamental financial data, factor data, and unstructured data (e.g., text, images).; Support the quantitative research team by fulfilling data needs and assisting in the development of data-driven quantitative models and strategies.; Leverage AI and machine learning techniques to optimize data workflows and enhance data quality and processing efficiency.; Monitor and tune data pipelines to resolve bottlenecks and ensure smooth data processing operations.; Stay up to date with the latest technologies in data engineering and AI, and drive innovation within the team.; Requirements:; Bachelor's degree or above in Computer Science, Data Engineering, Software Engineering, or a related field.; Minimum of 5 years of experience in data engineering or a related domain, preferably with a background in the financial industry.; Proficient in Python, Scala, or Java, and experienced with data processing and analytics libraries (e.g., Pandas, NumPy, PySpark).; Familiarity with streaming data technologies (e.g., Kafka, Flink, Spark Streaming), with the ability to handle high-frequency real-time data.; Experience in building and maintaining data warehouses and data lakes.; Knowledge of cloud platforms and their big data ecosystems (e.g., AWS, Azure, GCP).; Experience with deploying AI\/ML models and optimizing data workflows is a strong plus.; Strong system design skills, with a solid understanding of distributed systems and microservices architecture.; Excellent problem-solving abilities and strong team collaboration skills.; Preferred Qualifications:; Experience developing quantitative trading platforms or high-frequency trading systems.; Familiarity with factor analysis and the development process of quantitative models.; Experience working with unstructured data (e.g., NLP, image processing).; Understanding of deep learning frameworks (e.g., TensorFlow, PyTorch) and their applications in financial data processing.","salary":"","work_type":"Full time"}
{"Job_ID":"85866721","Role":"Software Integration Engineer - AWS (Services Planning)","Company":"Synapxe","Location":"One North","Publish_Time":"2025-07-18 08:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85866721","country":"singapore","job_desc":"Position Overview; We are seeking a highly skilled and motivated software integration engineer - AWS to join our team. The ideal candidate will have a strong background in cloud computing and application development, with a focus on designing, developing, and deploying cloud-based applications. The potential candidate will work closely with cross-functional teams, include the operational and data teams, partners and vendors to ensure the successful implementation and maintenance of cloud solutions. This is a year two year direct contract with Synapxe. ; Role & Responsibilities; Design, develop, deploy cloud-based and integrate non-cloud-based applications using industry best practices and cloud technologies; Collaborate with software engineers, architects, and other stakeholders to gather requirements and define application specifications; Implement security measures to protect cloud-based applications and data; Troubleshoot and resolve issues related to cloud infrastructure and applications; Optimize cloud-based applications for performance, scalability, and cost-efficiency; Provide technical guidance and support to team members and stakeholders; Assist in managing and monitoring of cloud-based assets hosted on Singapore GCC platforms; Requirements; Bachelor's degree in Computer Science, Engineering, or a related field; More than 6 years experience in coding with cloud technologies environment; At least 3 years of experience in working as AWS cloud developer; Strong experience in cloud computing platforms such as AWS, Azure, or Google Cloud; Experience with Singapore GCC hosting platform will be of advantage but not essential; Experience with containerization technologies such as Docker and Kubernetes; Familiarity with CI\/CD pipelines and automation tools; Experience with Apache Hadoop and Apache Spark; Proficiency in programming languages such as Java, Python, JavaScript and\/or C#; Knowledge of cloud security best practices and compliance standards; Experience working with version control and repository tools like Git, Maven; Strong background working with Linux\/UNIX environments; Working knowledge with SQL and NoSQL databases preferred; Strong collaboration and communication skills within project teams; Excellent problem-solving and troubleshooting skills; Apply Now; NOTE: It only takes a few minutes to apply for a meaningful career in HealthTech - GO FOR IT!!; #LI-SYNX34","salary":"","work_type":"Full time"}
{"Job_ID":"85837188","Role":"Core Engineering, SDLC \u2013 Developer Collaboration Software Engineer,...","Company":"Goldman Sachs Bank AG","Location":"Singapore","Publish_Time":"2025-07-17 20:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85837188","country":"singapore","job_desc":"Core Engineering, SDLC \u2013 Developer Collaboration Software Engineer, Associate\/ Vice President, Singapore location_on Singapore; OVERVIEW:; At Goldman Sachs, our Engineers don\u2019t just build things \u2013 we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.; Engineering, which is comprised of our Technology Division and Global Strategist groups, is at the center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions.; CORE ENGINEERING \u2013 DEVELOPER COLLABORATION; The Developer Collaboration team owns the Atlassian toolset, focusing on JIRA and Confluence at Goldman Sachs. Our teampartners withinternal stakeholders across business units andfunctional groupsgloballyto drive strategic engineering and collaboration initiatives that deliver end user outcomes, while creating andmaintainingan outstanding customer experience, at scale.; SDLC @ GS:; The SDLC organization is the base and platform on which all technology solutions across the firm are managed. You will be working in the heart of developer experience, ensuring code that is written by thousands of GS engineers is versioned securely, reviewed expertly, compiles fast, is comprehensively tested, compliant, and distributed widely. We empower thousands of developers and all teams across the firm to innovate better, faster, more securely, and in a fully compliant manner, all while striving to create an easy to use, stable, performant, and frictionless ecosystem.; RESPONSIBILITIES:; Own, manage and automate infrastructure and deployments across a variety of environments, including development, testing and production.; Own, implement and maintain continuous integration and delivery pipelines.; Design, configure and manage observability for our systems to ensure application availability and performance.; Own relationships with senior stakeholders and our client development teams to ensure that their needs are met as well as those of the firm.; Implement and maintain security controls and compliance requirements.; Ensure that production issues are addressed in a timely manner, including post mortem and longer term steps to avoid repetition.; Stay current with emerging technologies and tools in the DevOps space.; Advocate for improvements to product quality, security, reliability, and performance.; Develop custom integrations and interfaces between external tooling and Jira\/Confluence infrastructure as needed.; SKILLS AND EXPERIENCE WE ARE LOOKING FOR:; 3+ years (Associate) \/ 8+ years (VP) of experience in a software development, DevOps or related role.; Professional experience with CI \/CD tools such as GitLab, Jenkins, CircleCI or Bitbucket.; Professional experience with cloud deployment patterns. Specifically AWS cloud constructs, Terraform, Docker, Kubernetes, and Kafka.; General knowledge of multiple languages and expert in-depth knowledge of at least one of: Golang, Java, Python, C, C++.; Strong software engineering and system design fundamentals.; Experience with all stages of SDLC.; Experience with SRE principles, as well as diagnosis, prevention, performance management, and availability of large distributed systems.; Strong written and verbal communication.; Excellent problem-solving and analytical skills.; Ability to work collaboratively in a team environment.; PREFERRED QUALIFICATIONS:; BSc, MSc, PhD in relevant field (Computer Science, Information Systems, or similar).; Experience with Prometheus and Grafana, as well as knowledgeable about networking protocols (TCP, UDP, ICMP, ARP, DNS, TLS, HTTP, SSH, etc.); Experience with the use of ML and\/or agentic AI, especially in relation to facilitating the SDLC.; Experience in stakeholder management.; ABOUT GOLDMAN SACHS; At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.; We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com\/careers.; We\u2019re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https:\/\/www.goldmansachs.com\/careers\/footer\/disability-statement.html; Goldman Sachs is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, national origin, age, veterans status, disability, or any other characteristic protected by applicable law.; Healthcare & Medical Insurance; We offer a wide range of health and welfare programs that vary depending on office location. These generally include medical, dental, short-term disability, long-term disability, life, accidental death, labor accident and business travel accident insurance.; We offer competitive vacation policies based on employee level and office location. We promote time off from work to recharge by providing generous vacation entitlements and a minimum of three weeks expected vacation usage each year.; Financial Wellness & Retirement; We assist employees in saving and planning for retirement, offer financial support for higher education, and provide a number of benefits to help employees prepare for the unexpected. We offer live financial education and content on a variety of topics to address the spectrum of employees\u2019 priorities.; Health Services; We offer a medical advocacy service for employees and family members facing critical health situations, and counseling and referral services through the Employee Assistance Program (EAP). We provide Global Medical, Security and Travel Assistance and a Workplace Ergonomics Program. We also offer state-of-the-art on-site health centers in certain offices.; Fitness; To encourage employees to live a healthy and active lifestyle, some of our offices feature on-site fitness centers. For eligible employees we typically reimburse fees paid for a fitness club membership or activity (up to a pre-approved amount).; Child Care & Family Care; We offer on-site child care centers that provide full-time and emergency back-up care, as well as mother and baby rooms and homework rooms. In every office, we provide advice and counseling services, expectant parent resources and transitional programs for parents returning from parental leave. Adoption, surrogacy, egg donation and egg retrieval stipends are also available.; Benefits at Goldman Sachs; Read more about the full suite of class-leading benefits our firm has to offer.; #J-18808-Ljbffr","salary":"","work_type":"Full time"}
{"Job_ID":"85871664","Role":"Lead Big Data Engineer","Company":"The Great Eastern Life Assurance Company Limited","Location":"Central Region","Publish_Time":"2025-07-18 03:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85871664","country":"singapore","job_desc":"We are seeking a skilled and detail-oriented Data Engineer to design, develop, and maintain robust data pipelines and ETL solutions. This role involves working closely with cross-functional teams to ensure data quality, scalability, and alignment with business and technical requirements.; Design, develop, test, and maintain scalable ETL pipelines to meet business, technical, and user requirements.; Collect, refine, and integrate new datasets. Maintain comprehensive documentation and data mappings across multiple systems.; Create optimized and scalable data models that align with organizational data architecture standards and best practices.; Conduct code reviews and perform rigorous testing to ensure high-quality deliverables.; Drive continuous improvement in data quality through optimization, testing, and solution design reviews.; Ensure all solutions conform to big data architecture guidelines and long-term roadmap.; Implement robust monitoring, logging, and alerting systems to ensure pipeline reliability and data accuracy.; Apply best practices in data engineering to design and build reliable data marts within the Hadoop ecosystem for planning, reporting, and analytics.; Maintain and optimize data pipelines to ensure data accuracy, integrity, and timeliness.; Manage code in a centralized repository with clear branching strategies and well-documented commit messages.; Coordinate with stakeholders to ensure smooth production deployment and adherence to data governance policies.; Proactively identify and implement improvements to data engineering processes and workflows.; Architect end-to-end solutions for insurance data modeling in the data warehouse, including data acquisition, contextualization, and integration with business processes.; Act as a business process owner for onboarding users and data products onto the data platform and pipelines supporting dashboards and statistical models.; Ensure adherence to development standards and perform periodic reviews to maintain pipeline performance and sustainability.; Coordinate and conduct testing with stakeholders to ensure effective deployment of data pipelines and dashboards.; Monitor data pipelines continuously and collaborate with stakeholders to troubleshoot and optimize performance.; We are looking for people who; Diploma with at least 10 years\u2019 working experience, preferably in Life Insurance; Proven experience in data engineering, ETL development, and big data technologies; A strong team player who is meticulous, detail-oriented, and capable of performing under pressure; Proficiency in tools and platforms such as Hadoop, Spark, Hive, and cloud data services (e.g., AWS, Azure, GCP).; Possesses strong problem-solving and interpersonal skills.; Committed, dependable, and adaptable with the flexibility to support during peak periods and tight deadlines; Demonstrate high integrity, accountability, and a collaborative mindset; How you succeed; Champion and embody our Core Values in everyday tasks and interactions.; Demonstrate high level of integrity and accountability.; Take initiative to drive improvements and embrace change.; Take accountability of business and regulatory compliance risks, implementing measures to mitigate them effectively.; Keep abreast with industry trends, regulatory compliance, and emerging threats and technologies to understand and highlight potential concerns\/ risks to safeguard our company proactively.; Who we are; Founded in 1908, Great Eastern is a well-established market leader and trusted brand in Singapore and Malaysia. With over S$100 billion in assets and more than 16 million policyholders, including 12.5 million from government schemes, it provides insurance solutions to customers through three successful distribution channels \u2013 a tied agency force, bancassurance, and financial advisory firm Great Eastern Financial Advisers. The Group also operates in Indonesia and Brunei. The Great Eastern Life Assurance Company Limited and Great Eastern General Insurance Limited have been assigned the financial strength and counterparty credit ratings of \"AA-\" by S&P Global Ratings since 2010, one of the highest among Asian life insurance companies. Great Eastern's asset management subsidiary, Lion Global Investors Limited, is one of the leading asset management companies in Southeast Asia. Great Eastern is a subsidiary of OCBC, the longest established Singapore bank, formed in 1932. It is the second largest financial services group in Southeast Asia by assets and one of the world\u2019s most highly-rated banks, with an Aa1 rating from Moody\u2019s and AA- by both Fitch and S&P. Recognised for its financial strength and stability, OCBC is consistently ranked among the World\u2019s Top 50 Safest Banks by Global Finance and has been named Best Managed Bank in Singapore by The Asian Banker.","salary":"","work_type":"Full time"}
{"Job_ID":"85823545","Role":"Data Engineer","Company":"Innowave Tech Pte Ltd","Location":"Paya Lebar East","Publish_Time":"2025-07-17 20:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85823545","country":"singapore","job_desc":"About Innowave Tech Singapore ; Innowave Tech is an Artificial Intelligence (AI) company offering solutions for the Semiconductor and Advanced Manufacturing industry. Utilizing deep industrial domain knowledge, proven experience, and innovation, we provide expert AI solutions and systems to address various industry pain points. ;  Roles & Responsibilities ; We are seeking Data Engineer to establish and lead our data infrastructure. The successful candidate will be responsible for building our data engineering practice from the ground up, implementing robust data systems for industrial AI applications, and establishing best practices that will power our semiconductor manufacturing AI solutions. ;  Your Role and Impact ; As our first Data Engineer, you will have a foundational role in building robust data infrastructure to handle manufacturing data and LLM applications, while establishing secure data practices that power our AI solutions for advanced manufacturing operations. ;  What You\u2019ll Do ; Select and manage on-premises technologies suitable for secure and efficient operations. ; Build robust pipelines to collect, clean, and transform diverse datasets including process data, sensor data, image data, and human annotations. ; Ensure secure, maintainable, and scalable deployment of data infrastructure. ; Define and enforce best practices in data governance, privacy, and access control. ; Collaboration & Deployment. ;  What We\u2019re Looking For ; Educational Background: ; Minimum Poly or Bachelor Degree in Computer Science, Engineering, or a related field. ; * We welcome applications from Singapore Citizens, Permanent Residents (PRs), Malaysians, and local graduates bonded for local employment, in accordance with MoM regulations.;  Technical Expertise: ; 3+ years of experience in data engineering roles, ideally with on-premises or hybrid infrastructure. ; Proven track record of building scalable data systems from ground up in a startup environment. ; Proficiency in Python and\/or Java for data pipeline development. ; Solid experience with ETL frameworks (e.g., Apache Airflow, Dagster) and streaming systems (e.g., Kafka). ; Experience designing and maintaining SQL and NoSQL databases. ; Experience building and operating data lakes and data catalog. ; Familiarity with containerization (Docker), version control (Git), and CI\/CD practices. ;  Soft Skills: ; Excellent communication skills and ability to collaborate with cross-functional technical and non-technical teams. ; Excellent problem-solving and debugging abilities. ; Ability to balance engineering tradeoffs. ;  Bonus Skills: ; Experience with manufacturing data systems, especially SPC, SCADA, and industrial sensor protocols (e.g., OPC UA, MQTT, Modbus). ; Familiarity with AI\/ML pipelines and tools (e.g., MLflow). ; Knowledge in vector databases and LLM data infrastructure. ; Prior experience working in or with regulated industries (e.g., semiconductor, automotive, aerospace). ; What we Offer ; \u2022 A leading role in cutting-edge AI projects within the semiconductor industry. ; \u2022 The opportunity to work with an learn from experts in the field of AI and data science. ; \u2022 A dynamic, innovative, and supportive work environment. ; \u2022 Competitive salary and benefits package. ; \u2022 Career growth opportunities in a fast-paces technology company.","salary":"$5,333 \u2013 $8,000 per month (SGD)","work_type":"Full time"}
{"Job_ID":"85873741","Role":"Big Data Engineer (Libra) - Data Platform","Company":"BYTEDANCE PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-18 15:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85873741","country":"singapore","job_desc":"Big Data Engineer (Libra) - Data Platform; Singapore Regular R&D Job ID: A220563; Responsibilities; About the team Libra is a large-scale online one-stop A\/B testing platform developed by Data Platform. Some of its features include:; Provides experimental evaluation services for all product lines within the company, covering solutions for complex scenarios such as recommendation, algorithm, function, UI, marketing, advertising, operation, social isolation, causal inference, etc.; Provides services throughout the entire experimental lifecycle from experimental design, experimental creation, indicator calculation, statistical analysis to final evaluation launch.; Supports the entire company's business on the road of rapid iterative trial and error, boldly assuming and carefully verifying.; Responsibilities; Responsible for data system of experimentation platform operation and maintenance.; Construct PB-level data warehouses, participate in and be responsible for data warehouse design, modeling, and development, etc.; Build ETL data pipelines and automated ETL data pipeline systems.; Build an expert system for metric data processing that combines offline and real-time processing.; Qualifications; Minimum Qualifications; Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience.; Proficiency with big data frameworks such as Presto, Hive, Spark, Flink, Clickhouse, Hadoop, and have experience in large-scale data processing.; Minimum 1 year of experience in Data Engineering.; Experience writing code in Java, Scala, SQL, Python or a similar language.; Experience with data warehouse implementation methodologies, and have supported actual business scenarios.; Preferred Qualifications; Knowledge about a variety of strategies for ingesting, modeling, processing, and persisting data, ETL design, job scheduling and dimensional modeling.; Expertise in designing, analyzing, and troubleshooting large-scale distributed systems is a plus (Hadoop, M\/R, Hive, Spark, Presto, Flume, Kafka, ClickHouse, Flink or comparable solutions).; Work\/internship experience in internet companies, and those with big data processing experience are preferred.; Job Information; Inspiring creativity is at the core of ByteDance's mission. Our innovative products are built to help people authentically express themselves, discover and connect \u2013 and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and enrich life - a mission we work towards every day.; As ByteDancers, we strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. By constantly iterating and fostering an \"Always Day 1\" mindset, we achieve meaningful breakthroughs for ourselves, our Company, and our users. When we create and grow together, the possibilities are limitless. Join us.; Diversity & Inclusion; ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Apply; Share to","salary":"","work_type":"Full time"}
{"Job_ID":"85840488","Role":"Sr. Data Engineer","Company":"VISA WORLDWIDE PTE. LIMITED","Location":"Singapore","Publish_Time":"2025-07-17 20:18:33","URL":"https:\/\/id.jobstreet.com\/id\/job\/85840488","country":"singapore","job_desc":"Company Description; Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose \u2013 to uplift everyone, everywhere by being the best way to pay and be paid.; Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa.; Job Description; Visa\u2019s Technology Organization is a community of problem solvers and innovators reshaping the future of commerce. We operate the world\u2019s most sophisticated processing networks, capable of handling more than 65k secure transactions a second across 80M merchants, 15k Financial Institutions, and billions of everyday people. You\u2019ll work on complex distributed systems and solve massive scale problems centered on new payment flows, business and data solutions, cybersecurity, and B2C platforms.; In addition, Value Added Services (VAS) - VAS Digital Marketing is a key growth strategy for Visa globally, aimed at diversifying Visa\u2019s revenue with products and solutions that differentiate its network and deliver valuable solutions across other networks.; ; The Opportunity:; We are developing and executing a shared strategic vision for Digital Marketing platforms and products that enable Visa to be the world-leading data-driven payments company. As a Senior Data Engineer, you will be part of a world-class team of Engineers to define, drive and execute on this vision. We are looking for a self-motivated, versatile and energetic individual with software engineering skills and expertise with Java, Big data & Web technologies, who embraces solving complex challenges on a global scale. The candidate will be extensively involved in hands-on activities including POCs, design, development, testing, and managing applications globally used by Visa cardholders. Candidate must be flexible and willing to switch tasks based on team's needs.; ; You will use your Java skills and experience with various technologies to design, develop, test, and deploy high-quality code that meets stringent business, security, and resiliency requirements. You will collaborate with other teams, vendors, and stakeholders to ensure the smooth delivery and operation of the application. You will have the opportunity to learn and apply new technologies and frameworks, such as AI and generative AI, to enhance the functionality and performance of the application.; Primary responsibilities will include:; Design, develop, test, document, and implement new applications and enhance existing systems to ensure high performance and reliability.; Write secure, maintainable, and efficient code that adheres to Java\/J2EE best practices, organizational and security standards.; Create and maintain comprehensive technical documentation, including design changes and architectural decisions, using Wiki or similar tools.; Participate in code and design review sessions to ensure high-quality deliverables and adherence to development standards.; Collaborate with architects, product owners, and technical stakeholders to deliver products that meet business requirements and leverage modern technologies.; Identify and recommend opportunities for process improvements, enhancements, and adoption of best practices within the development team.; Mentor and support junior developers, fostering knowledge sharing and contributing to the development of departmental procedures and standards.; Coordinate and contribute to Continuous Integration (CI) activities and the implementation of automated testing frameworks.; Develop proof-of-concepts (POCs) and prototypes to validate ideas and quickly iterate new features or enhancements.; Communicate technical solutions, project status, issues, and risks effectively to both technical and non-technical stakeholders.; Ensure the delivery of high-quality, defect-free code and take accountability for meeting project timelines and quality standards.; This is a hybrid position. Expectation of days in office will be confirmed by your Hiring Manager.; Qualifications; Preferred Qualifications; \u20223 or more years of work experience with a Bachelor\u2019s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD); \u20224\u20137 years of relevant experience in Java\/J2EE enterprise applications.; \u2022Strong skills in Core Java, J2EE, Spring Framework, Spring Boot, Hibernate, and Web services.; \u2022Proficiency in object-oriented design and software design principles.; \u2022Experience with secure coding practices.; \u2022Strong SQL skills with experience in relational (MySQL, PostgreSQL) and NoSQL (MongoDB) databases.; \u2022Understanding of data warehousing concepts and tools.; \u2022Exposure to data engineering frameworks such as Apache Spark, Hadoop, or Kafka is an advantage.; \u2022Basic understanding of ETL processes and data pipeline development.; \u2022Hands-on experience with containerization and orchestration tools (Docker, Kubernetes).; \u2022Proficiency in version control systems (Git\/Stash), build tools (Maven), and CI\/CD tools (Jenkins).; \u2022Familiarity with Unix\/Linux operating systems and shell scripting.; \u2022Experience with UI frameworks and frontend development using Angular or React, Next.js, JavaScript, HTML, and CSS.; \u2022AI and generative AI skills are highly desirable.; \u2022Experience working in all phases of the software development life cycle.; \u2022Experience with Agile methodologies (Scrum, sprints) and tools (Jira).; \u2022Understanding of DevOps practices.; \u2022Solid foundation in computer science, including data structures and algorithms.; \u2022Willingness to learn and improve coding skills, especially in Java or Scala.; Additional Information:; Skills\/Abilities; \u2022Strong analytical and problem-solving abilities.; \u2022Quick to learn and adapt to new technologies and challenges.; \u2022Excellent organizational skills with the ability to manage multiple tasks and deadlines in a fast-paced environment.; \u2022Outstanding written and verbal communication skills for conveying ideas and implementation plans to team members and stakeholders.; \u2022Highly detail-oriented, resourceful, and results-driven.; \u2022Self-motivated with a demonstrated ability to work independently and meet commitments.; \u2022Comfortable collaborating in dynamic, fast-paced, and highly interactive team settings.; \u2022Eager to learn new skills, embrace new initiatives, and contribute to team success.; \u2022Proven ability to maintain a positive attitude and have fun while working as part of a team.; Additional Information; Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","salary":"","work_type":"Full time"}
