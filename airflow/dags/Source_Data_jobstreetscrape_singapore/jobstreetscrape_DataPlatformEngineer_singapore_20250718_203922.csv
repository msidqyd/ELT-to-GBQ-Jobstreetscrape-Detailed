Job_ID,Role,Company,Location,Publish_Time,URL,country,job_desc,salary,work_type
85838975,Data Engineer - ETL (MOH ITDG),Synapxe,One North,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85838975,singapore,"Company description:; ; Synapxe is the national HealthTech agency inspiring tomorrow's health. The nexus of HealthTech, we connect people and systems to power a healthier Singapore.; ; Together with partners, we create intelligent technological solutions to improve the health of millions of people every day, everywhere. Reimagine the future of health together with us at www.synapxe.sg; ; ; Job description:; ; Position Overview Role & Responsibilities; Develop TRUST data strategy:; Work with stakeholders to understand data analytics needs, data structure requirements (both in terms of scalability and accessibility), and translate this into a coherent near to long term data strategy for TRUST; Support translation of data business needs into technical system requirements for MCDR, in terms of collection, storage, batch -time processing, as well as analysis of information from structured and unstructured sources in a scalable, repeatable, and secure manner; Identify opportunities for improvements and optimisation e.g., Implement best practices and performance optimization on Big Data and Cloud to achieve the best data engineering outcomes; Oversee data preparation and data provisioning for TRUST:; Collaborate with data engineers to organise and prepare anonymised datasets in MCDR according to TRUST standards, and then providing the data in accordance with the approved TRUST Data Request. This involves working with the data engineers closely to ensure that the datasets meet the required standards and are made available as per the specific data request guidelines set by TRUST; Oversee implementation of common data model and data quality programme in TRUST and MCDR; Work with data analysts, data scientists, clinicians and other stakeholders to implement common data models to support analytics use cases; Design and implement tools to enhance the data strategy and enable seamless integration with the data, potentially leveraging API calls for efficient integration; Implement data management standards and practices; Requirements; Degree/master's in computer science, Information Technology, Computer Engineering or equivalent; At least ten (10) years of relevant working experience in Data management / Integration / Modelling the data warehouse or advanced analytics solutions; Demonstrate good, in-depth knowledge in relevant Extract-Transform-Load (ETL) hardware/software products, frameworks, and methodologies; Experience in designing and implementing cloud-based data solutions using cloud platforms (e.g., AWS cloud native tools); Databases (e.g., Oracle, MS SQL, MySQL, Teradata); Big data (e.g., Hadoop ecosystem); ETL development using ETL tools (e.g., Informatica, IBM DataStage, Talend); Data repository design (e.g., operational data stores, dimensional data stores, data marts); Experience in interacting with analytics stakeholders (economists, statisticians, clinicians, policy makers) on a business or domain level; Comfortable working independently to carry out data analysis, estimate data quality and sufficiency; Good interpersonal skills, a detail-oriented & flexible person who can work across different areas within the team; The following will be preferred: Some understanding of Singapore Healthcare System and healthcare data governance, management; and/or familiarity with health informatics; Apply Now; NOTE: It only takes a few minutes to apply for a meaningful career in HealthTech - GO FOR IT!!; #LI-SYNX40",,Full time
85848016,Senior Data engineer,Flintex Consulting Pte Ltd,City Hall,2025-07-17 22:18:41,https://id.jobstreet.com/id/job/85848016,singapore,"Benefits: 13th Month Salary; Responsibilities; Integrate data from multiple sources, such as databases, APIs, or streaming platforms, to provide a unified view of the data; Implement data quality checks and validation processes to ensure the accuracy, completeness, and consistency of data; Identify and resolve data quality issues, monitor data pipelines for errors, and implement data governance and data quality frameworks; Enforce data security and compliance with relevant regulations and industry-specific standards; Implement data access controls, encryption mechanisms, and monitor data privacy and security risks; Optimise data processing and query performance by tuning database configurations, implementing indexing strategies, and leveraging distributed computing frameworks; Optimize data structures for efficient querying and develop data dictionaries and metadata repositories; Identify and resolve performance bottlenecks in data pipelines and systems; Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders; Document data pipelines, data schemas, and system configurations, making it easier for others to understand and work with the data infrastructure; Monitor data pipelines, databases, and data infrastructure for errors, performance issues, and system failures; Set up monitoring tools, alerts, and logging mechanisms to proactively identify and resolve issues to ensure the availability and reliability of data; It would be a plus if he has software engineering background; Requirements; Bachelor's or master's degree in computer science, information technology, data engineering, or a related field; Strong knowledge of databases, data structures, algorithms; Proficiency in working with data engineering tools and technologies including knowledge of data integration tools (e.g., Apache Kafka, Azure IoTHub, Azure EventHub), ETL/ELT frameworks (e.g., Apache Spark, Azure Synapse), big data platforms (e.g., Apache Hadoop), and cloud platforms (e.g., Amazon Web Services, Google Cloud Platform, Microsoft Azure); Expertise in working with relational databases (e.g., MySQL, PostgreSQL, Azure SQL, Azure Data Explorer) and data warehousing concepts.; Familiarity with data modeling, schema design, indexing, and optimization techniques is valuable for building efficient and scalable data systems; Proficiency in languages such as Python, SQL, KQL, Java, and Scala; Experience with scripting languages like Bash or PowerShell for automation and system administration tasks; Strong knowledge of data processing frameworks like Apache Spark, Apache Flink, or Apache Beam for efficiently handling large-scale data processing and transformation tasks; Understanding of data serialization formats (e.g., JSON, Avro, Parquet) and data serialization libraries (e.g., Apache Avro, Apache Parquet) is valuable; Having experience in CI/CD and GitHub that demonstrates ability to work in a collaborative and iterative development environment; Having experience in visualization tools (e.g. Power BI, Plotly, Grafana, Redash) is beneficial; Preferred Skills & Characteristics; Consistently display dynamic independent work habits, goal oriented, passionate in growth mindsets and self-motivated professional. Self-driven and proactive in keeping up with new technologies and programming","$6,000 – $9,000 per month (SGD)",Full time
85872576,Data Engineer,"Exoduspoint Capital Management Singapore, Pte. Ltd.",Central Region,2025-07-18 09:18:41,https://id.jobstreet.com/id/job/85872576,singapore,"ExodusPoint Capital, founded in 2017 by Michael Gelband, began managing investor capital in 2018. The firm employs a global multi-strategy investment approach, seeking to deliver compelling asymmetric returns by combining complementary liquid strategies managed by experienced investment professionals within a robust risk framework. ExodusPoint brings together an accomplished team with hands-on experience running multi-manager businesses to create an institutional investment management firm.; ExodusPoint is seeking an experienced Data Engineer with financial data knowledge to join an established data engineering team to help build a next generation data offering for ExodusPoint’s diverse investment teams, varying across asset classes and strategies. The ideal candidate is a domain expert on financial datasets who has technical skills to work with business and create enterprise data assets utilizing advanced data processing techniques and tools.; The Enterprise Data group is focused on building a robust data platform which services a diverse set of investment teams and internal clients. The group consists of data sourcing experts, data product specialists, data scientists and data engineers, who are responsible for the discovery, management, and curation of thousands of alpha sources for the firm and our investment professionals.; Responsibilities:;  Build data sets using Python, SQL, Snowflake, Kafka, AWS, and other related technologies.;  Understand financial reference data sets from Bloomberg and/or Refinitiv.;  Engage with vendors and technical teams to systematically ingest, evaluate, and create valuable data assets;  Engage with technical and non-technical clients as SME on data asset offerings;  Collaborate with core engineering team to create central capabilities to process, manage and distribute data assts at scale;  Apply robust data quality rules to systemically qualify data deliveries and guarantee the integrity of financial datasets;  Investigate and remediate domain-specific production issues escalated by the operations teams;  Enrich the central data catalog with advanced data profiling visualizations to enable discovery and evaluation;  Build up internal documentation and sample uses cases of the data sets;  Partner with data strategy and sourcing team on data requirements to design data pipelines and delivery structures.; Qualifications:;  Bachelor's degree in STEM;  +3 years of experience with programming in Python and/or Java;  Experience working with security master, financial datasets and/or enterprise financial vendor data products;  Familiar with SQL and/or time-series database technologies;  Experience with data modeling, data warehousing, and building data pipelines;  Experience working with FTP, API, S3 and other distribution channels to source data;  Experience working on multiple projects and with different stakeholders; Desired Qualifications:;  Hands-on experience with AWS native data and compute technologies (S3, Lambda, Glue, DataSync, EMR, Athena, Lake Formation, Kinesis, etc.).;  Experience designing and working with APIs (REST, GraphQL, etc.).;  Experience with Apache Kafka or other data streaming technologies.;  Knowledge of developing containerized applications.;  Experience with JIRA and Agile project management.",,Full time
85871904,Financial Data Engineer,BICHEER TECHNOLOGY PTE. LTD.,Singapore,2025-07-18 02:18:41,https://id.jobstreet.com/id/job/85871904,singapore,"Key Responsibilities:; Design, develop, and maintain high-performance data processing platforms to support the ingestion, storage, and analysis of high-frequency real-time financial data.; Build scalable and resilient data architectures to ensure system stability and high availability under large-scale data loads.; Manage and integrate data from multiple sources, including fundamental financial data, factor data, and unstructured data (e.g., text, images).; Support the quantitative research team by fulfilling data needs and assisting in the development of data-driven quantitative models and strategies.; Leverage AI and machine learning techniques to optimize data workflows and enhance data quality and processing efficiency.; Monitor and tune data pipelines to resolve bottlenecks and ensure smooth data processing operations.; Stay up to date with the latest technologies in data engineering and AI, and drive innovation within the team.; Requirements:; Bachelor's degree or above in Computer Science, Data Engineering, Software Engineering, or a related field.; Minimum of 5 years of experience in data engineering or a related domain, preferably with a background in the financial industry.; Proficient in Python, Scala, or Java, and experienced with data processing and analytics libraries (e.g., Pandas, NumPy, PySpark).; Familiarity with streaming data technologies (e.g., Kafka, Flink, Spark Streaming), with the ability to handle high-frequency real-time data.; Experience in building and maintaining data warehouses and data lakes.; Knowledge of cloud platforms and their big data ecosystems (e.g., AWS, Azure, GCP).; Experience with deploying AI/ML models and optimizing data workflows is a strong plus.; Strong system design skills, with a solid understanding of distributed systems and microservices architecture.; Excellent problem-solving abilities and strong team collaboration skills.; Preferred Qualifications:; Experience developing quantitative trading platforms or high-frequency trading systems.; Familiarity with factor analysis and the development process of quantitative models.; Experience working with unstructured data (e.g., NLP, image processing).; Understanding of deep learning frameworks (e.g., TensorFlow, PyTorch) and their applications in financial data processing.",,Full time
85833905,Data Engineer - Cloud Operations (Engineering & Ops),Synapxe,One North,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85833905,singapore,"Company description:; ; Synapxe is the national HealthTech agency inspiring tomorrow's health. The nexus of HealthTech, we connect people and systems to power a healthier Singapore.; ; Together with partners, we create intelligent technological solutions to improve the health of millions of people every day, everywhere. Reimagine the future of health together with us at www.synapxe.sg; ; ; Job description:; ; Position Overview; This position will serve as primary support for cloud operations related to IDMC, Tableau, STATA, Sagemaker and Databricks. This role will be responsible for ensuring platforms operate reliably, securely and efficiently within the AWS environment. Responsibilities include maintaining operational excellence, monitoring and automation, managing incident response and performance optimization and ensure governance and cloud best practices.; Role & Responsibilities; Operational Architecture and Reliability; Design scalable, fault-tolerant, and high available AWS infrastructure; Define and implement operational best practices for cloud workloads (compute, storage, database); Monitoring and Logging; Build and maintain operational playbooks; Setup alerts, dashboards and logs to track health and performance of AWS workloads; Incident Management and Troubleshooting; Conduct Root Cause analysis and drive permanent fixes for recurring issues; Define and enforce incident response processes and escalation paths; Lead resolution of incidents; Requirements; Degree in Computer Science, Computer Engineering; Minimum 10-12 year working experience in system operations compliance and management areas; 5+ years of experience in cloud operations or cloud architecture; Must be cloud certified; Good in-depth understanding of data warehouse concepts, data profiling, data verification and advanced analytics techniques; Strong knowledge of monitoring, incident management, and clous cost control; Possess prior hands-on experience with technologies such as AWS, IDMC, Tableau, .NET, MS-SQL database, Oracle Database, Databricks, ML Ops, STATA, Sagemaker, Data Robot technologies.; Good interpersonal skills with the ability to work with different groups of stakeholders; Exposure to hospital information / clinical systems is an added advantage; Apply Now; NOTE: It only takes a few minutes to apply for a meaningful career in HealthTech - GO FOR IT!!; #LI-SYNX40",,Full time
85843199,Backend Data Engineer,Whitehall Resources,Singapore,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85843199,singapore,"Backend Data Engineer; Backend Data Engineer required by Whitehall Resources for a 9-12 Month extendable project assignment for our client headquartered in Germany.; Please note, we are looking for candidates that can either work in CET or APAC time zones. Candidates based in offshore locations such as APAC are preferred.; Start Date: ASAP; Duration: 9-12 Months extendable; Delivery: Fully Remote; Capacity: Full Time; Overview:; We are seeking a skilled Backend Data Engineer to design, build, and maintain scalable data pipelines and infrastructure that support advanced analytics and business intelligence. You will work closely with data scientists, analysts, and platform teams to ensure efficient, secure, and reliable data delivery.; Key Responsibilities:; - Develop and maintain ETL/ELT pipelines using tools such as Apache Spark, Airflow, or dbt; - Design and optimize data warehouses and data lakes (e.g., Snowflake, BigQuery, Redshift); - Integrate data from various sources including APIs, databases, and streaming platforms; - Ensure data quality, consistency, and security through validation and monitoring; - Collaborate with DevOps to automate deployments and CI/CD workflows; Key Skills & Technologies:; - Proficient in Python, SQL, and working with relational & NoSQL databases; - Experience with cloud platforms (AWS, GCP, or Azure); - Knowledge of data modeling, partitioning, and performance tuning; - Familiarity with Kafka, Spark, or other big data technologies; - Understanding of data governance, security, and compliance (GDPR, etc.); Start Date is ASAP!; Please Apply Now!; All of our opportunities require that applicants are eligible to work in the specified country/location, unless otherwise stated in the job description.; Whitehall Resources are an equal opportunities employer who value a diverse and inclusive working environment. All qualified applicants will receive consideration for employment without regard to race, religion, gender identity or expression, sexual orientation, national origin, pregnancy, disability, age, veteran status, or other characteristics.",,Kontrak/Temporer
85845116,Data Engineer & Reporting Developer,ALMR CONSULTING PTE. LTD.,Singapore,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85845116,singapore,"Job Description; We are looking for a skilled Data Engineer & Reporting Developer with 3 to 10 years of experience in big data engineering and analytics. The ideal candidate will have a strong background in Python, PySpark, ETL, and reporting tools. You will be responsible for designing and building data pipelines, improving data collection, and delivering analytical solutions for business users.; Key Responsibilities; Analyse data needs and document business requirements.; Refine and migrate data collection to more efficient sources.; Plan, design, and implement data engineering jobs and reporting solutions.; Develop test plans, execute system testing, and support UAT.; Work closely with technical teams for deployment and adoption.; Ensure smooth operations and service levels.; Provide support for production issues.; Requirements; Degree in Computer Science, Information Systems, or related field preferred.; 3–10 years of experience in big data engineering.; Experience in Cloudera Data Platform is a plus.; Proficient in Python, PySpark, Linux, and ETL tools like Informatica.; Strong SQL and data analysis skills.; Experience with data virtualisation tools (e.g., Denodo) is a bonus.; Hands-on with reporting tools like SAP BO, Tableau.; Familiarity with Agile and Waterfall methodologies.; Strong communication and stakeholder management skills.; Self-driven, collaborative team player.",,Kontrak/Temporer
85831330,Cloudera Platform Engineer,Morgan McKinley,Marina South,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85831330,singapore,"Roles & Responsibilities; Morgan McKinley is looking for Cloudera Platform Engineer for a 12- month contract assignment with our global professional services client providing a broad range of services and solutions in strategy, consulting, digital, technology, and operations.; Responsibilities; Oversee day-to-day operations of big data platform to ensure high availability, reliability and performance.; Proactively monitor big data platform services, components and clusters to identify potential issues.; Take corrective actions as needed to maintain platform health; Manage configuration, upgrades, and patching of big data platform, ensuring all services are up to date up to date; Work with the Authority's technical teams to ensure smooth deployment and adoption of new solution to support data ingestions, process and workflows; Maintain clear and detailed documentation of platform configuration, troubleshooting steps and incident resolution.; Continuously monitor for and address platform security vulnerabilities. Implement patching strategies to resolve identified vulnerabilities and maintain a secure environment.; Develop automation script to streamline administrative tasks, platform health and ensure operational consistency.; Ensure the smooth operations and service level of IT solutions.; Support production issues; Qualifications; Bachelor’s degree in Information Technology or related field.; Minimum of 5 years’ experience in related field or in Data Warehousing (e.g. Snowflakes, Databricks, etc.); Hands-on experience, knowledge and troubleshooting of Cloudera Data Platform such as HDFS, YARN, HIVE, Spark, Impala, Ranger, operating systems, security and network.; Hands on experience with monitoring tools like Cloudera Manager, Zabbix, Grafana, Splunk, SyslogNG; Familiarity with middleware applications i.e. Informatica, Denodo and scripting languages like bash, python, or shell scripting for automation; Experience with cloud technology i.e. AWS, Azure is a plus; Ability to troubleshoot complex issues ranging from system resource to application stack traces.; Track record in implementing systems with high availability, high performance, high security hosted at various data centres or hybrid cloud environments will be an added advantage.; Cloudera Certified Administrator or similar certification are a plus.; Excellent communication skill to work with cross-functional teams.; Interested candidates may apply through the application system or send it to sg-rscontracting@morganmckinley.com. Shortlisted candidates will be notified.; ; By sending us your personal data and curriculum vitae (CV), you are deemed to consent to Morgan Mckinley Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy available at https://www.morganmckinley.com/sg/privacy-policy. You acknowledge that you have read, understood, and agree with the Privacy Policy.; ; Morgan McKinley Pte Ltd; Koh Boon Sien; EA Licence No: 11C5502; EA Registration No. R1110345",,Kontrak/Temporer
85840938,Data Engineer - Growth,TikTok Pte. Ltd.,Singapore,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85840938,singapore,"Responsibilities; The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Lemon8, etc. We are building platform foundations, leveraging data and ML models, and providing end-to-end solutions to power global growth of products. You will:; - Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; - Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; - Keep improving the integrity of data pipelines to provide a comprehensive data service.; Qualifications; Minimum Qualifications：; Bachelor's degree in Computer Science, Statistic, Data Science or a related field;; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python);; Experience in issue tracking and problem solving on data pipelines;; Fast business understanding and collaborative in teamwork.; Preferred Qualification：; Industry experience working with user growth.",,Full time
85862823,Cloud Engineer - 12 Months Agency Contract,PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),Central Region,2025-07-18 07:18:41,https://id.jobstreet.com/id/job/85862823,singapore,"Requirements; VMware Tanzu Certification (Must have); Minimum Diploma - 3-5 Year; Responsibilities:; Cloud Architecture Design: Creating and maintaining the architecture of cloud environments, ensuring they meet the organization's requirements for scalability, security, and performance.; Deployment and Migration: Managing the deployment of applications and services to the cloud, and overseeing the migration of existing systems to cloud platforms.; Security Management: Implementing and maintaining security measures to protect cloud-based systems and data from threats and vulnerabilities.; Performance Monitoring: Continuously monitoring the performance of cloud systems, identifying and resolving issues to ensure optimal operation.; Cost Management: Managing cloud resources efficiently to control costs, including optimizing resource usage and implementing cost-saving measures.; Automation and Scripting: Developing scripts and automation tools to streamline cloud operations and improve efficiency.; Collaboration and Support: Working closely with other IT teams and stakeholders to support cloud initiatives and provide technical expertise.; Interested parties, please click on the following link to begin your job search journey and submit your CV directly through the official PERSOLKELLY job application platform – GO mobile.; We regret that only shortlisted applicants would be notified.; Toh Wen Qi, Celeste | REG No : R25135730; PERSOLKELLY SINGAPORE PTE LTD | EA License No : 01C4394; This is in partnership with Employment and Employability Institute Pte Ltd (“e2i”). e2i is the empowering network for workers and employers seeking employment and employability solutions. e2i serves as a bridge between workers and employers, connecting with workers to offer job security through job-matching, career guidance and skills upgrading services, and partnering employers to address their manpower needs through recruitment, training and job redesign solutions. e2i is a tripartite initiative of the National Trades Union Congress set up to support nation-wide manpower and skills upgrading initiatives. By applying for this role, you consent to e2i’s PDPA.; By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy available at https://www.persolkelly.com.sg/policies. You acknowledge that you have read, understood, and agree with the Privacy Policy.","$5,500 – $8,200 per month (SGD)",Kontrak/Temporer
85872810,Machine Learning Integration Engineer,Synechron,Singapore,2025-07-18 02:18:41,https://id.jobstreet.com/id/job/85872810,singapore,"This ML / Integration Engineer role focuses on building and integrating Generative AI and Agentic AI solutions into enterprise environments. You will work closely with data scientists, architects, and DevOps teams to design, implement, and optimize AI pipelines and infrastructure.; Job Responsibilities:; Design and implement scalable ML pipelines for Generative and Agentic AI applications.; Integrate AI models into production environments using containerized platforms such as OpenShift and Kubernetes .; Collaborate with cross-functional teams to understand AI workflows and translate them into robust engineering solutions.; Develop and maintain automation scripts using Linux shell scripting , Python , or other relevant tools.; Ensure seamless deployment and integration of AI services in cloud environments (e.g., AWS, Azure, GCP).; Implement and maintain network security protocols to safeguard AI systems and data pipelines.; Monitor and optimize system performance , reliability , and scalability .; Support CI/CD processes and infrastructure for AI model deployment and updates.; Job Requirements:; Bachelor’s degree in Computer Science, Engineering, or a related field.; 4+ years of experience in Machine Learning engineering or AI system integration.; Hands-on experience with OpenShift, Docker, Kubernetes .; Knowledge of cloud platforms (e.g. AWS , GCP) is a must-have.; Exposure to data and network security and compliance in AI systems.; Understanding of Generative AI and Agentic AI concepts .; Experience with LLM prompt engineering, or RAG pipelines.; Knowledge of API integration and microservices architecture.; Proficiency in Python used both for ML and automation tasks; Good knowledge of Bash and Unix/Linux command-line toolkit is a must-have.; Knowledge of Workflow Orchestrator , such as Ctrl-M; Knowledge of Logging and Monitoring tools, such as Splunk and Geneos .; Experience with Observability framework , such as Langfuse, Elastic Stack, Grafana, OpenTelemetry.; Interested candidates are invited to submit application via https://www.linkedin.com/jobs/view/4265421740",,Full time
85870608,AWS Solutions Architect,ONECONNECT FINANCIAL TECHNOLOGY (SINGAPORE) CO. PTE. LTD.,Central Region,2025-07-18 10:18:41,https://id.jobstreet.com/id/job/85870608,singapore,"Job Responsibilities:; Proficient in mainstream cloud platforms such as AWS, Alibaba Cloud, and Huawei Cloud.; Strong expertise in cloud IAM (Identity and Access Management), monitoring setup, and cost optimization.; Collaborate effectively with L1 support teams and development teams to ensure the availability and reliability of applications deployed on the cloud.; Work closely with development teams and cloud solution architects to optimize applications for better cost-efficiency and performance on the cloud.; Technical Requirements (familiarity in the following areas is required):; Networking (including dedicated lines, VPNs, VPC Peering, and hybrid cloud networking); Secure communications; Cloud compute and storage (e.g., virtual machines and disk management); Data backup and disaster recovery; Database systems; Monitoring and observability tools; Proficiency in Kubernetes (K8s); Mandatory Requirements; English must be used as a working language.; Candidates must hold at least one of the following certifications:; 1. AWS Certified Solutions Architect – Professional; 2. AWS Certified Advanced Networking – Specialty; 3. AWS Certified Security – Specialty",,Full time
85866721,Software Integration Engineer - AWS (Services Planning),Synapxe,One North,2025-07-18 08:18:41,https://id.jobstreet.com/id/job/85866721,singapore,"Position Overview; We are seeking a highly skilled and motivated software integration engineer - AWS to join our team. The ideal candidate will have a strong background in cloud computing and application development, with a focus on designing, developing, and deploying cloud-based applications. The potential candidate will work closely with cross-functional teams, include the operational and data teams, partners and vendors to ensure the successful implementation and maintenance of cloud solutions. This is a year two year direct contract with Synapxe. ; Role & Responsibilities; Design, develop, deploy cloud-based and integrate non-cloud-based applications using industry best practices and cloud technologies; Collaborate with software engineers, architects, and other stakeholders to gather requirements and define application specifications; Implement security measures to protect cloud-based applications and data; Troubleshoot and resolve issues related to cloud infrastructure and applications; Optimize cloud-based applications for performance, scalability, and cost-efficiency; Provide technical guidance and support to team members and stakeholders; Assist in managing and monitoring of cloud-based assets hosted on Singapore GCC platforms; Requirements; Bachelor's degree in Computer Science, Engineering, or a related field; More than 6 years experience in coding with cloud technologies environment; At least 3 years of experience in working as AWS cloud developer; Strong experience in cloud computing platforms such as AWS, Azure, or Google Cloud; Experience with Singapore GCC hosting platform will be of advantage but not essential; Experience with containerization technologies such as Docker and Kubernetes; Familiarity with CI/CD pipelines and automation tools; Experience with Apache Hadoop and Apache Spark; Proficiency in programming languages such as Java, Python, JavaScript and/or C#; Knowledge of cloud security best practices and compliance standards; Experience working with version control and repository tools like Git, Maven; Strong background working with Linux/UNIX environments; Working knowledge with SQL and NoSQL databases preferred; Strong collaboration and communication skills within project teams; Excellent problem-solving and troubleshooting skills; Apply Now; NOTE: It only takes a few minutes to apply for a meaningful career in HealthTech - GO FOR IT!!; #LI-SYNX34",,Full time
85862067,Assistant Lead Engineer - Data Loss Prevention (Security Engineering),Synapxe,One North,2025-07-18 06:18:41,https://id.jobstreet.com/id/job/85862067,singapore,"Position Overview; As a part of the Security Operations department, the incumbent will review and conduct technical security risk checks. SecOps is also aligned to SOC for incident management handling, reporting and investigation. Candidate will have to work on technical risk management. Handle day-to-day incident reporting and support investigation to healthcare IT platform. The Security Engineer is part of the Data Loss Prevention (DLP) project and operation team. Candidate will be reporting to the DLP Team Lead.; Role & Responsibilities; Responsible for handling project and operational work; Processing requests; Investigate operational issues; Facilitate security investigation by providing the necessary information in accordance with approved policy and procedures as well as process improvement; Requirements; Relevant qualification, Diploma/ Degree in Computer Science, Engineering or equivalent; At least 6 years of relevant experience in IT preferably within Incident Management, DLP Operations or SOC; Good team player as well as strong communications skills with stakeholders at all levels; Strong analytical skills and ability to work independently",,Full time
85852478,Infrastructure Engineer (CyberArk Engineer),PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),East Region,2025-07-18 02:18:41,https://id.jobstreet.com/id/job/85852478,singapore,"CyberArk Engineer; We are seeking a skilled and motivated CyberArk Engineer to join our growing security engineering team. In this role, you will be responsible for designing, implementing, and supporting privileged access management (PAM) solutions using CyberArk, ensuring the highest levels of security, compliance, and operational efficiency.; The ideal candidate will hold a CyberArk Certified Delivery Engineer (CDE) certification and have experience with Sentry (preferred). You will collaborate with cross-functional teams to protect sensitive data and critical systems from unauthorized access.;  Key Responsibilities:; Manage the onboarding and lifecycle of privileged accounts across various systems and environments.; Implement CyberArk policies and security best practices to align with compliance and regulatory standards.; Develop and maintain automation scripts and integrations with CyberArk using REST APIs, PowerShell, and other tools.; Monitor and troubleshoot CyberArk infrastructure and user issues, providing escalation support as needed.; Troubleshoot and remediate CyberArk Central Policy Manager (CPM) failures, including credential rotation errors, connectivity issues, and policy misconfigurations.; Analyse CPM logs and error codes to identify root causes and implement durable solutions in collaboration with infrastructure and application teams.; Perform health checks and tuning of CPM components to ensure stability and optimal performance.; Basic understanding of custom CPM and PSM connectors for target platforms not natively supported by CyberArk.; Work with application owners to gather requirements for new connectors, create integration documentation, and test connector functionality in pre-production environments.; Leverage scripting (e.g., PowerShell, Python) to enhance connector behaviour and automate remediation tasks.; Contribute to the connector certification process and maintain version control for custom components.; Assist with audits, documentation, and reporting of privileged access activities.; Work with IT, DevOps, and Security teams to integrate PAM solutions into existing workflows.; Stay up to date with emerging threats, PAM trends, and CyberArk product updates.;  Required Qualifications:; CyberArk Certified Delivery Engineer (CDE) certification (must-have); 3+ years of experience implementing and supporting CyberArk solutions in enterprise environments; Proficiency with CyberArk components and architecture; Strong scripting skills (PowerShell, Python, etc.) and experience using CyberArk APIs; Understanding of Identity and Access Management (IAM) concepts, Zero Trust, and least privilege; Solid knowledge of Windows/Linux systems, Active Directory, and network security fundamentals;  Preferred Qualifications:; Experience or certification with Sentry; CyberArk Defender or Guardian certification(s); Familiarity with cloud PAM implementations (AWS, Azure, GCP); Experience with SIEM tools and security monitoring; Bachelor’s degree in Computer Science, Information Security, or related field; EA License No. 01C4394 • RCB No. 200007268E •Derrick Tiew Yong Han EA Registration No. R1877971; By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy available at https://www.persolkelly.com.sg/policies. You acknowledge that you have read, understood, and agree with the Privacy Policy.","$5,000 – $7,500 per month (SGD)",Kontrak/Temporer
85840948,"Cloud Engineer (AWS, Devops, Tech Firm)",PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),One North,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85840948,singapore,"Our client is one of the leader in the software provider industry. The team is seeking a Cloud DevOps Engineer who will have a critical role on how we design, build, and deliver reusable managed cloud stacks; Location: One North; Salary up to $8000; Contract: 6 Month; ; Responsibilities:; ; 1) Build and extend Full Stack infrastructure automations for enterprise and business applications in the enterprise cloud environment by leveraging Python, NodeJs, CI/CD and GitOps Methodologies etc.; 2) Configure and implement the public cloud environment for enterprise and business applications.; Refactor and migrate business applications to adopt Platform strategy to increase Engineering Productivity; 3) Troubleshooting and solutioning of issues in the AWS environment. 24x7 OnCall rotation; 4) Design and build automation solutions to reduce manual efforts and increase team efficiency.; ; Desired Skills & Experience:; ; 1) Must have 5+ years of hands-on experience on AWS & DevOps; 2) 3 years of Hands-on experience in Software development and Automation using Python, NodeJS, TypeScript, Rest API, GitOps, etc.; 3) Working knowledge on setting up cloud infra using terraforms, cloud formation templates and/or CDK; 4) Expert knowledge with CI/CD tools like Code Build, Code Deploy, Jenkins.; 5) Expert Knowledge with observability and logging tools/services (ie Splunk, Catchpoint, Dynatrace, etc); 6) Good knowledge on developing automations on using Python, PowerShell, TypeScript, etc.; 7) Hands-on experience with the AWS Cloud Services (i.e. EC2, RDS, DynamoDB, S3 Bucket, API Gateway, Lambda, CloudWatch etc.); 8) Hands-on Experience on Linux is a plus; 9) API Development experience with Java and/or NodeJS is a plus; 10) Attention to detail and dedication to Quality, Automation; 11) Should have SRE mindset; PERSOLKELLY Singapore Pte Ltd • RCB No. 200007268E EA License No. 01C4394 • EA Registration No. R21103542 (Ling Kai Jin); By sending us your personal data and CV, you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for account creation in GO and the purposes set out in the Privacy Policy https://www.persolkelly.com.sg/policies. You acknowledge that you have read, understood, and agree with GO’s Terms of Use https://go.persolkelly.com/Tacand the Privacy Policy. If you wish to withdraw your consent, please email us at dataprotection@persolkelly.com. Please feel free to contact us if you have any queries.","$6,500 – $8,500 per month (SGD)",Full time
85824205,Cloud Engineer,Alphaeus Pte Ltd,Central Region,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85824205,singapore,"Job Type: Contract; Duration: 1 Year; Location: Ang Mo Kio; Job Description; The primary purpose of an IT Cloud Engineer is to design, implement, and manage cloud-based systems and infrastructure to support an organization's IT needs.; Here are some key responsibilities:;  Cloud Architecture Design: Creating and maintaining the architecture of cloud environments, ensuring they meet the organization's requirements for scalability, security, and performance.; Deployment and Migration: Managing the deployment of applications and services to the cloud, and overseeing the migration of existing systems to cloud platforms.; Security Management: Implementing and maintaining security measures to protect cloud-based systems and data from threats and vulnerabilities.; Performance Monitoring: Continuously monitoring the performance of cloud systems, identifying and resolving issues to ensure optimal operation.; Cost Management: Managing cloud resources efficiently to control costs, including optimizing resource usage and implementing cost-saving measures.; Automation and Scripting: Developing scripts and automation tools to streamline cloud operations and improve efficiency.; Collaboration and Support: Working closely with other IT teams and stakeholders to support cloud initiatives and provide technical expertise.; Requirements:; Minimum Diploma in Computer Science, Information Technology, or a related field.; VMware Tanzu Certification (Mandatory).; 2–4 years of hands-on experience working in a cloud environment.; Willingness to be on a 24/7 standby rotation, including nights, weekends, and holidays as required.; Experience with cloud-native applications and Kubernetes-based platforms.","$6,000 – $7,000 per month (SGD)",Full time
85867413,"System and Network Engineer [Active Directory, DNS, DHCP, SQL, Linux, Microsoft]",TRUST RECRUIT PTE. LTD.,Central Region,2025-07-18 09:18:41,https://id.jobstreet.com/id/job/85867413,singapore,"Job Responsibilities:; Deliver presales support for solutions such as Data Loss Prevention (DLP), data backup, and system applications to clients and partners.; Perform implementation and provide technical support for system, security, and network solutions.; Troubleshoot technical issues and coordinate with technology vendors for escalation when necessary.; Manage and follow through on daily operational tasks and responsibilities.; Offer technical assistance during tender submissions, including preparing technical compliance documents, drafting solution proposals, and conducting Proof-of-Concept (PoC) tests.; Assess and test security and network technologies to identify and recommend new solution offerings.;  Requirements:; Diploma or Degree in Information Technology, Computer Science, Cybersecurity, or a related field.; 2–3 years of hands-on experience in the design, implementation, and management of cybersecurity solutions across multi-vendor infrastructures, including:; ▪ Microsoft-based services such as Domain Controller, Active Directory, DNS, DHCP, LDAP, RADIUS, and AAA servers; ▪ Microsoft Certificate Authority; ▪ Windows, Linux, and UNIX operating environments; ▪ Cloud deployment and integration experience with AWS, Azure, or GCP is an added advantage; Strong troubleshooting skills and the ability to perform technical configurations independently.; Working knowledge of SQL databases, including MSSQL, Oracle, and MySQL, is a plus.; Solid understanding of networking concepts, including switching and routing.; Self-motivated with a proactive attitude and a strong sense of responsibility.; Eagerness to learn and adopt new technologies and skills.;  HOW TO APPLY:; Interested applicants, please click on “Apply Now” and provide the below details in your resume.; We regret only shortlisted candidates will be notified.; Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA). ; Please read our privacy statement on our corporate website www.trustrecruit.com.sg.; Trust Recruit Pte Ltd ; EA License No: 19C9950; EA Personnel: Nyon Hock Sen; EA Personnel Reg No: R24124070","$5,000 – $6,500 per month (SGD)",Full time
85837188,"Core Engineering, SDLC – Developer Collaboration Software Engineer,...",Goldman Sachs Bank AG,Singapore,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85837188,singapore,"Core Engineering, SDLC – Developer Collaboration Software Engineer, Associate/ Vice President, Singapore location_on Singapore; OVERVIEW:; At Goldman Sachs, our Engineers don’t just build things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.; Engineering, which is comprised of our Technology Division and Global Strategist groups, is at the center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions.; CORE ENGINEERING – DEVELOPER COLLABORATION; The Developer Collaboration team owns the Atlassian toolset, focusing on JIRA and Confluence at Goldman Sachs. Our teampartners withinternal stakeholders across business units andfunctional groupsgloballyto drive strategic engineering and collaboration initiatives that deliver end user outcomes, while creating andmaintainingan outstanding customer experience, at scale.; SDLC @ GS:; The SDLC organization is the base and platform on which all technology solutions across the firm are managed. You will be working in the heart of developer experience, ensuring code that is written by thousands of GS engineers is versioned securely, reviewed expertly, compiles fast, is comprehensively tested, compliant, and distributed widely. We empower thousands of developers and all teams across the firm to innovate better, faster, more securely, and in a fully compliant manner, all while striving to create an easy to use, stable, performant, and frictionless ecosystem.; RESPONSIBILITIES:; Own, manage and automate infrastructure and deployments across a variety of environments, including development, testing and production.; Own, implement and maintain continuous integration and delivery pipelines.; Design, configure and manage observability for our systems to ensure application availability and performance.; Own relationships with senior stakeholders and our client development teams to ensure that their needs are met as well as those of the firm.; Implement and maintain security controls and compliance requirements.; Ensure that production issues are addressed in a timely manner, including post mortem and longer term steps to avoid repetition.; Stay current with emerging technologies and tools in the DevOps space.; Advocate for improvements to product quality, security, reliability, and performance.; Develop custom integrations and interfaces between external tooling and Jira/Confluence infrastructure as needed.; SKILLS AND EXPERIENCE WE ARE LOOKING FOR:; 3+ years (Associate) / 8+ years (VP) of experience in a software development, DevOps or related role.; Professional experience with CI /CD tools such as GitLab, Jenkins, CircleCI or Bitbucket.; Professional experience with cloud deployment patterns. Specifically AWS cloud constructs, Terraform, Docker, Kubernetes, and Kafka.; General knowledge of multiple languages and expert in-depth knowledge of at least one of: Golang, Java, Python, C, C++.; Strong software engineering and system design fundamentals.; Experience with all stages of SDLC.; Experience with SRE principles, as well as diagnosis, prevention, performance management, and availability of large distributed systems.; Strong written and verbal communication.; Excellent problem-solving and analytical skills.; Ability to work collaboratively in a team environment.; PREFERRED QUALIFICATIONS:; BSc, MSc, PhD in relevant field (Computer Science, Information Systems, or similar).; Experience with Prometheus and Grafana, as well as knowledgeable about networking protocols (TCP, UDP, ICMP, ARP, DNS, TLS, HTTP, SSH, etc.); Experience with the use of ML and/or agentic AI, especially in relation to facilitating the SDLC.; Experience in stakeholder management.; ABOUT GOLDMAN SACHS; At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.; We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.; We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html; Goldman Sachs is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, national origin, age, veterans status, disability, or any other characteristic protected by applicable law.; Healthcare & Medical Insurance; We offer a wide range of health and welfare programs that vary depending on office location. These generally include medical, dental, short-term disability, long-term disability, life, accidental death, labor accident and business travel accident insurance.; We offer competitive vacation policies based on employee level and office location. We promote time off from work to recharge by providing generous vacation entitlements and a minimum of three weeks expected vacation usage each year.; Financial Wellness & Retirement; We assist employees in saving and planning for retirement, offer financial support for higher education, and provide a number of benefits to help employees prepare for the unexpected. We offer live financial education and content on a variety of topics to address the spectrum of employees’ priorities.; Health Services; We offer a medical advocacy service for employees and family members facing critical health situations, and counseling and referral services through the Employee Assistance Program (EAP). We provide Global Medical, Security and Travel Assistance and a Workplace Ergonomics Program. We also offer state-of-the-art on-site health centers in certain offices.; Fitness; To encourage employees to live a healthy and active lifestyle, some of our offices feature on-site fitness centers. For eligible employees we typically reimburse fees paid for a fitness club membership or activity (up to a pre-approved amount).; Child Care & Family Care; We offer on-site child care centers that provide full-time and emergency back-up care, as well as mother and baby rooms and homework rooms. In every office, we provide advice and counseling services, expectant parent resources and transitional programs for parents returning from parental leave. Adoption, surrogacy, egg donation and egg retrieval stipends are also available.; Benefits at Goldman Sachs; Read more about the full suite of class-leading benefits our firm has to offer.; #J-18808-Ljbffr",,Full time
85838966,Software Engineer (Tech MNC /Partner Developer/ Game/UP14K+),Adecco Personnel Pte Ltd.,Central Region,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85838966,singapore,"Software Engineer; The Opportunity; Adecco is partnering our client, one of the world's largest tech organizations; We are looking for a Software Engineer; The role will start out as a contract (Renewable); Candidates who are immediately available/ able to start work within short notice will be preferred; The Talent; Experience as a software engineer building and shipping production quality code; Experience in shipping reliable, scalable, and efficient code, with an emphasis on long-term maintainability, in partnership with all appropriate reviewers, with clear milestones, and with relevant documentation and test plans; Experience with open source languages such as PHP, Python, Java, or JavaScript Frameworks; Experience with software design and architecture; Experience communicating technical concepts to non-technical audiences; Degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.; Experience with capturing data at scale and/or using data analytics to drive decision-making and impact measurement; Experience or strong interest in Gaming industry is a big plus; Job Description; Build new products and improve existing ones in collaboration with product engineering teams, Partnerships, and other cross-functional partners to meet business needs; Understand and apply knowledge of products, technologies, and business to build solutions to solve for problems at scale; Design and build end-to-end systems and go-to-market strategies; Use a broad range of technical and soft skills to build productive relationships with our partners, and resolve complex technical and business needs; Use and product insight to deliver high-quality project/integration/partner engagements, while influencing product roadmap to meet the business needs; Guide workflow changes, and gain consensus from stakeholders while driving toward solutions; Respond and maintain effective communication with industry partners and internal stakeholders; Work with partners to develop a long-term plan, grounded on business objectives, and manage partners during integrations with platform products and ensure value creation; Build and manage working relationships with technical counterparts. Mentor and share knowledge with peers, creating atmosphere amongst team; Conduct code reviews and provide constructive feedback while quickly actioning feedback from code reviews conducted of your code; Influence decision-making through presentation of data-centric topics; Serve as a subject matter within Partner Engineering and provide consultation on domain-level projects; Participate in interviewing and onboarding of new team members; Willingness to travel, may vary per team/function; Next Step; Prepare your updated resume (please include your current salary package with full breakdown such as base, incentives, annual wage supplement, etc.) and expected package; Send your resume to Xinyang.liu@Adecco.com; All shortlisted candidates will be contacted; Liu XinYang; ; EA Licence Number: 91C2918; ; Personnel Registration Number: R1988872",,Kontrak/Temporer
85869493,Rail Infrastructure Systems Engineer,Adecco Personnel Pte Ltd.,Central Region,2025-07-18 10:18:41,https://id.jobstreet.com/id/job/85869493,singapore,"-; ; ; The Opporunity; Permanent Role; 5 Day Work; Work location: Island-Wide; The Client; Adecco is partnering with a organisation that oversees planning, development and regulation of land-based transport systems.; The Job; Review and contribute to systems designs with a focus on maintability, buildability and long-term maintenance.; Evaluate proposal for upgrades and modifications, ensuring they are cost effective and operational.; Work with cross-functional teams to develop an integrated assest data management platform that enables smarter data-driven decision across the rail network.; The Talent; Minimum Degree in Computer Engineering/Science, Electrical/Electronics Engineering or relevant expertise; Famailiar with system intergration, control/embedded systems, data analytics,IoT or automation tools; 2-5 years of relevant engineering expertise in infrastructure,transport or industrial sectors.; Next Steps; Apply through this application or send your resume to Shawn.Teo@adecco.com in MS Word/PDF Copy and indicate ""Rail Infrastructure Systems Engineer""; Only shortlisted candidates will be contacted; Shawn Teo; Direct Line: 9817 4696; EA License No: 91C2918; Personnel Registration Number: R25127747",$3500 - $6k p.a. (SGD),Full time
85873741,Big Data Engineer (Libra) - Data Platform,BYTEDANCE PTE. LTD.,Singapore,2025-07-18 14:18:41,https://id.jobstreet.com/id/job/85873741,singapore,"Big Data Engineer (Libra) - Data Platform; Singapore Regular R&D Job ID: A220563; Responsibilities; About the team Libra is a large-scale online one-stop A/B testing platform developed by Data Platform. Some of its features include:; Provides experimental evaluation services for all product lines within the company, covering solutions for complex scenarios such as recommendation, algorithm, function, UI, marketing, advertising, operation, social isolation, causal inference, etc.; Provides services throughout the entire experimental lifecycle from experimental design, experimental creation, indicator calculation, statistical analysis to final evaluation launch.; Supports the entire company's business on the road of rapid iterative trial and error, boldly assuming and carefully verifying.; Responsibilities; Responsible for data system of experimentation platform operation and maintenance.; Construct PB-level data warehouses, participate in and be responsible for data warehouse design, modeling, and development, etc.; Build ETL data pipelines and automated ETL data pipeline systems.; Build an expert system for metric data processing that combines offline and real-time processing.; Qualifications; Minimum Qualifications; Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience.; Proficiency with big data frameworks such as Presto, Hive, Spark, Flink, Clickhouse, Hadoop, and have experience in large-scale data processing.; Minimum 1 year of experience in Data Engineering.; Experience writing code in Java, Scala, SQL, Python or a similar language.; Experience with data warehouse implementation methodologies, and have supported actual business scenarios.; Preferred Qualifications; Knowledge about a variety of strategies for ingesting, modeling, processing, and persisting data, ETL design, job scheduling and dimensional modeling.; Expertise in designing, analyzing, and troubleshooting large-scale distributed systems is a plus (Hadoop, M/R, Hive, Spark, Presto, Flume, Kafka, ClickHouse, Flink or comparable solutions).; Work/internship experience in internet companies, and those with big data processing experience are preferred.; Job Information; Inspiring creativity is at the core of ByteDance's mission. Our innovative products are built to help people authentically express themselves, discover and connect – and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and enrich life - a mission we work towards every day.; As ByteDancers, we strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. By constantly iterating and fostering an ""Always Day 1"" mindset, we achieve meaningful breakthroughs for ourselves, our Company, and our users. When we create and grow together, the possibilities are limitless. Join us.; Diversity & Inclusion; ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Apply; Share to",,Full time
85845477,Data Engineer,TOPPAN Ecquaria Pte Ltd,Braddell,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85845477,singapore,"Responsibilities:; Design and implement robust, scalable data pipelines and architectures to support data ingestion, processing, and storage. Including performance optimizations for data modeling and ingestion; Develop and optimize complex SQL queries and stored procedures for data extraction, transformation, and analysis.; Model data to meet different use casesng applications and automate data workflows.; Collaborate with data scientists and analysts to understand data requirements and deliver high-quality data solutions.; Lead the integration of data from various sources into data lakes and warehouses, ensuring data quality and consistency.; Monitor and troubleshoot data pipelines and workflows to ensure optimal performance and reliability.; Communicate with and support data users; Document data processes, data models, and architectural designs to ensure knowledge sharing and compliance with best practices.; Prerequisites:; Experience: Minimum 3 years in data engineering fields with system integration, and at least 1 year in system integration and implementation in cloud/web-based environments.; Proven Solutions: Demonstrated experience in providing effective, working solutions and implementations, particularly in cloud-based environments.; Technical Skills:; Solid understanding of ETL processes, data warehousing concepts, and data modeling best practices.; Proficiency in Databricks, Azure Data lake, PowerBI, Tableau and related data processing and visualisation software.; Familiarity with Windows, Linux, AWS and/or Azure platforms.; Strong programming skills in languages such as Python and R is a must; Proficiency in other programming languages such as Java, Scala and C# will be advantages; Experience in data processing frameworks (e.g., Apache Spark, Apache Flink); Preferred Exposure:; Experience with large-data management system with visualisation tools.; Experience with Data Integration and ETL Pipelines, Data Warehousing and BI reporting projects.; Experience with Singapore Government Project will be advantages; Personal Attributes:; Excellent problem-solving skills; Ability to work independently; Collaborative in a fast-paced environment; Why Join Us?; Be part of a forward-thinking team that is transforming government digital services. If you are passionate about technology and innovation, and thrive in a dynamic environment, we want to hear from you!; If you are passionate about building partnerships and driving growth, we would love to hear from you!; TOPPAN Ecquaria is an equal opportunity employer and values diversity within our company. We welcome all interested candidates to apply for this position, however, we regret to inform that only shortlisted candidates will be contacted by us for an interview.; Find us at www.topppanecquaria.com or www.linkedin.com/company/toppan-ecquaria; For more career opportunities, please visit our career site at:- https://toppanecquaria.com/careers/job-openings?utm_source=Jobstreet&utm_medium=Page&utm_campaign=2020 (Please copy & paste the above link onto your browser)",,Full time
85846361,Reporting and Analytics Developer/Data Engineer 0910,USER EXPERIENCE RESEARCHERS PTE. LTD,Singapore,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85846361,singapore,"We are seeking a highly skilled and experienced Big Data Engineer to join our team. The ideal candidate will have a minimum of 4 years of experience managing data engineering jobs in big data environment e.g., Cloudera Data Platform. The successful candidate will be responsible for designing, developing, and maintaining the data ingestion and processing jobs. The candidate will also be integrating data sets to provide seamless data access to users.; The developer is responsible to:; i. Analyse the Authority's data needs and document the requirements.; ii. Refine data collection/consumption by migrating data collection to more efficient channels; iii. Plan, design, and implement data engineering jobs and reporting solutions to meet the analytical needs.; iv. Develop test plan and scripts for system testing, support user acceptance testing.; v. Work with the Authority's technical teams to ensure smooth deployment and adoption of new solution.; vi. Ensure the smooth operations and service level of IT solutions.; vii. Support production issues; Skill Set and Track Record:; i. Tertiary Education in relevant fields is preferred.; ii. Good understanding and completion of projects using waterfall/Agile methodology.; iii. Analytical, conceptualisation and problem-solving skills.; iv. Good understanding of analytics and data warehouse implementations; v. Hands-on experience in big data engineering jobs using Python, Pyspark, Linux, and ETL tools like Informatica; vi. Strong SQL and data analysis skills. Hands-on experience in data virtualisation tools like Denodo will be an added advantage; vii. Hands-on experience in a reporting or visualization tool like SAP BO and Tableau is preferred; viii. Track record in implementing systems using Cloudera Data Platform will be an added advantage.; ix. Motivated and self-driven, with ability to learn new concepts and tools in a short period of time; x. Team player with ability to collaborate and work effectively within team; · Good written and verbal communication and interpersonal skills, ability to communicate confidently with stakeholders; xi. Passion for automation, standardization, and best practices; xii. Good presentation skills are preferred",,Full time
85865507,Senior Data Engineer - TEKsystems (Allegis Group Singapore Pte Ltd),Allegis Group Singapore Pte Ltd,Singapore,2025-07-18 07:18:41,https://id.jobstreet.com/id/job/85865507,singapore,"Optimize ETL/ELT processes for real-time and batch data processing; Ensure data quality, consistency, and lineage across enterprise systems; Work closely across functions teams to understand data needs and develop effective solutions; Job Summary; We are seeking an experienced data engineer where the candidate will focus on designing, building, and maintaining robust data pipelines, ensuring best practices are followed across engineering and governance; The ideal candidate is technically hands-on, understands the full data lifecycle, able to drive work independently and is driven by quality, scalability, and collaboration, with a strong openness and willingness to learn, adapt, and pick up new technologies as needed.; Responsibilities; • Design and develop scalable data pipelines to ingest, process, and store structured and unstructured data from internal and external sources.; • Optimize ETL/ELT processes for real-time and batch data processing.; • Ensure data quality, consistency, and lineage across enterprise systems.; • Work closely across functions teams to understand data needs and develop effective solutions.; • Enforce data governance policies to ensure compliance with industry regulations and internal standards.; • Provide guidance on best practices for data management and analytics to cross-functional teams.; Requirements; • Bachelor's Degree in relevant discipline.; • 5+ years of experience in data engineering; • Proven experience in designing and building data pipeline in Azure Synapse or Databricks; • Strong expertise in SQL, Python, or Scala for data processing and transformation.; • Proven experience in big data processing and working with technologies such as Apache Spark, Hadoop, Snowflake, Databricks, or AWS/GCP/Azure data platforms.; • Hands-on experience with ETL/ELT tools and modern data warehousing solutions.; • Experience in implementing data governance and security measures, with a strong understanding of how governance applies across the entire data pipeline to ensure quality, security and compliance.; • Experience with data modeling and data analytics is advantageous.; • Excellent communication and stakeholder management skills.; • Strong analytical and problem-solving skills with attention to detail.; • Detail-oriented and able to balance multiple tasks in a fast-paced environment.; • Ability to work independently and as part of a cross-functional team.; We regret to inform that only shortlisted candidates will be notified / contacted.; EA Registration No.: R21109465, Marshall Tan; Allegis Group Singapore Pte Ltd, Company Reg No. 200909448N, EA License No. 10C4544; information_technology",,Full time
85871664,Lead Big Data Engineer,The Great Eastern Life Assurance Company Limited,Central Region,2025-07-18 02:18:41,https://id.jobstreet.com/id/job/85871664,singapore,"We are seeking a skilled and detail-oriented Data Engineer to design, develop, and maintain robust data pipelines and ETL solutions. This role involves working closely with cross-functional teams to ensure data quality, scalability, and alignment with business and technical requirements.; Design, develop, test, and maintain scalable ETL pipelines to meet business, technical, and user requirements.; Collect, refine, and integrate new datasets. Maintain comprehensive documentation and data mappings across multiple systems.; Create optimized and scalable data models that align with organizational data architecture standards and best practices.; Conduct code reviews and perform rigorous testing to ensure high-quality deliverables.; Drive continuous improvement in data quality through optimization, testing, and solution design reviews.; Ensure all solutions conform to big data architecture guidelines and long-term roadmap.; Implement robust monitoring, logging, and alerting systems to ensure pipeline reliability and data accuracy.; Apply best practices in data engineering to design and build reliable data marts within the Hadoop ecosystem for planning, reporting, and analytics.; Maintain and optimize data pipelines to ensure data accuracy, integrity, and timeliness.; Manage code in a centralized repository with clear branching strategies and well-documented commit messages.; Coordinate with stakeholders to ensure smooth production deployment and adherence to data governance policies.; Proactively identify and implement improvements to data engineering processes and workflows.; Architect end-to-end solutions for insurance data modeling in the data warehouse, including data acquisition, contextualization, and integration with business processes.; Act as a business process owner for onboarding users and data products onto the data platform and pipelines supporting dashboards and statistical models.; Ensure adherence to development standards and perform periodic reviews to maintain pipeline performance and sustainability.; Coordinate and conduct testing with stakeholders to ensure effective deployment of data pipelines and dashboards.; Monitor data pipelines continuously and collaborate with stakeholders to troubleshoot and optimize performance.; We are looking for people who; Diploma with at least 10 years’ working experience, preferably in Life Insurance; Proven experience in data engineering, ETL development, and big data technologies; A strong team player who is meticulous, detail-oriented, and capable of performing under pressure; Proficiency in tools and platforms such as Hadoop, Spark, Hive, and cloud data services (e.g., AWS, Azure, GCP).; Possesses strong problem-solving and interpersonal skills.; Committed, dependable, and adaptable with the flexibility to support during peak periods and tight deadlines; Demonstrate high integrity, accountability, and a collaborative mindset; How you succeed; Champion and embody our Core Values in everyday tasks and interactions.; Demonstrate high level of integrity and accountability.; Take initiative to drive improvements and embrace change.; Take accountability of business and regulatory compliance risks, implementing measures to mitigate them effectively.; Keep abreast with industry trends, regulatory compliance, and emerging threats and technologies to understand and highlight potential concerns/ risks to safeguard our company proactively.; Who we are; Founded in 1908, Great Eastern is a well-established market leader and trusted brand in Singapore and Malaysia. With over S$100 billion in assets and more than 16 million policyholders, including 12.5 million from government schemes, it provides insurance solutions to customers through three successful distribution channels – a tied agency force, bancassurance, and financial advisory firm Great Eastern Financial Advisers. The Group also operates in Indonesia and Brunei. The Great Eastern Life Assurance Company Limited and Great Eastern General Insurance Limited have been assigned the financial strength and counterparty credit ratings of ""AA-"" by S&P Global Ratings since 2010, one of the highest among Asian life insurance companies. Great Eastern's asset management subsidiary, Lion Global Investors Limited, is one of the leading asset management companies in Southeast Asia. Great Eastern is a subsidiary of OCBC, the longest established Singapore bank, formed in 1932. It is the second largest financial services group in Southeast Asia by assets and one of the world’s most highly-rated banks, with an Aa1 rating from Moody’s and AA- by both Fitch and S&P. Recognised for its financial strength and stability, OCBC is consistently ranked among the World’s Top 50 Safest Banks by Global Finance and has been named Best Managed Bank in Singapore by The Asian Banker.",,Full time
85840488,Sr. Data Engineer,VISA WORLDWIDE PTE. LIMITED,Singapore,2025-07-17 20:18:41,https://id.jobstreet.com/id/job/85840488,singapore,"Company Description; Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid.; Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa.; Job Description; Visa’s Technology Organization is a community of problem solvers and innovators reshaping the future of commerce. We operate the world’s most sophisticated processing networks, capable of handling more than 65k secure transactions a second across 80M merchants, 15k Financial Institutions, and billions of everyday people. You’ll work on complex distributed systems and solve massive scale problems centered on new payment flows, business and data solutions, cybersecurity, and B2C platforms.; In addition, Value Added Services (VAS) - VAS Digital Marketing is a key growth strategy for Visa globally, aimed at diversifying Visa’s revenue with products and solutions that differentiate its network and deliver valuable solutions across other networks.; ; The Opportunity:; We are developing and executing a shared strategic vision for Digital Marketing platforms and products that enable Visa to be the world-leading data-driven payments company. As a Senior Data Engineer, you will be part of a world-class team of Engineers to define, drive and execute on this vision. We are looking for a self-motivated, versatile and energetic individual with software engineering skills and expertise with Java, Big data & Web technologies, who embraces solving complex challenges on a global scale. The candidate will be extensively involved in hands-on activities including POCs, design, development, testing, and managing applications globally used by Visa cardholders. Candidate must be flexible and willing to switch tasks based on team's needs.; ; You will use your Java skills and experience with various technologies to design, develop, test, and deploy high-quality code that meets stringent business, security, and resiliency requirements. You will collaborate with other teams, vendors, and stakeholders to ensure the smooth delivery and operation of the application. You will have the opportunity to learn and apply new technologies and frameworks, such as AI and generative AI, to enhance the functionality and performance of the application.; Primary responsibilities will include:; Design, develop, test, document, and implement new applications and enhance existing systems to ensure high performance and reliability.; Write secure, maintainable, and efficient code that adheres to Java/J2EE best practices, organizational and security standards.; Create and maintain comprehensive technical documentation, including design changes and architectural decisions, using Wiki or similar tools.; Participate in code and design review sessions to ensure high-quality deliverables and adherence to development standards.; Collaborate with architects, product owners, and technical stakeholders to deliver products that meet business requirements and leverage modern technologies.; Identify and recommend opportunities for process improvements, enhancements, and adoption of best practices within the development team.; Mentor and support junior developers, fostering knowledge sharing and contributing to the development of departmental procedures and standards.; Coordinate and contribute to Continuous Integration (CI) activities and the implementation of automated testing frameworks.; Develop proof-of-concepts (POCs) and prototypes to validate ideas and quickly iterate new features or enhancements.; Communicate technical solutions, project status, issues, and risks effectively to both technical and non-technical stakeholders.; Ensure the delivery of high-quality, defect-free code and take accountability for meeting project timelines and quality standards.; This is a hybrid position. Expectation of days in office will be confirmed by your Hiring Manager.; Qualifications; Preferred Qualifications; •3 or more years of work experience with a Bachelor’s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD); •4–7 years of relevant experience in Java/J2EE enterprise applications.; •Strong skills in Core Java, J2EE, Spring Framework, Spring Boot, Hibernate, and Web services.; •Proficiency in object-oriented design and software design principles.; •Experience with secure coding practices.; •Strong SQL skills with experience in relational (MySQL, PostgreSQL) and NoSQL (MongoDB) databases.; •Understanding of data warehousing concepts and tools.; •Exposure to data engineering frameworks such as Apache Spark, Hadoop, or Kafka is an advantage.; •Basic understanding of ETL processes and data pipeline development.; •Hands-on experience with containerization and orchestration tools (Docker, Kubernetes).; •Proficiency in version control systems (Git/Stash), build tools (Maven), and CI/CD tools (Jenkins).; •Familiarity with Unix/Linux operating systems and shell scripting.; •Experience with UI frameworks and frontend development using Angular or React, Next.js, JavaScript, HTML, and CSS.; •AI and generative AI skills are highly desirable.; •Experience working in all phases of the software development life cycle.; •Experience with Agile methodologies (Scrum, sprints) and tools (Jira).; •Understanding of DevOps practices.; •Solid foundation in computer science, including data structures and algorithms.; •Willingness to learn and improve coding skills, especially in Java or Scala.; Additional Information:; Skills/Abilities; •Strong analytical and problem-solving abilities.; •Quick to learn and adapt to new technologies and challenges.; •Excellent organizational skills with the ability to manage multiple tasks and deadlines in a fast-paced environment.; •Outstanding written and verbal communication skills for conveying ideas and implementation plans to team members and stakeholders.; •Highly detail-oriented, resourceful, and results-driven.; •Self-motivated with a demonstrated ability to work independently and meet commitments.; •Comfortable collaborating in dynamic, fast-paced, and highly interactive team settings.; •Eager to learn new skills, embrace new initiatives, and contribute to team success.; •Proven ability to maintain a positive attitude and have fun while working as part of a team.; Additional Information; Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",,Full time
85871688,INFRASTRUCTURE & SECURITY ENGINEER,Trusted Hub Ltd,Bedok,2025-07-18 02:18:41,https://id.jobstreet.com/id/job/85871688,singapore,"Responsibilities:; Install, configure, and maintain physical and virtual servers (latest Windows Server OS), network devices (switches, firewalls), and desktops/laptops in a secure, on-premise data center environment.; Manage and optimize the data center infrastructure, including physical rack organization, cabling, environmental controls, and power management.; Support and improve network infrastructure — including design, VLAN configuration, routing, switching, and firewall rules — to ensure performance, stability, and scalability.; Perform system and network hardening following industry standards (e.g., CIS Benchmarks) and security best practices.; Monitor system and network performance; troubleshoot and resolve infrastructure issues across servers, networks, storage, and endpoints.; Automate routine administrative tasks using PowerShell and scripting to improve operational efficiency and consistency.; Support and maintain infrastructure applications such as backup systems, antivirus, endpoint protection, monitoring tools, and logging platforms.; Manage and secure file transfer services (e.g., SFTP), ensuring encryption, access control, and policy enforcement.; Participate in or support the execution of patch management, upgrades, and server migrations (including off-hours or weekends when needed).; Deploy and maintain virtualization platforms including Hyper-V and VMware, including provisioning, resource allocation, and snapshots.; Assist in planning and executing infrastructure projects — including server refreshes, office IT deployments, and client site setups.; Provide Level 1 and Level 2 technical support for internal users and clients, and ensure all incidents and tasks are properly documented.; Collaborate with security stakeholders or vendors on vulnerability assessments and penetration testing (VAPT); assist in remediation and documentation.; Support compliance with data protection regulations (e.g., PDPA) and implement relevant technical and administrative controls.; Maintain documentation for infrastructure configurations, procedures, security policies, and incident reports.; Requirements:; Diploma or higher in Information Technology, Computer Engineering, or a related field.; Minimum 3 years of hands-on experience in IT infrastructure, data center, or systems/network administration roles.; Strong knowledge of Microsoft Windows Server (2016/2019/2022), Active Directory, DNS, DHCP, and Group Policy.; Experience managing virtualization platforms including Hyper-V and VMware in a production environment.; Proficiency in PowerShell scripting for task automation and system management.; Solid understanding of network architecture, VLANs, Layer 2/3 switching, routing, and firewall configurations.; Familiarity with infrastructure security hardening, patching, and applying CIS Benchmarks or other recognized security guidelines.; Experience implementing or supporting Vulnerability Assessment and Penetration Testing (VAPT) activities.; Familiarity with secure protocols such as SFTP, SSL/TLS, and concepts like least privilege and access control.; Able to work outside regular business hours (e.g., weekends or evenings) during critical maintenance windows or infrastructure rollouts.; Strong problem-solving skills and a professional, collaborative attitude.; Willing to travel occasionally for customer site support and deployment.; Added Advantages:; Able to work independently and as a team, being proactive with a mind for details and creative in trouble-shooting and problem-solving.; Demonstrate problem-solving skills or work improvements, especially with different approaches as well as leveraging usage of tools and/or AI.; Ability to source for solutions (software/hardware/hybrid) that are economical, timely and good.",,Full time
