{"Job_ID":"85838975","Role":"Data Engineer - ETL (MOH ITDG)","Company":"Synapxe","Location":"One North","Publish_Time":"2025-07-17 20:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85838975","country":"singapore","job_desc":"Company description:; ; Synapxe is the national HealthTech agency inspiring tomorrow's health. The nexus of HealthTech, we connect people and systems to power a healthier Singapore.; ; Together with partners, we create intelligent technological solutions to improve the health of millions of people every day, everywhere. Reimagine the future of health together with us at www.synapxe.sg; ; ; Job description:; ; Position Overview Role & Responsibilities; Develop TRUST data strategy:; Work with stakeholders to understand data analytics needs, data structure requirements (both in terms of scalability and accessibility), and translate this into a coherent near to long term data strategy for TRUST; Support translation of data business needs into technical system requirements for MCDR, in terms of collection, storage, batch -time processing, as well as analysis of information from structured and unstructured sources in a scalable, repeatable, and secure manner; Identify opportunities for improvements and optimisation e.g., Implement best practices and performance optimization on Big Data and Cloud to achieve the best data engineering outcomes; Oversee data preparation and data provisioning for TRUST:; Collaborate with data engineers to organise and prepare anonymised datasets in MCDR according to TRUST standards, and then providing the data in accordance with the approved TRUST Data Request. This involves working with the data engineers closely to ensure that the datasets meet the required standards and are made available as per the specific data request guidelines set by TRUST; Oversee implementation of common data model and data quality programme in TRUST and MCDR; Work with data analysts, data scientists, clinicians and other stakeholders to implement common data models to support analytics use cases; Design and implement tools to enhance the data strategy and enable seamless integration with the data, potentially leveraging API calls for efficient integration; Implement data management standards and practices; Requirements; Degree\/master's in computer science, Information Technology, Computer Engineering or equivalent; At least ten (10) years of relevant working experience in Data management \/ Integration \/ Modelling the data warehouse or advanced analytics solutions; Demonstrate good, in-depth knowledge in relevant Extract-Transform-Load (ETL) hardware\/software products, frameworks, and methodologies; Experience in designing and implementing cloud-based data solutions using cloud platforms (e.g., AWS cloud native tools); Databases (e.g., Oracle, MS SQL, MySQL, Teradata); Big data (e.g., Hadoop ecosystem); ETL development using ETL tools (e.g., Informatica, IBM DataStage, Talend); Data repository design (e.g., operational data stores, dimensional data stores, data marts); Experience in interacting with analytics stakeholders (economists, statisticians, clinicians, policy makers) on a business or domain level; Comfortable working independently to carry out data analysis, estimate data quality and sufficiency; Good interpersonal skills, a detail-oriented & flexible person who can work across different areas within the team; The following will be preferred: Some understanding of Singapore Healthcare System and healthcare data governance, management; and\/or familiarity with health informatics; Apply Now; NOTE: It only takes a few minutes to apply for a meaningful career in HealthTech - GO FOR IT!!; #LI-SYNX40","salary":"","work_type":"Full time"}
{"Job_ID":"85845116","Role":"Data Engineer & Reporting Developer","Company":"ALMR CONSULTING PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-17 20:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85845116","country":"singapore","job_desc":"Job Description; We are looking for a skilled Data Engineer & Reporting Developer with 3 to 10 years of experience in big data engineering and analytics. The ideal candidate will have a strong background in Python, PySpark, ETL, and reporting tools. You will be responsible for designing and building data pipelines, improving data collection, and delivering analytical solutions for business users.; Key Responsibilities; Analyse data needs and document business requirements.; Refine and migrate data collection to more efficient sources.; Plan, design, and implement data engineering jobs and reporting solutions.; Develop test plans, execute system testing, and support UAT.; Work closely with technical teams for deployment and adoption.; Ensure smooth operations and service levels.; Provide support for production issues.; Requirements; Degree in Computer Science, Information Systems, or related field preferred.; 3\u201310 years of experience in big data engineering.; Experience in Cloudera Data Platform is a plus.; Proficient in Python, PySpark, Linux, and ETL tools like Informatica.; Strong SQL and data analysis skills.; Experience with data virtualisation tools (e.g., Denodo) is a bonus.; Hands-on with reporting tools like SAP BO, Tableau.; Familiarity with Agile and Waterfall methodologies.; Strong communication and stakeholder management skills.; Self-driven, collaborative team player.","salary":"","work_type":"Kontrak\/Temporer"}
{"Job_ID":"85872576","Role":"Data Engineer","Company":"Exoduspoint Capital Management Singapore, Pte. Ltd.","Location":"Central Region","Publish_Time":"2025-07-18 09:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85872576","country":"singapore","job_desc":"ExodusPoint Capital, founded in 2017 by Michael Gelband, began managing investor capital in 2018. The firm employs a global multi-strategy investment approach, seeking to deliver compelling asymmetric returns by combining complementary liquid strategies managed by experienced investment professionals within a robust risk framework. ExodusPoint brings together an accomplished team with hands-on experience running multi-manager businesses to create an institutional investment management firm.; ExodusPoint is seeking an experienced Data Engineer with financial data knowledge to join an established data engineering team to help build a next generation data offering for ExodusPoint\u2019s diverse investment teams, varying across asset classes and strategies. The ideal candidate is a domain expert on financial datasets who has technical skills to work with business and create enterprise data assets utilizing advanced data processing techniques and tools.; The Enterprise Data group is focused on building a robust data platform which services a diverse set of investment teams and internal clients. The group consists of data sourcing experts, data product specialists, data scientists and data engineers, who are responsible for the discovery, management, and curation of thousands of alpha sources for the firm and our investment professionals.; Responsibilities:; \uf0d8 Build data sets using Python, SQL, Snowflake, Kafka, AWS, and other related technologies.; \uf0d8 Understand financial reference data sets from Bloomberg and\/or Refinitiv.; \uf0d8 Engage with vendors and technical teams to systematically ingest, evaluate, and create valuable data assets; \uf0d8 Engage with technical and non-technical clients as SME on data asset offerings; \uf0d8 Collaborate with core engineering team to create central capabilities to process, manage and distribute data assts at scale; \uf0d8 Apply robust data quality rules to systemically qualify data deliveries and guarantee the integrity of financial datasets; \uf0d8 Investigate and remediate domain-specific production issues escalated by the operations teams; \uf0d8 Enrich the central data catalog with advanced data profiling visualizations to enable discovery and evaluation; \uf0d8 Build up internal documentation and sample uses cases of the data sets; \uf0d8 Partner with data strategy and sourcing team on data requirements to design data pipelines and delivery structures.; Qualifications:; \uf0d8 Bachelor's degree in STEM; \uf0d8 +3 years of experience with programming in Python and\/or Java; \uf0d8 Experience working with security master, financial datasets and\/or enterprise financial vendor data products; \uf0d8 Familiar with SQL and\/or time-series database technologies; \uf0d8 Experience with data modeling, data warehousing, and building data pipelines; \uf0d8 Experience working with FTP, API, S3 and other distribution channels to source data; \uf0d8 Experience working on multiple projects and with different stakeholders; Desired Qualifications:; \uf0d8 Hands-on experience with AWS native data and compute technologies (S3, Lambda, Glue, DataSync, EMR, Athena, Lake Formation, Kinesis, etc.).; \uf0d8 Experience designing and working with APIs (REST, GraphQL, etc.).; \uf0d8 Experience with Apache Kafka or other data streaming technologies.; \uf0d8 Knowledge of developing containerized applications.; \uf0d8 Experience with JIRA and Agile project management.","salary":"","work_type":"Full time"}
{"Job_ID":"85848016","Role":"Senior Data engineer","Company":"Flintex Consulting Pte Ltd","Location":"City Hall","Publish_Time":"2025-07-17 22:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85848016","country":"singapore","job_desc":"Benefits: 13th Month Salary; Responsibilities; Integrate data from multiple sources, such as databases, APIs, or streaming platforms, to provide a unified view of the data; Implement data quality checks and validation processes to ensure the accuracy, completeness, and consistency of data; Identify and resolve data quality issues, monitor data pipelines for errors, and implement data governance and data quality frameworks; Enforce data security and compliance with relevant regulations and industry-specific standards; Implement data access controls, encryption mechanisms, and monitor data privacy and security risks; Optimise data processing and query performance by tuning database configurations, implementing indexing strategies, and leveraging distributed computing frameworks; Optimize data structures for efficient querying and develop data dictionaries and metadata repositories; Identify and resolve performance bottlenecks in data pipelines and systems; Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders; Document data pipelines, data schemas, and system configurations, making it easier for others to understand and work with the data infrastructure; Monitor data pipelines, databases, and data infrastructure for errors, performance issues, and system failures; Set up monitoring tools, alerts, and logging mechanisms to proactively identify and resolve issues to ensure the availability and reliability of data; It would be a plus if he has software engineering background; Requirements; Bachelor's or master's degree in computer science, information technology, data engineering, or a related field; Strong knowledge of databases, data structures, algorithms; Proficiency in working with data engineering tools and technologies including knowledge of data integration tools (e.g., Apache Kafka, Azure IoTHub, Azure EventHub), ETL\/ELT frameworks (e.g., Apache Spark, Azure Synapse), big data platforms (e.g., Apache Hadoop), and cloud platforms (e.g., Amazon Web Services, Google Cloud Platform, Microsoft Azure); Expertise in working with relational databases (e.g., MySQL, PostgreSQL, Azure SQL, Azure Data Explorer) and data warehousing concepts.; Familiarity with data modeling, schema design, indexing, and optimization techniques is valuable for building efficient and scalable data systems; Proficiency in languages such as Python, SQL, KQL, Java, and Scala; Experience with scripting languages like Bash or PowerShell for automation and system administration tasks; Strong knowledge of data processing frameworks like Apache Spark, Apache Flink, or Apache Beam for efficiently handling large-scale data processing and transformation tasks; Understanding of data serialization formats (e.g., JSON, Avro, Parquet) and data serialization libraries (e.g., Apache Avro, Apache Parquet) is valuable; Having experience in CI\/CD and GitHub that demonstrates ability to work in a collaborative and iterative development environment; Having experience in visualization tools (e.g. Power BI, Plotly, Grafana, Redash) is beneficial; Preferred Skills & Characteristics; Consistently display dynamic independent work habits, goal oriented, passionate in growth mindsets and self-motivated professional. Self-driven and proactive in keeping up with new technologies and programming","salary":"$6,000 \u2013 $9,000 per month (SGD)","work_type":"Full time"}
{"Job_ID":"85866045","Role":"Data Architect (2-year contract), IITS","Company":"Singapore Management University","Location":"Central Region","Publish_Time":"2025-07-18 08:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85866045","country":"singapore","job_desc":"This position is for Office of Integrated Information Technology Services (IITS).; Data Architecture; Create and maintain data architecture framework, standards and principles including modelling, metadata, security, master and reference data.; Data Analytics Solution Leadership; Lead BI Specialists, data scientists to build, support and continuously improve data analytics solutions in both day-to-day data management (BAU) activities and new project implementation.; Champion the good practices of enterprise-grade analytics solution design that promote standardization, scalability, integrability, reusability, resiliency, etc.; Data Analytics System Delivery Management; Work with data engineers, data scientists and other IT members in the implementation of analytics solutions.; Responsible for requirements analysis, design, development, testing, implementation and maintenance of enterprise-grade analytics system.; Effectively manage project timelines, resources, and deliverables to ensure successful project outcomes, aligning with organizational objectives.; Data Analytics System Support; Lead operational support for enterprise analytics systems, ensure high adoption and Customer Satisfaction (CSAT).; Establish necessary forums with stakeholders to define and execute in accordance to analytics solution roadmap.; Controls & Standards; Define, develop and promote BI & Analytics framework, standards, guidelines, procedures and practices.; Team Management; Take ownership and support team and while holding team accountable for their commitments, removing roadblocks to their work.; Leverage organizational resources to improve capacity for project work.; Mentor and develop team members.; Any other duties as assigned.; Qualifications; Degree or Diploma in Computer Science, Information Technology, or a related discipline.; Minimum 3 years' experience in architect and lead roles, showcasing proficiency in end-to-end BI solution design and architecture.; Must be technically competent with hands-on expertise in designing enterprise-grade BI solutions using Microsoft Power BI and\/or Qlik Sense.; Proficient in end-to-end analytics solutions and familiar with third normalization, dimensional modelling, ETL, visualization, statistical analysis and machine learning. Experience in cloud technologies, e.g. Azure, AWS, Google is advantageous.; Relevant certification in data management domain (e.g. DCAM, CDMP) is advantageous.; Good to be knowledgeable in AI and LLM.; Capable of assuming roles as project manager and business analyst, leading discussions from project initiation to planning and delivery of data and analytics projects.; Skilled at quickly assimilating ideas, techniques and information, translating complex requirements into clear and concise statements.; Well-versed in secure software development life cycle models, code versioning, release management, ticket management, CI\/CD, and disaster recovery planning. Experience in establishing these processes is advantageous.; Experienced in managing third-party vendors, particularly offshore partners, with a focus on project delivery initiatives.; Resourceful and able to work independently, demonstrating strong planning, organizational, and problem-solving skills to manage competing demands.; Ability to manage and prioritise work within a small team, and function as a strong individual contributor as well as team leader. The team is small, and strong performers must demonstrate their capability as a subject matter expert.; Excellent interpersonal, persuasive, and communication skills, with proficiency in both oral and written communication. Capable of collaborating effectively with individuals at various levels of the organization.; Other Information; #LI-XL1; Candidates who do not possess the stipulated qualifications but have relevant work experience may still apply. Remuneration and appointment terms shall commensurate with qualifications and experience. SMU reserves the right to modify the appointment terms where necessary.","salary":"","work_type":"Kontrak\/Temporer"}
{"Job_ID":"85866559","Role":"Associate Data Engineer - Datawarehouse (Engineering & Ops)","Company":"Synapxe","Location":"One North","Publish_Time":"2025-07-18 08:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85866559","country":"singapore","job_desc":"Position Overview; The Data Engineer supports the implementation of data structure and architecture, master\/meta-data management approach and data quality programme to facilitate access to data and information. He\/She support the design, implementation and maintenance of data flow channels and data processing systems that support the collection, storage, batch and real-time processing, and analysis of information from structured and unstructured sources in a scalable, repeatable and secure manner on on-premise or commercial cloud. He\/She implements data management standards and practices.; Role & Responsibilities; Manage and prioritize user queries and production issues for existing applications in Engineering and Operations; Track and resolve production support incidents; Attend user meetings to document and analyze change request requirements or conduct regular workgroup meetings with stakeholders; Perform data profiling and mapping to define data requirements for new projects or change requests; Provide support for production reports, dashboards, and metadata; Collaborate with vendors and developers to design, configure, and test enhancements per Synapxe project methodologies; Translate user requirements into analytics, reporting needs, and ETL rules for new data mart applications and enhancements; Identify and document business attributes and metrics by analyzing existing data and reporting requirements; Conduct technical data mapping for potential data warehouse sources; Execute testing phases (system integration testing, user acceptance testing) before implementation; Provide 24\/7 primary application maintenance support; Assist the Project Manager in assessing technical feasibility for cost evaluations; Requirements; Bachelor's degree in Computer Science, Information Technology, or a related field; At least 4 years of experience in the IT industry, including:; Development, implementation, and maintenance of IT systems, preferably in Data Warehousing, ETL rules, data modeling, and BI applications; Operations support and business analysis experience; Strong MS-SQL and Oracle Database scripting; Experience in diagnosing, troubleshooting, and performing root cause analysis; Ability to diagnose and troubleshoot problems with BI reports and ETL processes; Experience with AWS, Data Lake, Databricks, and the healthcare domain is a plus; Able to work independently and as an effective team player with a strong desire to deliver results; Adaptable, meticulous, and possess strong analytical skills; Good communication skills (both written and spoken); Strong team player; Apply Now; NOTE: It only takes a few minutes to apply for a meaningful career in HealthTech - GO FOR IT!!; #LI-SYNX40","salary":"","work_type":"Full time"}
{"Job_ID":"85871421","Role":"Data Architect (2-year contract), IITS","Company":"Singapore Management University","Location":"Singapore","Publish_Time":"2025-07-18 12:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85871421","country":"singapore","job_desc":"About Us; Singapore Management University is a place where high-level professionalism blends together with a healthy informality. The 'family-like' atmosphere among the SMU community fosters a culture where employees work, plan, organise and play together building a strong collegiality and morale within the university.; Our commitment to attract and retain talent is ongoing. We offer attractive benefits and welfare, competitive compensation packages, and generous professional development opportunities all to meet the work-life needs of our staff. No wonder, then, that SMU continues to be given numerous awards and recognition for its human resource excellence.; Job Description; This position is for Office of Integrated Information Technology Services (IITS).; Data Architecture; Create and maintain data architecture framework, standards and principles including modelling, metadata, security, master and reference data.; Data Analytics Solution Leadership; Lead BI Specialists, data scientists to build, support and continuously improve data analytics solutions in both day-to-day data management (BAU) activities and new project implementation.; Champion the good practices of enterprise-grade analytics solution design that promote standardization, scalability, integrability, reusability, resiliency, etc.; Data Analytics System Delivery Management; Work with data engineers, data scientists and other IT members in the implementation of analytics solutions.; Responsible for requirements analysis, design, development, testing, implementation and maintenance of enterprise-grade analytics system.; Effectively manage project timelines, resources, and deliverables to ensure successful project outcomes, aligning with organizational objectives.; Data Analytics System Support; Lead operational support for enterprise analytics systems, ensure high adoption and Customer Satisfaction (CSAT).; Establish necessary forums with stakeholders to define and execute in accordance to analytics solution roadmap.; Controls & Standards; Define, develop and promote BI & Analytics framework, standards, guidelines, procedures and practices.; Team Management; Take ownership and support team and while holding team accountable for their commitments, removing roadblocks to their work.; Leverage organizational resources to improve capacity for project work.; Mentor and develop team members.; Any other duties as assigned.; Qualifications; Degree or Diploma in Computer Science, Information Technology, or a related discipline.; Minimum 3 years' experience in architect and lead roles, showcasing proficiency in end-to-end BI solution design and architecture.; Must be technically competent with hands-on expertise in designing enterprise-grade BI solutions using Microsoft Power BI and\/or Qlik Sense.; Proficient in end-to-end analytics solutions and familiar with third normalization, dimensional modelling, ETL, visualization, statistical analysis and machine learning. Experience in cloud technologies, e.g. Azure, AWS, Google is advantageous.; Relevant certification in data management domain (e.g. DCAM, CDMP) is advantageous.; Good to be knowledgeable in AI and LLM.; Capable of assuming roles as project manager and business analyst, leading discussions from project initiation to planning and delivery of data and analytics projects.; Skilled at quickly assimilating ideas, techniques and information, translating complex requirements into clear and concise statements.; Well-versed in secure software development life cycle models, code versioning, release management, ticket management, CI\/CD, and disaster recovery planning. Experience in establishing these processes is advantageous.; Experienced in managing third-party vendors, particularly offshore partners, with a focus on project delivery initiatives.; Resourceful and able to work independently, demonstrating strong planning, organizational, and problem-solving skills to manage competing demands.; Ability to manage and prioritise work within a small team, and function as a strong individual contributor as well as team leader. The team is small, and strong performers must demonstrate their capability as a subject matter expert.; Excellent interpersonal, persuasive, and communication skills, with proficiency in both oral and written communication. Capable of collaborating effectively with individuals at various levels of the organization.; Other Information; #LI-XL1; Candidates who do not possess the stipulated qualifications but have relevant work experience may still apply. Remuneration and appointment terms shall commensurate with qualifications and experience. SMU reserves the right to modify the appointment terms where necessary.","salary":"","work_type":"Kontrak\/Temporer"}
{"Job_ID":"85846352","Role":"Data Engineer - ETL (MOH ITDG)","Company":"Synapxe","Location":"Singapore","Publish_Time":"2025-07-17 20:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85846352","country":"singapore","job_desc":"Develop TRUST data strategy:; Work with stakeholders to understand data analytics needs, data structure requirements (both in terms of scalability and accessibility), and translate this into a coherent near to long term data strategy for TRUST; Support translation of data business needs into technical system requirements for MCDR, in terms of collection, storage, batch -time processing, as well as analysis of information from structured and unstructured sources in a scalable, repeatable, and secure manner; Identify opportunities for improvements and optimisation e.g., Implement best practices and performance optimization on Big Data and Cloud to achieve the best data engineering outcomes; Oversee data preparation and data provisioning for TRUST:; Collaborate with data engineers to organise and prepare anonymised datasets in MCDR according to TRUST standards, and then providing the data in accordance with the approved TRUST Data Request. This involves working with the data engineers closely to ensure that the datasets meet the required standards and are made available as per the specific data request guidelines set by TRUST; Oversee implementation of common data model and data quality programme in TRUST and MCDR; Work with data analysts, data scientists, clinicians and other stakeholders to implement common data models to support analytics use cases; Design and implement tools to enhance the data strategy and enable seamless integration with the data, potentially leveraging API calls for efficient integration; Implement data management standards and practices","salary":"","work_type":"Full time"}
{"Job_ID":"85865507","Role":"Senior Data Engineer - TEKsystems (Allegis Group Singapore Pte Ltd)","Company":"Allegis Group Singapore Pte Ltd","Location":"Singapore","Publish_Time":"2025-07-18 08:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85865507","country":"singapore","job_desc":"Optimize ETL\/ELT processes for real-time and batch data processing; Ensure data quality, consistency, and lineage across enterprise systems; Work closely across functions teams to understand data needs and develop effective solutions; Job Summary; We are seeking an experienced data engineer where the candidate will focus on designing, building, and maintaining robust data pipelines, ensuring best practices are followed across engineering and governance; The ideal candidate is technically hands-on, understands the full data lifecycle, able to drive work independently and is driven by quality, scalability, and collaboration, with a strong openness and willingness to learn, adapt, and pick up new technologies as needed.; Responsibilities; \u2022 Design and develop scalable data pipelines to ingest, process, and store structured and unstructured data from internal and external sources.; \u2022 Optimize ETL\/ELT processes for real-time and batch data processing.; \u2022 Ensure data quality, consistency, and lineage across enterprise systems.; \u2022 Work closely across functions teams to understand data needs and develop effective solutions.; \u2022 Enforce data governance policies to ensure compliance with industry regulations and internal standards.; \u2022 Provide guidance on best practices for data management and analytics to cross-functional teams.; Requirements; \u2022 Bachelor's Degree in relevant discipline.; \u2022 5+ years of experience in data engineering; \u2022 Proven experience in designing and building data pipeline in Azure Synapse or Databricks; \u2022 Strong expertise in SQL, Python, or Scala for data processing and transformation.; \u2022 Proven experience in big data processing and working with technologies such as Apache Spark, Hadoop, Snowflake, Databricks, or AWS\/GCP\/Azure data platforms.; \u2022 Hands-on experience with ETL\/ELT tools and modern data warehousing solutions.; \u2022 Experience in implementing data governance and security measures, with a strong understanding of how governance applies across the entire data pipeline to ensure quality, security and compliance.; \u2022 Experience with data modeling and data analytics is advantageous.; \u2022 Excellent communication and stakeholder management skills.; \u2022 Strong analytical and problem-solving skills with attention to detail.; \u2022 Detail-oriented and able to balance multiple tasks in a fast-paced environment.; \u2022 Ability to work independently and as part of a cross-functional team.; We regret to inform that only shortlisted candidates will be notified \/ contacted.; EA Registration No.: R21109465, Marshall Tan; Allegis Group Singapore Pte Ltd, Company Reg No. 200909448N, EA License No. 10C4544; information_technology","salary":"","work_type":"Full time"}
{"Job_ID":"85845477","Role":"Data Engineer","Company":"TOPPAN Ecquaria Pte Ltd","Location":"Braddell","Publish_Time":"2025-07-17 20:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85845477","country":"singapore","job_desc":"Responsibilities:; Design and implement robust, scalable data pipelines and architectures to support data ingestion, processing, and storage. Including performance optimizations for data modeling and ingestion; Develop and optimize complex SQL queries and stored procedures for data extraction, transformation, and analysis.; Model data to meet different use casesng applications and automate data workflows.; Collaborate with data scientists and analysts to understand data requirements and deliver high-quality data solutions.; Lead the integration of data from various sources into data lakes and warehouses, ensuring data quality and consistency.; Monitor and troubleshoot data pipelines and workflows to ensure optimal performance and reliability.; Communicate with and support data users; Document data processes, data models, and architectural designs to ensure knowledge sharing and compliance with best practices.; Prerequisites:; Experience: Minimum 3 years in data engineering fields with system integration, and at least 1 year in system integration and implementation in cloud\/web-based environments.; Proven Solutions: Demonstrated experience in providing effective, working solutions and implementations, particularly in cloud-based environments.; Technical Skills:; Solid understanding of ETL processes, data warehousing concepts, and data modeling best practices.; Proficiency in Databricks, Azure Data lake, PowerBI, Tableau and related data processing and visualisation software.; Familiarity with Windows, Linux, AWS and\/or Azure platforms.; Strong programming skills in languages such as Python and R is a must; Proficiency in other programming languages such as Java, Scala and C# will be advantages; Experience in data processing frameworks (e.g., Apache Spark, Apache Flink); Preferred Exposure:; Experience with large-data management system with visualisation tools.; Experience with Data Integration and ETL Pipelines, Data Warehousing and BI reporting projects.; Experience with Singapore Government Project will be advantages; Personal Attributes:; Excellent problem-solving skills; Ability to work independently; Collaborative in a fast-paced environment; Why Join Us?; Be part of a forward-thinking team that is transforming government digital services. If you are passionate about technology and innovation, and thrive in a dynamic environment, we want to hear from you!; If you are passionate about building partnerships and driving growth, we would love to hear from you!; TOPPAN Ecquaria is an equal opportunity employer and values diversity within our company. We welcome all interested candidates to apply for this position, however, we regret to inform that only shortlisted candidates will be contacted by us for an interview.; Find us at www.topppanecquaria.com or www.linkedin.com\/company\/toppan-ecquaria; For more career opportunities, please visit our career site at:- https:\/\/toppanecquaria.com\/careers\/job-openings?utm_source=Jobstreet&utm_medium=Page&utm_campaign=2020 (Please copy & paste the above link onto your browser)","salary":"","work_type":"Full time"}
{"Job_ID":"85823545","Role":"Data Engineer","Company":"Innowave Tech Pte Ltd","Location":"Paya Lebar East","Publish_Time":"2025-07-17 20:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85823545","country":"singapore","job_desc":"About Innowave Tech Singapore ; Innowave Tech is an Artificial Intelligence (AI) company offering solutions for the Semiconductor and Advanced Manufacturing industry. Utilizing deep industrial domain knowledge, proven experience, and innovation, we provide expert AI solutions and systems to address various industry pain points. ;  Roles & Responsibilities ; We are seeking Data Engineer to establish and lead our data infrastructure. The successful candidate will be responsible for building our data engineering practice from the ground up, implementing robust data systems for industrial AI applications, and establishing best practices that will power our semiconductor manufacturing AI solutions. ;  Your Role and Impact ; As our first Data Engineer, you will have a foundational role in building robust data infrastructure to handle manufacturing data and LLM applications, while establishing secure data practices that power our AI solutions for advanced manufacturing operations. ;  What You\u2019ll Do ; Select and manage on-premises technologies suitable for secure and efficient operations. ; Build robust pipelines to collect, clean, and transform diverse datasets including process data, sensor data, image data, and human annotations. ; Ensure secure, maintainable, and scalable deployment of data infrastructure. ; Define and enforce best practices in data governance, privacy, and access control. ; Collaboration & Deployment. ;  What We\u2019re Looking For ; Educational Background: ; Minimum Poly or Bachelor Degree in Computer Science, Engineering, or a related field. ; * We welcome applications from Singapore Citizens, Permanent Residents (PRs), Malaysians, and local graduates bonded for local employment, in accordance with MoM regulations.;  Technical Expertise: ; 3+ years of experience in data engineering roles, ideally with on-premises or hybrid infrastructure. ; Proven track record of building scalable data systems from ground up in a startup environment. ; Proficiency in Python and\/or Java for data pipeline development. ; Solid experience with ETL frameworks (e.g., Apache Airflow, Dagster) and streaming systems (e.g., Kafka). ; Experience designing and maintaining SQL and NoSQL databases. ; Experience building and operating data lakes and data catalog. ; Familiarity with containerization (Docker), version control (Git), and CI\/CD practices. ;  Soft Skills: ; Excellent communication skills and ability to collaborate with cross-functional technical and non-technical teams. ; Excellent problem-solving and debugging abilities. ; Ability to balance engineering tradeoffs. ;  Bonus Skills: ; Experience with manufacturing data systems, especially SPC, SCADA, and industrial sensor protocols (e.g., OPC UA, MQTT, Modbus). ; Familiarity with AI\/ML pipelines and tools (e.g., MLflow). ; Knowledge in vector databases and LLM data infrastructure. ; Prior experience working in or with regulated industries (e.g., semiconductor, automotive, aerospace). ; What we Offer ; \u2022 A leading role in cutting-edge AI projects within the semiconductor industry. ; \u2022 The opportunity to work with an learn from experts in the field of AI and data science. ; \u2022 A dynamic, innovative, and supportive work environment. ; \u2022 Competitive salary and benefits package. ; \u2022 Career growth opportunities in a fast-paces technology company.","salary":"$5,333 \u2013 $8,000 per month (SGD)","work_type":"Full time"}
{"Job_ID":"85871664","Role":"Lead Big Data Engineer","Company":"The Great Eastern Life Assurance Company Limited","Location":"Central Region","Publish_Time":"2025-07-18 03:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85871664","country":"singapore","job_desc":"We are seeking a skilled and detail-oriented Data Engineer to design, develop, and maintain robust data pipelines and ETL solutions. This role involves working closely with cross-functional teams to ensure data quality, scalability, and alignment with business and technical requirements.; Design, develop, test, and maintain scalable ETL pipelines to meet business, technical, and user requirements.; Collect, refine, and integrate new datasets. Maintain comprehensive documentation and data mappings across multiple systems.; Create optimized and scalable data models that align with organizational data architecture standards and best practices.; Conduct code reviews and perform rigorous testing to ensure high-quality deliverables.; Drive continuous improvement in data quality through optimization, testing, and solution design reviews.; Ensure all solutions conform to big data architecture guidelines and long-term roadmap.; Implement robust monitoring, logging, and alerting systems to ensure pipeline reliability and data accuracy.; Apply best practices in data engineering to design and build reliable data marts within the Hadoop ecosystem for planning, reporting, and analytics.; Maintain and optimize data pipelines to ensure data accuracy, integrity, and timeliness.; Manage code in a centralized repository with clear branching strategies and well-documented commit messages.; Coordinate with stakeholders to ensure smooth production deployment and adherence to data governance policies.; Proactively identify and implement improvements to data engineering processes and workflows.; Architect end-to-end solutions for insurance data modeling in the data warehouse, including data acquisition, contextualization, and integration with business processes.; Act as a business process owner for onboarding users and data products onto the data platform and pipelines supporting dashboards and statistical models.; Ensure adherence to development standards and perform periodic reviews to maintain pipeline performance and sustainability.; Coordinate and conduct testing with stakeholders to ensure effective deployment of data pipelines and dashboards.; Monitor data pipelines continuously and collaborate with stakeholders to troubleshoot and optimize performance.; We are looking for people who; Diploma with at least 10 years\u2019 working experience, preferably in Life Insurance; Proven experience in data engineering, ETL development, and big data technologies; A strong team player who is meticulous, detail-oriented, and capable of performing under pressure; Proficiency in tools and platforms such as Hadoop, Spark, Hive, and cloud data services (e.g., AWS, Azure, GCP).; Possesses strong problem-solving and interpersonal skills.; Committed, dependable, and adaptable with the flexibility to support during peak periods and tight deadlines; Demonstrate high integrity, accountability, and a collaborative mindset; How you succeed; Champion and embody our Core Values in everyday tasks and interactions.; Demonstrate high level of integrity and accountability.; Take initiative to drive improvements and embrace change.; Take accountability of business and regulatory compliance risks, implementing measures to mitigate them effectively.; Keep abreast with industry trends, regulatory compliance, and emerging threats and technologies to understand and highlight potential concerns\/ risks to safeguard our company proactively.; Who we are; Founded in 1908, Great Eastern is a well-established market leader and trusted brand in Singapore and Malaysia. With over S$100 billion in assets and more than 16 million policyholders, including 12.5 million from government schemes, it provides insurance solutions to customers through three successful distribution channels \u2013 a tied agency force, bancassurance, and financial advisory firm Great Eastern Financial Advisers. The Group also operates in Indonesia and Brunei. The Great Eastern Life Assurance Company Limited and Great Eastern General Insurance Limited have been assigned the financial strength and counterparty credit ratings of \"AA-\" by S&P Global Ratings since 2010, one of the highest among Asian life insurance companies. Great Eastern's asset management subsidiary, Lion Global Investors Limited, is one of the leading asset management companies in Southeast Asia. Great Eastern is a subsidiary of OCBC, the longest established Singapore bank, formed in 1932. It is the second largest financial services group in Southeast Asia by assets and one of the world\u2019s most highly-rated banks, with an Aa1 rating from Moody\u2019s and AA- by both Fitch and S&P. Recognised for its financial strength and stability, OCBC is consistently ranked among the World\u2019s Top 50 Safest Banks by Global Finance and has been named Best Managed Bank in Singapore by The Asian Banker.","salary":"","work_type":"Full time"}
{"Job_ID":"85873741","Role":"Big Data Engineer (Libra) - Data Platform","Company":"BYTEDANCE PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-18 15:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85873741","country":"singapore","job_desc":"Big Data Engineer (Libra) - Data Platform; Singapore Regular R&D Job ID: A220563; Responsibilities; About the team Libra is a large-scale online one-stop A\/B testing platform developed by Data Platform. Some of its features include:; Provides experimental evaluation services for all product lines within the company, covering solutions for complex scenarios such as recommendation, algorithm, function, UI, marketing, advertising, operation, social isolation, causal inference, etc.; Provides services throughout the entire experimental lifecycle from experimental design, experimental creation, indicator calculation, statistical analysis to final evaluation launch.; Supports the entire company's business on the road of rapid iterative trial and error, boldly assuming and carefully verifying.; Responsibilities; Responsible for data system of experimentation platform operation and maintenance.; Construct PB-level data warehouses, participate in and be responsible for data warehouse design, modeling, and development, etc.; Build ETL data pipelines and automated ETL data pipeline systems.; Build an expert system for metric data processing that combines offline and real-time processing.; Qualifications; Minimum Qualifications; Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience.; Proficiency with big data frameworks such as Presto, Hive, Spark, Flink, Clickhouse, Hadoop, and have experience in large-scale data processing.; Minimum 1 year of experience in Data Engineering.; Experience writing code in Java, Scala, SQL, Python or a similar language.; Experience with data warehouse implementation methodologies, and have supported actual business scenarios.; Preferred Qualifications; Knowledge about a variety of strategies for ingesting, modeling, processing, and persisting data, ETL design, job scheduling and dimensional modeling.; Expertise in designing, analyzing, and troubleshooting large-scale distributed systems is a plus (Hadoop, M\/R, Hive, Spark, Presto, Flume, Kafka, ClickHouse, Flink or comparable solutions).; Work\/internship experience in internet companies, and those with big data processing experience are preferred.; Job Information; Inspiring creativity is at the core of ByteDance's mission. Our innovative products are built to help people authentically express themselves, discover and connect \u2013 and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and enrich life - a mission we work towards every day.; As ByteDancers, we strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. By constantly iterating and fostering an \"Always Day 1\" mindset, we achieve meaningful breakthroughs for ourselves, our Company, and our users. When we create and grow together, the possibilities are limitless. Join us.; Diversity & Inclusion; ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Apply; Share to","salary":"","work_type":"Full time"}
{"Job_ID":"85846361","Role":"Reporting and Analytics Developer\/Data Engineer 0910","Company":"USER EXPERIENCE RESEARCHERS PTE. LTD","Location":"Singapore","Publish_Time":"2025-07-17 20:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85846361","country":"singapore","job_desc":"We are seeking a highly skilled and experienced Big Data Engineer to join our team. The ideal candidate will have a minimum of 4 years of experience managing data engineering jobs in big data environment e.g., Cloudera Data Platform. The successful candidate will be responsible for designing, developing, and maintaining the data ingestion and processing jobs. The candidate will also be integrating data sets to provide seamless data access to users.; The developer is responsible to:; i. Analyse the Authority's data needs and document the requirements.; ii. Refine data collection\/consumption by migrating data collection to more efficient channels; iii. Plan, design, and implement data engineering jobs and reporting solutions to meet the analytical needs.; iv. Develop test plan and scripts for system testing, support user acceptance testing.; v. Work with the Authority's technical teams to ensure smooth deployment and adoption of new solution.; vi. Ensure the smooth operations and service level of IT solutions.; vii. Support production issues; Skill Set and Track Record:; i. Tertiary Education in relevant fields is preferred.; ii. Good understanding and completion of projects using waterfall\/Agile methodology.; iii. Analytical, conceptualisation and problem-solving skills.; iv. Good understanding of analytics and data warehouse implementations; v. Hands-on experience in big data engineering jobs using Python, Pyspark, Linux, and ETL tools like Informatica; vi. Strong SQL and data analysis skills. Hands-on experience in data virtualisation tools like Denodo will be an added advantage; vii. Hands-on experience in a reporting or visualization tool like SAP BO and Tableau is preferred; viii. Track record in implementing systems using Cloudera Data Platform will be an added advantage.; ix. Motivated and self-driven, with ability to learn new concepts and tools in a short period of time; x. Team player with ability to collaborate and work effectively within team; \u00b7 Good written and verbal communication and interpersonal skills, ability to communicate confidently with stakeholders; xi. Passion for automation, standardization, and best practices; xii. Good presentation skills are preferred","salary":"","work_type":"Full time"}
{"Job_ID":"85840488","Role":"Sr. Data Engineer","Company":"VISA WORLDWIDE PTE. LIMITED","Location":"Singapore","Publish_Time":"2025-07-17 20:18:40","URL":"https:\/\/id.jobstreet.com\/id\/job\/85840488","country":"singapore","job_desc":"Company Description; Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose \u2013 to uplift everyone, everywhere by being the best way to pay and be paid.; Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa.; Job Description; Visa\u2019s Technology Organization is a community of problem solvers and innovators reshaping the future of commerce. We operate the world\u2019s most sophisticated processing networks, capable of handling more than 65k secure transactions a second across 80M merchants, 15k Financial Institutions, and billions of everyday people. You\u2019ll work on complex distributed systems and solve massive scale problems centered on new payment flows, business and data solutions, cybersecurity, and B2C platforms.; In addition, Value Added Services (VAS) - VAS Digital Marketing is a key growth strategy for Visa globally, aimed at diversifying Visa\u2019s revenue with products and solutions that differentiate its network and deliver valuable solutions across other networks.; ; The Opportunity:; We are developing and executing a shared strategic vision for Digital Marketing platforms and products that enable Visa to be the world-leading data-driven payments company. As a Senior Data Engineer, you will be part of a world-class team of Engineers to define, drive and execute on this vision. We are looking for a self-motivated, versatile and energetic individual with software engineering skills and expertise with Java, Big data & Web technologies, who embraces solving complex challenges on a global scale. The candidate will be extensively involved in hands-on activities including POCs, design, development, testing, and managing applications globally used by Visa cardholders. Candidate must be flexible and willing to switch tasks based on team's needs.; ; You will use your Java skills and experience with various technologies to design, develop, test, and deploy high-quality code that meets stringent business, security, and resiliency requirements. You will collaborate with other teams, vendors, and stakeholders to ensure the smooth delivery and operation of the application. You will have the opportunity to learn and apply new technologies and frameworks, such as AI and generative AI, to enhance the functionality and performance of the application.; Primary responsibilities will include:; Design, develop, test, document, and implement new applications and enhance existing systems to ensure high performance and reliability.; Write secure, maintainable, and efficient code that adheres to Java\/J2EE best practices, organizational and security standards.; Create and maintain comprehensive technical documentation, including design changes and architectural decisions, using Wiki or similar tools.; Participate in code and design review sessions to ensure high-quality deliverables and adherence to development standards.; Collaborate with architects, product owners, and technical stakeholders to deliver products that meet business requirements and leverage modern technologies.; Identify and recommend opportunities for process improvements, enhancements, and adoption of best practices within the development team.; Mentor and support junior developers, fostering knowledge sharing and contributing to the development of departmental procedures and standards.; Coordinate and contribute to Continuous Integration (CI) activities and the implementation of automated testing frameworks.; Develop proof-of-concepts (POCs) and prototypes to validate ideas and quickly iterate new features or enhancements.; Communicate technical solutions, project status, issues, and risks effectively to both technical and non-technical stakeholders.; Ensure the delivery of high-quality, defect-free code and take accountability for meeting project timelines and quality standards.; This is a hybrid position. Expectation of days in office will be confirmed by your Hiring Manager.; Qualifications; Preferred Qualifications; \u20223 or more years of work experience with a Bachelor\u2019s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD); \u20224\u20137 years of relevant experience in Java\/J2EE enterprise applications.; \u2022Strong skills in Core Java, J2EE, Spring Framework, Spring Boot, Hibernate, and Web services.; \u2022Proficiency in object-oriented design and software design principles.; \u2022Experience with secure coding practices.; \u2022Strong SQL skills with experience in relational (MySQL, PostgreSQL) and NoSQL (MongoDB) databases.; \u2022Understanding of data warehousing concepts and tools.; \u2022Exposure to data engineering frameworks such as Apache Spark, Hadoop, or Kafka is an advantage.; \u2022Basic understanding of ETL processes and data pipeline development.; \u2022Hands-on experience with containerization and orchestration tools (Docker, Kubernetes).; \u2022Proficiency in version control systems (Git\/Stash), build tools (Maven), and CI\/CD tools (Jenkins).; \u2022Familiarity with Unix\/Linux operating systems and shell scripting.; \u2022Experience with UI frameworks and frontend development using Angular or React, Next.js, JavaScript, HTML, and CSS.; \u2022AI and generative AI skills are highly desirable.; \u2022Experience working in all phases of the software development life cycle.; \u2022Experience with Agile methodologies (Scrum, sprints) and tools (Jira).; \u2022Understanding of DevOps practices.; \u2022Solid foundation in computer science, including data structures and algorithms.; \u2022Willingness to learn and improve coding skills, especially in Java or Scala.; Additional Information:; Skills\/Abilities; \u2022Strong analytical and problem-solving abilities.; \u2022Quick to learn and adapt to new technologies and challenges.; \u2022Excellent organizational skills with the ability to manage multiple tasks and deadlines in a fast-paced environment.; \u2022Outstanding written and verbal communication skills for conveying ideas and implementation plans to team members and stakeholders.; \u2022Highly detail-oriented, resourceful, and results-driven.; \u2022Self-motivated with a demonstrated ability to work independently and meet commitments.; \u2022Comfortable collaborating in dynamic, fast-paced, and highly interactive team settings.; \u2022Eager to learn new skills, embrace new initiatives, and contribute to team success.; \u2022Proven ability to maintain a positive attitude and have fun while working as part of a team.; Additional Information; Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","salary":"","work_type":"Full time"}
