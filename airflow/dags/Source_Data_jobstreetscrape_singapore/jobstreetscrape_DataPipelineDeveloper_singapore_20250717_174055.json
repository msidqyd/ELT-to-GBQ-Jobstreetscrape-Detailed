{"Job_ID":"85074940","Role":"Senior Application & Data Engineer","Company":"BRC GLOBAL ROLLS PTE. LTD.-","Location":"Downtown Tanjong Pagar","Publish_Time":"2025-06-21 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85074940","job_desc":"The Senior Application & Data Engineer is responsible for Identifying, designing, and implementing process improvements that include building\/re-engineering data models, data architectures, pipelines, and data applications. Continuously look for data optimization processes and oversee data management, governance, security, and analysis.; Job Responsibilities:; Lead the development and optimization of our data pipelines, databases, and systems for serving data to our customers, ensuring scalability, efficiency, and reliability.; Work in close collaboration with stakeholders and analysts to design and implement robust data models.; Drive innovation by staying updated with the latest in data engineering practices, tools, and technologies, applying them to solve complex business and data challenges.; Design, construct, install, test and maintain a highly scalable data platform.; Analyze business requirements and create conceptual, logical, and physical data models.; Design database tables, columns, and relationships, and document data flow and dependencies.; Build high-performance algorithms, prototypes, models and proof of concepts.; Develop data set processes for data modeling, mining, and production.; Integrate new data management technologies and software engineering tools into existing structures.; Research opportunities for data acquisition and new uses for existing data for reporting.; Create custom software components and analytics applications.; Collaborate with IT team members on project and technology related goals.; Job Requirements:; Degree in Computer Science\/Information Technology or equivalent data-related fields, such as data science, data engineering, data management, data governance, data analytics etc; Minimum 5 years of relevant experience in areas such as data management, engineering, extract, transfer and load data.; Strong SQL skills, on MS SQL server environment, for querying and managing data.; Proficiency in Python and SQL.; Strong understanding of object-oriented programming (OOP) and design patterns.; Proficiency in programming languages such as .NET and Python.; Experience with software development frameworks and libraries.; Familiarity with version control systems such as Git or Azure Devops.; Knowledge of software testing and debugging methodologies.; Ability to write clean, maintainable, and efficient code.; Experience with agile development methodologies.; Skills in systems problem-solving and conflict resolution.; Ability to work as part of a team, independently and make decisions.; Artificial Intelligence on LLM\/RAG knowledge will be an advantage.; Ethical and able to organize and complete tasks to expected standards and on-time.; Trustworthy and accountable to deliver quality results.; Adaptability to changing requirements and circumstances.; Strong written and verbal communication skills; Ability to manage time effectively.; Ability to travel and take on short overseas assignments on an as needed basis.","salary":"$6,000 \u2013 $9,000 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85845116","Role":"Data Engineer & Reporting Developer","Company":"ALMR CONSULTING PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-17 05:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85845116","job_desc":"Job Description; We are looking for a skilled Data Engineer & Reporting Developer with 3 to 10 years of experience in big data engineering and analytics. The ideal candidate will have a strong background in Python, PySpark, ETL, and reporting tools. You will be responsible for designing and building data pipelines, improving data collection, and delivering analytical solutions for business users.; Key Responsibilities; Analyse data needs and document business requirements.; Refine and migrate data collection to more efficient sources.; Plan, design, and implement data engineering jobs and reporting solutions.; Develop test plans, execute system testing, and support UAT.; Work closely with technical teams for deployment and adoption.; Ensure smooth operations and service levels.; Provide support for production issues.; Requirements; Degree in Computer Science, Information Systems, or related field preferred.; 3\u201310 years of experience in big data engineering.; Experience in Cloudera Data Platform is a plus.; Proficient in Python, PySpark, Linux, and ETL tools like Informatica.; Strong SQL and data analysis skills.; Experience with data virtualisation tools (e.g., Denodo) is a bonus.; Hands-on with reporting tools like SAP BO, Tableau.; Familiarity with Agile and Waterfall methodologies.; Strong communication and stakeholder management skills.; Self-driven, collaborative team player.","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85570215","Role":"Contract - Data Engineer [AI Data Pipeline] (1 year)","Company":"Infineon Technologies","Location":"Kallang","Publish_Time":"2025-07-08 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85570215","job_desc":"#WeAreIn for driving decarbonization and digitalization.; As a global leader in semiconductor solutions in power systems and IoT, Infineon enables game-changing solutions for green and efficient energy, clean and safe mobility, as well as smart and secure IoT. Together, we drive innovation and customer success, while caring for our people and empowering them to reach ambitious goals. Be a part of making life easier, safer and greener.; Are you in?; ; We are on a journey to create the best Infineon for everyone.; This means we embrace diversity and inclusion and welcome everyone for who they are. At Infineon, we offer a working environment characterized by trust, openness, respect and tolerance and are committed to give all applicants and employees equal opportunities. We base our recruiting decisions on the applicant\u00b4s experience and skills.; Please let your recruiter know if they need to pay special attention to something in order to enable your participation in the interview process.; Click here for more information about Diversity & Inclusion at Infineon.; The Data Engineer will serve as a technical expert in the fields of design and develop AI data pipelines to manage both large unstructured and structured datasets, with a particular focus on GenAI RAG\/Agent solutions.; ; In your new role you will:; Working closely with data scientists and domain experts to design and develop AI data pipelines using agile development process.; Developing pipelines for ingesting and processing large unstructured and structured datasets from a variety of sources, ensure efficient and effective data processing.; Development of BIA solution using defined framework for Data Modelling; Data Profiling; Data Extraction, Transformation & Loading; Design and provide data\/information in form of reports, dashboards, scorecards and data storytelling using Visualization Tools such as Business Objects & Tableau.; Work with cloud technologies such as AWS to design and implement scalable data architectures; Supporting the operation of the data pipelines involves troubleshooting and bug fixing, as well as implementing change requests to ensure that the data pipelines continue to meet user requirements.; You are best equipped for this task if you have:; Master's or Bachelor's Degree in Computer Science\/Mathematics\/ Statistics or equivalent.; Minimum of 3 years of relevant work experience in data engineering, including in-depth technical knowledge of databases, BI tools, SQL, OLAP, ETL, RAG \/ Agentic Data pipeline.; Proficient in RDBMS: Oracle\/PL SQL; Extensive hands-on experience in conceptualising, designing, and implementing data pipelines. Proficiency in handling unstructured data formats (e.g., PPT, PDF, Docx), databases (RDMS, NoSQL such as Elasticsearch, MongoDB, Neo4j, CEPH) and familiarity with big data platforms (HDFS, Spark, Impala).; Experience in working with AWS technologies focusing on building scalable data pipelines.; Front-end Reporting & Dashboard and Data Exploration tools -Tableau; Strong background in Software Engineering & Development cycles (CI\/CD) with proficiency in scripting languages, particularly Python.; Good understanding and experience with Kubernetes \/ Openshift Platform.; Other Skills \/ Attributes:; Good understanding of data management, data governance, and data security practices.; Highly motivated, structured and methodical with high degree of self-initiative; Team player with good cross-cultural skills to work in an international team; Customer and result-oriented; This is a 12 months contract under 3rd party payroll partner and entitled to benefits according to partner company","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"75168122","Role":"Senior\/ Data Engineer - DSC\/EZ","Company":"ST Engineering Mission Software & Services Pte Ltd","Location":"North-East Region","Publish_Time":"2025-07-06 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/75168122","job_desc":"About our Line of Business \u2013 Mission Software & Services; Our Mission Software & Services business provides leading-edge mission critical command, control, and communications (C3) systems with secured IT infrastructure and managed services. We support our client\u2019s innovation journey through design thinking, analytics, and AI-enabled decision support with our full suite of cloud computing solutions. We provide intelligent, actionable insights and sustainable solutions to our valued partners in diverse industries including defence, government, and commercial sectors.; ; Together, We Can Make A Significant Impact; The Data Engineer supports the design, implementation and maintenance of data flow channels and data processing systems that support the collection, storage, batch and real-time processing, and analysis of information in a scalable, repeatable and secure manner. The Data Engineer focuses on defining optimal solutions to data collection, processing and warehousing. He \/ She designs, codes and tests data systems and works on implementing those into the internal infrastructure.; Be Part of Our Success; Work with stakeholders including customers, partners and colleagues on data-related technical issues and support their data infrastructure needs;; Work closely with data scientists to solicit data requirements to support modeling works; Design, develop, document, manage and maintain data models, ETL processes, data warehouse, data management and pipeline solutions for large volume of structured\/unstructured data from disparate sources and with different latencies (e.g. on-demand, batch, real-time, near-real-time);; Define, monitor and report SLAs for data pipelines and data products;; Understand data security and governance standards or requirements to implement solutions that ensure adherence to these standards or meet such requirements;; Drive\/execute data quality assurance practices; and; Support data management solutions pre-sales initiatives, proposal development and provide post-sales support.; Qualities We Value; In-depth technical knowledge in:; Data Modelling;; Data Pipelines;; OLAP;; Data Ingestion & Integration techonlogies;; Query Optimisation; Technical expertise in:; Java, C\/C++, Python, Scala, SQL etc.; Big data technologies e.g. Hadoop, Spark, Hive, HBase etc.; Experience in master data management, data governance, data lifecycle management etc.;; Experience in designing, documenting, implementing and supporting data management solutions;; Experience in using software engineering best practices in development, programming, testing, version control etc.;; Knowledge of data privacy and security assurance;","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85034742","Role":"Junior Data Engineer (Python \/ JAVA \/ SQL)","Company":"Vanguard Software Pte Ltd","Location":"Central Region","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85034742","job_desc":"JOB SUMMARY:; We\u2019re looking for a Data Engineer to join our growing data team. This role is open to fresh graduates and early-career professionals (1\u20132 years of experience) who are excited about building data pipelines, transforming raw data into meaningful insights, and working with modern data technologies. You'll collaborate with data analysts, software engineers, and product teams to ensure that data flows smoothly across our systems and is reliable, secure, and accessible.; Whether you\u2019re just starting out or already have some experience, this is a great opportunity to develop your data engineering skills and contribute to impactful, data-driven decision-making.; ; KEY RESPONSIBILITIES:; Design, develop, and maintain scalable data pipelines and ETL\/ELT workflows; Clean, transform, and optimize raw data for storage and analysis; Work with structured and unstructured data from various sources (databases, APIs, files, etc.); Ensure data quality, accuracy, consistency, and availability; Support data infrastructure (e.g., data lakes, data warehouses) and performance tuning; Collaborate with analysts, data scientists, and backend teams; Document data models, processes, and technical decisions; What You\u2019ll Learn; Real-world data engineering with modern tools like Apache Spark\/Flink, Kafka, Airflow; Working with SQL\/NoSQL databases, data lakes, and cloud platforms (AWS, GCP, Azure); Building batch and streaming data pipelines; Data modeling, warehousing; Orchestration and monitoring of data workflows; Best practices in data governance, privacy, and security; Collaboration in agile, cross-functional teams with product, engineering, and analytics; JOB REQUIREMENTS:; \ud83c\udf93For Fresh Graduates; Bachelor\u2019s degree in Computer Science, Data Engineering, Software Engineering, or a related field (or graduating soon); Understanding of SQL and at least one programming language (Python preferred); Exposure to data concepts through coursework, internships, or projects; Eagerness to work with large datasets and cloud-based data platforms; Willingness to learn new tools and follow team best practices; \ud83d\udcbc For 1\u20132 Years Experience; 1\u20132 years of experience in data engineering, backend development, or analytics engineering; Proficient in SQL and Python; Familiar with ETL tools, data pipeline design, and version control (Git); Experience with cloud services (e.g., S3, Lambda, Cloud Functions, or GCP Dataflow); Able to troubleshoot data issues and build scalable data solutions; Nice to Have (For All Levels); Experience with data orchestration tools (Airflow, Prefect, Dagster, etc.); Familiarity with big data tools (Spark, Kafka, Hadoop); Exposure to data visualization tools (e.g., Looker, Tableau); Understanding of CI\/CD, containerization (Docker), and infrastructure-as-code; Contributions to personal or open-source data projects; Knowledge of data privacy and compliance (GDPR, HIPAA, etc.); Soft Skills; Analytical mindset and strong attention to detail; Team player with good communication skills; Open to feedback and continuous improvement; Responsible and proactive in solving data challenges; Eagerness to explore new tools and share knowledge; What We Offer; Structured onboarding and mentorship to grow your data skills; Opportunities to work on real-world data systems with production impact; A collaborative, knowledge-sharing team culture; Clear growth paths toward analytics engineering, senior data engineering, or data platform roles","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85763140","Role":"Data Engineer - Contract","Company":"Manpower Staffing Services (S) Pte Ltd - Head Office","Location":"Central Region","Publish_Time":"2025-07-15 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85763140","job_desc":"About the Role; As a Senior Data Engineer, you will focus on designing, building, and maintaining scalable data solutions that support business needs and AI applications. You will play a key role in:; Data Pipeline & Architecture Development; Build and optimize automated data pipelines for ingesting, transforming, and processing large datasets.; Design efficient data architectures that support analytics, machine learning, and real-time applications.; Cloud Migration & AI Enablement; Support cloud migration efforts, transitioning on-premises data workflows to cloud-based platforms like Databricks.; Collaborate with data scientists to improve feature selection, feature engineering, and enable end-to-end AI workflows from model training to deployment and monitoring.; CI\/CD & Automation; Develop CI\/CD pipelines to streamline data pipeline deployments and ensure stable, automated workflows.; Improve monitoring and observability to maintain system reliability.; Collaboration & Business Impact; Work with data scientists, product teams, and platform engineers to align data solutions with business objectives.; Ensure data quality, security, and compliance with industry standards.; Contribute to best practices in data governance, documentation, and automation.; Qualifications & Skills; Degree holder of Information Technology, Mathematics or Statistics with least 3 years of experience in data engineering.; Expert in Python, Java, SQL, Linux Shell.; Experience in UNIX environment, Git Flow, CI\/CD automation, Jenkins, Bitbucket.; Hands-on experience with Spark, Hadoop platforms & tools (Hive, Impala, Airflow, NiFi), Spring Boot, etc. to build big data products & platforms.; Proficiency with a modern cloud or hybrid-cloud stack (AWS, Databricks, Cloudera, etc).; Experience in building and deploying production-level data-driven applications and data processing workflows or pipelines.; Interested candidates may send in their resume and cover letter directly to gem.cabria@manpower.com.sg (R1434374), stating the position as the subject title in the email.; Jireli Gem Mejia Cabria EA License No.: 02C3423 Personnel Registration No.: R1434374; Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and\/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit https:\/\/www.manpower.com.sg\/privacy-policy","salary":"$8k - $10k p.m. (SGD)","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85072379","Role":"Data engineer - Azure","Company":"Flintex Consulting Pte Ltd","Location":"City Hall","Publish_Time":"2025-06-21 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85072379","job_desc":"Benefits: 13th Month Salary; Data engineer (Azure) \u2013 Synapse and Pyspark, Python,  Datawarehouse and Power BI , Azure Devops; Skills & Experience; Bachelor\u2019s Degree in Computer Science or Engineering with 3-5 years of experience in Azure Data engineering, Python, Pyspark or Big Data development; Sound Knowledge of Azure Synapse analytics for pipelines, orchestration, set up; 1-2  experience in Visualization design and development with Power BI. Knowledge on row-level security, access control; Sound experience in SQL, Datawarehouse, data marts, data ingestion with Pyspark and Python; Expertise in developing and maintaining ETL processing pipelines in cloud-based platforms such as AWS, Azure, etc. (Azure Synapse or data factory preferred); Team player with good interpersonal, communication, and problem-solving skills.; Job Scope; Design, review and development of Pyspark scripts. Testing, troubleshooting of data pipelines, orchestration; Designing and developing reports and dashboards in Power BI, setting up access control with row-level security, DAX query experience; Establishing connections to source data systems, including internal systems e.g. SAP, Historians, Data Lake, etc. as well as external systems such as Web APIs, etc; Managing the collected data in appropriate storage\/data-base solutions e.g. file systems, SQL servers, Big Data platforms such as Hadoop, HANA, etc. as required by the specific project requirements; Design, development of data marts and relevant data pipelines using pyspark, data copy activities for batch ingestion; Deployment of pipeline artifacts from one environment to the other using Azure Devops; Performing data integration e.g. using database table joins, or other mechanisms at an appropriate level as required by the analysis requirements of the project.; Good to have; Data catalog with Purview  enabling effective metadata management, lineage tracking, and data discovery; Candidates should demonstrate the ability to leverage Purview to ensure data governance, compliance, and efficient data exploration within Azure environments.; Others; Able to work independently on assignment according to agreed schedule without much supervision; Own assignment and take initiative to resolve issues hinder completion of assignment Proactively reach out for help\/guidance whenever required.","salary":"$7,000 \u2013 $10,000 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85795244","Role":"Data Engineer","Company":"SMRT Corporation Ltd","Location":"Bishan","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85795244","job_desc":"Company description:; ; SMRT Corporation Ltd is a public transport service provider. Our primary business is to manage and operate train services on the North-South Line, East-West Line, the Circle Line, the Thomson-East Coast Line and Bukit Panjang Light Rail Transit. This is complemented by our bus, taxi and private hire vehicle services.; ; Our core values are Respect, Integrity, Safety and Service, and Excellence. We are committed to provide safe, reliable and comfortable service for all our commuters.; ; ; Job description:; ; Job Purpose; The Data Engineer will be part of the team to develop operation & maintenance decision-support tools to enhance train reliability and maintenance efficiency. This position involves designing, developing, and maintaining data pipelines, APIs, and cloud infrastructure for various rail-oriented applications. The ideal candidate will have expertise in data analysis, transformation, ingestion, database design, API development, and preferably, cloud infrastructure setup. Collaborating closely with software engineers, data scientists, and frontend developers, the Data Engineer will contribute to building efficient, scalable, and reliable systems.; ; Responsibilities; The duties and responsibilities for Data Engineer, are as listed below. The list is not comprehensive and related duties and responsibilities may be assigned from time to time.; Data Engineering & Processing:; Develop and maintain data pipelines for efficient data ingestion and transformation.; Work with structured and unstructured data to ensure optimal storage and retrieval.; Perform data analysis and report on results.; Database Design & Management:; Design and implement relational and NoSQL database schemas for scalability.; Optimize database performance through indexing, partitioning, and query tuning.; Implement data security and compliance best practices.; API Development & Backend Engineering:; Design and develop APIs for data access and application integration.; Implement authentication, authorization, and API security best practices.; Cloud Infrastructure & Deployment (Supporting Role):; Assist in design Azure cloud architectures; Work with IT infrastructure team to set up cloud infrastructure for application hosting, data storage and processing.; Collaboration & Best Practices:; Collaborate with internal stakeholders to understand their business needs.; Work with software engineers, data scientist, frontend developer to understand the data requirement and design architecture of the data platform.; Implement CI\/CD pipelines for automated testing, deployment and monitoring.; Write testable and maintainable code and documentation to deploy to production.; Engage continuously with end-user for feedback and improvements.; Qualifications & Work Experience; Degree in Science, Technology, Engineering or Mathematics (STEM); Previous experience as a data engineer or in a similar role; Data engineering certification is a plus; Knowledge of security best practices in cloud and database management is a plus; Skills; Technical skills include:; Programming and Data processing: MATLAB, Python, SQL, or similar languages.; Databases: My SQL, SQL Server, MongoDB or similar.; Cloud Platforms: Azure; DevOps & CI\/CD: Git Lab CI\/CD, Docker; Generic skills include:; Strong inclination and eager for continual learning and development; Strong team player; Critical thinking and problem-solving skills; Ability to understand and explain complex data and effective interactions with the stakeholders; Ability to think independently and actively propose solutions to the team.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85038918","Role":"Contract - Data Engineer [AI Data Pipeline Dvt & Mgt] (1 yr)","Company":"Infineon Technologies","Location":"Kallang","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85038918","job_desc":"#WeAreIn for driving decarbonization and digitalization.; As a global leader in semiconductor solutions in power systems and IoT, Infineon enables game-changing solutions for green and efficient energy, clean and safe mobility, as well as smart and secure IoT. Together, we drive innovation and customer success, while caring for our people and empowering them to reach ambitious goals. Be a part of making life easier, safer and greener.; Are you in?; ; We are on a journey to create the best Infineon for everyone.; This means we embrace diversity and inclusion and welcome everyone for who they are. At Infineon, we offer a working environment characterized by trust, openness, respect and tolerance and are committed to give all applicants and employees equal opportunities. We base our recruiting decisions on the applicant\u00b4s experience and skills.; Please let your recruiter know if they need to pay special attention to something in order to enable your participation in the interview process.; Click here for more information about Diversity & Inclusion at Infineon.; The Data Engineer will serve as a technical expert in the fields of design and develop AI data pipelines to manage both large unstructured and structured datasets, with a particular focus on GenAI RAG\/Agent solutions.; ; In your new role you will:; Working closely with data scientists and domain experts to design and develop AI data pipelines using agile development process.; Developing pipelines for ingesting and processing large unstructured and structured datasets from a variety of sources, ensure efficient and effective data processing.; Development of BIA solution using defined framework for Data Modelling; Data Profiling; Data Extraction, Transformation & Loading; Design and provide data\/information in form of reports, dashboards, scorecards and data storytelling using Visualization Tools such as Business Objects & Tableau.; Work with cloud technologies such as AWS to design and implement scalable data architectures; Supporting the operation of the data pipelines involves troubleshooting and bug fixing, as well as implementing change requests to ensure that the data pipelines continue to meet user requirements.; You are best equipped for this task if you have:; Master's or Bachelor's Degree in Computer Science\/Mathematics\/ Statistics or equivalent.; Minimum of 3 years of relevant work experience in data engineering, including in-depth technical knowledge of databases, BI tools, SQL, OLAP, ETL, RAG \/ Agentic Data pipeline.; Proficient in RDBMS: Oracle\/PL SQL; Extensive hands-on experience in conceptualising, designing, and implementing data pipelines. Proficiency in handling unstructured data formats (e.g., PPT, PDF, Docx), databases (RDMS, NoSQL such as Elasticsearch, MongoDB, Neo4j, CEPH) and familiarity with big data platforms (HDFS, Spark, Impala).; Experience in working with AWS technologies focusing on building scalable data pipelines.; Front-end Reporting & Dashboard and Data Exploration tools -Tableau; Strong background in Software Engineering & Development cycles (CI\/CD) with proficiency in scripting languages, particularly Python.; Good understanding and experience with Kubernetes \/ Openshift Platform.; Other Skills \/ Attributes:; Good understanding of data management, data governance, and data security practices.; Highly motivated, structured and methodical with high degree of self-initiative; Team player with good cross-cultural skills to work in an international team; Customer and result-oriented; This is a 12 months contract under 3rd party payroll partner and entitled to benefits according to partner company","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85481896","Role":"Senior Data engineer","Company":"Flintex Consulting Pte Ltd","Location":"City Hall","Publish_Time":"2025-07-05 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85481896","job_desc":"Benefits: 13th Month Salary; Responsibilities; Integrate data from multiple sources, such as databases, APIs, or streaming platforms, to provide a unified view of the data; Implement data quality checks and validation processes to ensure the accuracy, completeness, and consistency of data; Identify and resolve data quality issues, monitor data pipelines for errors, and implement data governance and data quality frameworks; Enforce data security and compliance with relevant regulations and industry-specific standards; Implement data access controls, encryption mechanisms, and monitor data privacy and security risks; Optimise data processing and query performance by tuning database configurations, implementing indexing strategies, and leveraging distributed computing frameworks; Optimize data structures for efficient querying and develop data dictionaries and metadata repositories; Identify and resolve performance bottlenecks in data pipelines and systems; Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders; Document data pipelines, data schemas, and system configurations, making it easier for others to understand and work with the data infrastructure; Monitor data pipelines, databases, and data infrastructure for errors, performance issues, and system failures; Set up monitoring tools, alerts, and logging mechanisms to proactively identify and resolve issues to ensure the availability and reliability of data; It would be a plus if he has software engineering background; Requirements; Bachelor's or master's degree in computer science, information technology, data engineering, or a related field; Strong knowledge of databases, data structures, algorithms; Proficiency in working with data engineering tools and technologies including knowledge of data integration tools (e.g., Apache Kafka, Azure IoTHub, Azure EventHub), ETL\/ELT frameworks (e.g., Apache Spark, Azure Synapse), big data platforms (e.g., Apache Hadoop), and cloud platforms (e.g., Amazon Web Services, Google Cloud Platform, Microsoft Azure); Expertise in working with relational databases (e.g., MySQL, PostgreSQL, Azure SQL, Azure Data Explorer) and data warehousing concepts.; Familiarity with data modeling, schema design, indexing, and optimization techniques is valuable for building efficient and scalable data systems; Proficiency in languages such as Python, SQL, KQL, Java, and Scala; Experience with scripting languages like Bash or PowerShell for automation and system administration tasks; Strong knowledge of data processing frameworks like Apache Spark, Apache Flink, or Apache Beam for efficiently handling large-scale data processing and transformation tasks; Understanding of data serialization formats (e.g., JSON, Avro, Parquet) and data serialization libraries (e.g., Apache Avro, Apache Parquet) is valuable; Having experience in CI\/CD and GitHub that demonstrates ability to work in a collaborative and iterative development environment; Having experience in visualization tools (e.g. Power BI, Plotly, Grafana, Redash) is beneficial; Preferred Skills & Characteristics; Consistently display dynamic independent work habits, goal oriented, passionate in growth mindsets and self-motivated professional. Self-driven and proactive in keeping up with new technologies and programming","salary":"$6,000 \u2013 $9,000 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85306740","Role":"Data Engineer","Company":"Singapore LNG Corporation Pte Ltd","Location":"Telok Blangah","Publish_Time":"2025-07-01 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85306740","job_desc":"Company description:; ; Singapore LNG Corporation Pte Ltd (SLNG) was incorporated by the Energy Market Authority of Singapore in June 2009 to build, own and operate Singapore's very first open-access, multi-user LNG Terminal. This is a key national infrastructure that supports Singapore's energy diversification strategy and future economic development in the energy sector.; ; ; With more than 95% of electricity in Singapore being generated using natural gas, the SLNG Terminal helps to enhance the country's energy security by enabling natural gas to be shipped to Singapore from anywhere in the world. It also serves as a platform to facilitate the development of new LNG-related businesses, thereby contributing to the growth of Singapore's energy industry and the creation of new job opportunities.; ; ; Job description:; ; Roles and Responsibilties; Build and maintain scalable and reliable analytical solutions and dashboards to support commercial operations, throughput monitoring, and performance analysis.; Design, develop, and maintain scalable data pipelines, ETL processes, and data integration frameworks from commercial, operational, and external sources.; Collaborate with Commercial and Operations teams to model, analyse, and forecast terminal usage, cargo schedules, and system capacity.; Support the development of real-time and batch analytics dashboards for terminal throughput, slot utilisation, and performance benchmarking.; Implement and maintain data quality and validation frameworks to ensure high-integrity inputs into business-critical decisions.; Optimise data structures for simulation tools, commercial scenario modelling, and throughput planning systems.; Assist in the development of predictive models and optimisation algorithms in collaboration with data scientists and business analysts.; Keep up with emerging technologies and recommend tools or solutions to improve data analytics capabilities.; Database Management; Administer and maintain Wallix MSSQL databases, including writing complex queries, stored procedures, indexing, and performance tuning.; Support data integration efforts during the terminal expansion project, including real-time and batch data processing.; Automation & Scheduling; Develop scripts and automation workflows (e.g., via SQL Agent, Python, or PowerShell) to streamline data loading and quality checks.; Troubleshoot data issues and optimize data workflows to enhance system performance and reliability.; Data Quality & Governance; Implement processes to validate, monitor, and improve data accuracy, completeness, and consistency across all sources.; Develop and maintain documentation for data flows, architecture, and metadata. Implement data best practices within the team and ensure compliance with data governance and cybersecurity policies.; Work Requirements; 3+ years of experience in a data engineering or data-intensive role, preferably in energy, utilities, shipping, or logistics.; Proven experience as a Data Engineer, preferably within the energy, LNG, or industrial sector.; Strong proficiency in SQL, Python, or similar programming languages for data processing.; Experience with data pipeline and workflow management tools.; Familiarity with cloud platforms and data warehousing solutions.; Technical Skills:; Proficient in SQL, Python, and modern ETL tools (e.g., Airflow, DBT).; Experience with database MSSQL management.; Familiarity with data modelling, API integration, and streaming technologies (Kafka, Spark, etc.) is advantageous.; Experience working with visualisation tools like Power BI, Tableau, or similar.; Familiarity with commercial or operational systems such as ERP, SCADA, TMS, or LNG scheduling tools is a plus.; Experience in machine learning techniques and frameworks (e.g., scikit-learn, TensorFlow, PyTorch) to develop predictive models and advanced analytics is desirable; Soft Skills:; Strong analytical mindset with excellent problem-solving abilities.; Ability to work cross-functionally and communicate effectively with both technical and non-technical stakeholders.; Comfortable in a fast-paced, evolving environment where innovation and initiative are valued.; Understanding of commercial operations and throughput metrics in terminal or energy infrastructure is advantageous.; Strong communication skills to translate technical concepts for non-technical stakeholders.; Education Requirements; Bachelor's degree in Computer Science, Data Engineering, Information Systems, or related discipline.; Why Join SLNG?; An opportunity to contribute to Singapore's energy security and the region's LNG ecosystem.; Work on high-impact projects at the intersection of commercial strategy and operational excellence.; Collaborative and innovative work culture with professional development opportunities.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85246251","Role":"Senior\/ Data Engineer","Company":"BW LPG Holding Pte Ltd","Location":"Queenstown","Publish_Time":"2025-06-29 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85246251","job_desc":"COMPANY DESCRIPTION; As the world's leading owner and operator of LPG carriers with five decades of operating experience, BW LPG promotes competitive, sustainable solutions to secure value for society and our stakeholders.; Our global footprint spans seven countries with 17 nationalities represented across our workforce. Our fleet of 39 Very Large Gas Carriers (VLGC) offer a total carrying capacity of over 3 million CBM. From spot voyages and time charters to Contracts of Affreightments (CoAs), our emphasis on flexible, reliable service has earned the trust of leading oil companies as well as trading and utility companies. More information about BW LPG can be found at www.bwlpg.com.; BW LPG is associated with BW Group, a leading global maritime company involved in shipping, floating infrastructure, deepwater oil & gas production, and new sustainable technologies. Founded in 1955 by Sir YK Pao, BW controls a fleet of over 490 vessels transporting oil, gas and dry commodities, with its 200 LNG and LPG ships constituting the largest gas fleet in the world. In the renewables space, the group has investments in solar, wind, batteries, biofuels and water treatment. BW LPG, as a member of the BW Group, is one of Forbes World's Best Employers 2023.; DESIGNATION : Senior\/ Data Engineer; RESPONSIBILITIES; Role Overview; The Senior Data Engineer has a role focusing on building our modern Lakehouse including owning pipeline development, data modeling and governance within a cross-functional team responsible for the end-to-end delivery of data products and analytics solutions.; Additionally creating CI\/CD pipelines for automated deployments and monitoring, and enforce data quality checks, ensuring data consistency, reliability, and compliance.; Key Responsibilities; Working with Product Owners, Business Analysts and Data Analysts to ensure business requirements are translated into data solutions, deliver accurate and reliable datasets that enable impactful analytics and dashboards.; They collaborate with System Analysts and the Business to understand the business logic and data lifecycle within our systems and inform our solution design with a goal of balancing scalability and performance.; QUALIFICATIONS; Skills; Collaboration and Communication Skills: Excels at working in a team to align data solutions with business needs, focused on creative problem-solving in a fast-paced environment.; Analytical Thinking & Communication: Strong skills in analyzing and translating data-driven insights and requirements to both technical and non-technical stakeholders.; Spark & Azure Databricks: Proficiency in designing and implementing data pipelines to support reliable data ingestion and transformation using Databricks and Spark.; Data Modeling Expertise: Advanced SQL and Python skills for complex queries and data modeling, enabling efficient data access and transformation.; CI\/CD Pipeline Creation: Experience in creating CI\/CD pipelines, enabling automated testing, validation, and deployment of data pipelines models using GitHub and GitHub Actions with Databricks.; Infrastructure as Code: Experience in automating cloud infrastructure management for consistent deployment and scaling using tools like Terraform.; Experiences; 5+ Years in Data Engineering: Proven experience building and maintaining data infrastructure, with a deep understanding of data engineering principles and best practices.; Agile Mindset and Experience: Thrives in Agile Environments, with a strong resilience, adaptability and responsiveness to change in fast-paced settings.; OTHER INFORMATION; Only shortlisted candidate will be notified.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85572857","Role":"Snowflake Data Engineer (6 Months Extendable)","Company":"Robert Half International Pte Ltd","Location":"Central Region","Publish_Time":"2025-07-08 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85572857","job_desc":"The Company; ; We are seeking an experienced Snowflake Data Engineer to support our client within the Manufacturing industry on a mission-critical project for 6 months with potential of extension. This role is critical in supporting enterprise-wide data integration, transformation, and analytics initiatives by designing robust ETL\/ELT solutions and optimizing data workflows across platforms.; ; ; The Role; Design, develop, and optimize complex SQL-based transformations on the Snowflake platform.; Build and maintain reliable ETL\/ELT pipelines using Snowflake and Fivetran to seamlessly ingest data from diverse sources such as SharePoint and Oracle ERP.; Collaborate closely with analytics teams to create and optimize Power BI data models and reports that empower business decision-making.; Partner with the Data Architect Manager to drive best practices in data architecture, modeling, and governance across the organization.; Lead efforts in ensuring data quality and integrity by implementing validation checks and quickly resolving inconsistencies.; Monitor and optimize pipeline performance and Snowflake warehouse usage to maximize efficiency and control costs.; Provide ongoing technical support and knowledge transfer to internal teams and end users across APAC.; Document data flows, transformation logic, and system configurations clearly to maintain transparency and support ongoing development.; Use GitLab to manage code, collaborate with peers through version control, and automate deployment with CI\/CD pipelines.; Participate in Agile ceremonies: sprint planning, stand-ups, retrospectives, and peer reviews.; Your Profile; Degree in Computer Science, Information Technology, Data Science, Software Engineering, or a related field.; 8+ years' experience in data engineering or enterprise data warehousing; Expert in Snowflake, advanced SQL, data modeling (star\/snowflake schemas), performance tuning, and security.; Proven skills building and managing ETL\/ELT pipelines, preferably using Fivetran.; Hands-on experience with Power BI for data modeling, report building, and DAX.; Comfortable with GitLab for version control, CI\/CD, and code collaboration.; Experience with cloud platforms (AWS, Azure, or GCP) and orchestration tools like dbt, Airflow, or NiFi.; Strong focus on data quality, governance, and lineage best practices.; Excellent problem-solving, communication, and teamwork skills.; ; Apply Today; ; Please send your resume, in WORD format only and quote reference number GO13257376, by clicking the apply button. Please note that only short-listed candidates will be contacted.; ; ; Robert Half International Pte Ltd. Co. Registration no.: 200612189E | EA Licence No.: 07C5595 | Gabriela De Brito Lopes Prestes Oxby EA Registration no.: 1989404; By clicking 'apply', you give your express consent that Robert Half may use your personal information to process your job application and to contact you from time to time for future employment opportunities. For further information on how Robert Half processes your personal information and how to access and correct your information, please read the Robert Half privacy notice: https:\/\/www.roberthalf.com.sg\/privacy-statement. Please do not submit any sensitive personal data to us in your resume (such as government ID numbers, ethnicity, gender, religion, marital status or trade union membership) as we do not collect your sensitive personal data at this time.","salary":"Competitive (SGD)","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85746300","Role":"Senior Data Engineer","Company":"Adecco Personnel Pte Ltd.","Location":"Central Region","Publish_Time":"2025-07-14 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85746300","job_desc":"A regional tech services firm was formed through a major collaboration between a global hardware leader and a long-standing IT solutions provider in Asia. This partnership brought together thousands of professionals to deliver a full range of enterprise services, from system integration and software development to infrastructure support and managed operations. With strong capabilities across both global delivery and local implementation, the company plays a key role in driving digital transformation initiatives across the Asia-Pacific region. One party holds a significant majority stake in the venture, reinforcing its long-term commitment to expanding service offerings beyond hardware.; Join our client's presales team to design and recommend cutting-edge data and AI\/ML solutions for government and enterprise clients. You'll drive the technical vision, build POCs, and collaborate across teams to deliver scalable, secure, and high-impact data strategies.; Key Responsibilities:; Design and optimize data pipelines and architectures for analytics and ML use cases; Evaluate and recommend modern data\/AI\/ML technologies; Handle diverse data types (video, audio, tabular, text); Build POCs and demos to showcase solution feasibility; Communicate technical solutions and ROI to varied stakeholders; Support AI solution development to promote adoption internally and externally; Requirements:; Degree in Computer Science, Engineering, or related field; 3-5 years in data engineering or presales\/solution engineering; Certified in Azure\/AWS\/GCP Data Engineering (e.g., DP-203, Databricks, Snowflake); Experience in Spark, Kafka, Airflow, MLOps (CI\/CD, model deployment); Strong with cloud platforms (AWS, Azure, GCP), Linux, Docker\/Kubernetes, Terraform; Familiar with government standards (e.g., IM8, GCC); Preferred:; TOGAF or architecture certification; Presales experience; Hands-on with Azure Data Factory, AWS Glue, or Google DataFlow; ; Wilson Tay; Direct Line: 6697 7866; EA License No: 91C2918; Personnel Registration Number: R2091205","salary":"$10k - $12k p.m. + Bonus (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85646746","Role":"Data Engineer","Company":"StarHub Ltd","Location":"Singapore","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85646746","job_desc":"The Customer Lifecycle Management (CLM) team at StarHub is dedicated to understanding, enhancing, and optimizing the customer journey. From acquisition to retention, the CLM team employs data-driven strategies to provide unparalleled customer experiences. Through a combination of data science, business intelligence, customer insights, NPS, and digital analytics, the CLM team ensures that StarHub's offerings are aligned with customer needs, leading to increased loyalty, satisfaction, and growth.; The Data Engineer plays a crucial role in the CLM team by designing, implementing, and maintaining the data infrastructure that supports the team's analytics and data science initiatives. This position is responsible for developing and optimizing data pipelines, ensuring data quality and accessibility, and collaborating with data scientists and analysts to enable efficient data-driven decision-making. The Data Engineer will work on integrating data from various sources, implementing data governance practices, and creating scalable solutions that support the CLM team's objectives in enhancing customer experiences and driving business growth.;   Data Pipeline Development : Design, implement, and maintain efficient ETL (Extract, Transform, Load) processes to integrate data from various sources. Optimize existing data pipelines for improved performance and scalability.; Data Warehouse Management: Develop and maintain the data warehouse architecture, ensuring it meets the needs of the CLM team. Implement data modeling techniques to optimize data storage and retrieval.; Data Quality Assurance: Implement data quality checks and monitoring systems to ensure the accuracy and reliability of data used in analytics and reporting. Develop and maintain data documentation and metadata.; Big Data Technologies: Utilize big data technologies (e.g., Hadoop, Spark) to process and analyze large volumes of customer data efficiently. Implement solutions for real-time data processing when required.; Data Governance: Collaborate with relevant stakeholders to implement data governance policies and procedures. Ensure compliance with data privacy regulations and internal data management standards.; Infrastructure Optimization: Continuously assess and optimize the data infrastructure to improve performance, reduce costs, and enhance scalability. Implement automation solutions to streamline data processes.;   Education Level:; Bachelor's degree in Computer Science, Information Systems, Data Engineering, or a related field. Master's degree in a relevant field is preferred.; Required Experience and Knowledge; 3-5 years of experience in data engineering or a related field.; Strong knowledge of data warehouse concepts, ETL processes, and data modeling techniques.; Experience with cloud-based data platforms (e.g., AWS, SnowFlake).; Proficiency in SQL and experience with NoSQL databases.; Experience with big data technologies such as Hadoop, Spark, or Kafka.; Knowledge of data governance principles and data privacy regulations.; Job-Specific Technical Skills:; Proficiency in Python or Scala for data processing and automation.; Experience with ETL tools (e.g., Apache NiFi, Talend, Informatica).; Knowledge of data visualization tools (e.g., Tableau, PowerBI) to support data quality checks and pipeline monitoring.; Familiarity with version control systems (e.g., Git) and CI\/CD practices.; Experience with container technologies (e.g., Docker) and orchestration tools (e.g., Kubernetes).; Understanding of data security best practices and implementation.; Behavioural Skills:; Strong problem-solving and analytical skills.; Excellent communication abilities to collaborate with technical and non-technical team members.; Proactive approach to identifying and resolving data-related issues.; Ability to manage multiple projects and priorities effectively.; Detail-oriented with a focus on data quality and system reliability.; Adaptability to work with evolving technologies and changing business requirements.; Strong teamwork skills and ability to work in a collaborative environment.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85783260","Role":"Attractive Job Opening for AWS Python Data Engineer in Singapore","Company":"TALENT XPERTS PTE. LTD.","Location":"Paya Lebar Air Base","Publish_Time":"2025-07-15 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85783260","job_desc":"Mandatory skills*; Very Strong Proficiency:; Python: Extensive experience in Python for data manipulation, scripting, and building data applications.; PySpark: Deep expertise in developing and optimizing large-scale data transformations using PySpark.; SQL: Advanced SQL skills, including complex query writing, performance tuning, and database design.; AWS: Hands-on experience designing, deploying, and managing data solutions on various AWS services (S3, EMR, Glue, Lambda etc).; Solid understanding of data warehousing concepts, ETL\/ELT principles, and data pipeline best practices.; Excellent problem-solving, analytical, and communication skills.; Ability to work independently and as part of a collaborative team.; Desired skills*; Airflow: Experience with Airflow for orchestrating and managing data workflows.; Snowflake: Familiarity with Snowflake for cloud data warehousing and analytical processing.; Bitbucket (or Git): Proficient in using version control systems for collaborative development.; Domain*; Data Engineering; Mode of Interview: Telephonic\/Face to Face\/Skype Interview* -Teams or F2F","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85584364","Role":"Data Engineer, Healthcare","Company":"Menrva","Location":"Marina South","Publish_Time":"2025-07-08 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85584364","job_desc":"About the Organization; The organization plays a central role in architecting and implementing cutting-edge digital health solutions \u2014a major preventive care strategy aimed at improving long-term population health.; Why This Role Matters; As a Data Engineer, you will be integral to building and maintaining the data infrastructure that fuels analytics, reporting, and predictive modelling. Your work will directly influence how data is accessed, secured, and leveraged to improve healthcare outcomes.; Key Responsibilities; Design, build, and maintain robust data pipelines for integrating and processing data from diverse sources and formats.; Clean, prepare, and transform data for analytics, business intelligence, and data science use cases.; Ensure comprehensive documentation of data processes and pipeline architecture.; Monitor, troubleshoot, and improve the performance of data systems and pipelines.; Identify optimisation opportunities for scalability, repeatability, and security.; Handle data system errors and contribute to testing configurations for improved efficiency.; Requirements; Must-Have Skills:; Proven experience in designing scalable ETL pipelines to support AI and data science initiatives.; Strong proficiency in SQL, NoSQL, and Python for data preparation, transformation, and automation.; Hands-on experience with data lake management and data pipeline development.; Familiarity with cloud collaboration and development tools (e.g., Office 365, Atlassian, AWS, Azure).; Nice-to-Have Skills:; Exposure to AWS services (e.g., S3, Athena, Lambda, IAM, CloudWatch).; Domain knowledge in health informatics; Experience supporting machine learning, clinical data projects, or hospital information systems.; Familiarity with modern data engineering frameworks like Airflow, Docker, Kubernetes.; Qualifications; Bachelor's degree in Computer Science, Information Technology, Computer Engineering, or a related field.; 3 to 7 years of hands-on experience in data engineering, pipeline development, and production deployment.; Strong scripting abilities, preferably in Python.; Solid SQL skills and experience with platforms like Informatica, Teradata, or SQL Server.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85576102","Role":"Data Engineer","Company":"RSK Group","Location":"Singapore","Publish_Time":"2025-07-08 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85576102","job_desc":"We are seeking a Data Engineer with experience or interest in IoT technologies and cloud-based data engineering to join our team. This role blends the management of high-volume data flows and IoT-specific analytics with general data engineering practices to deliver robust and scalable data solutions. The ideal candidate will balance technical skills and domain knowledge, enabling data-driven insights for utility operations, customer services, and infrastructure optimisation initiatives.; Key Responsibilities:; Design, develop, and maintain scalable and efficient data pipelines and ETL processes for IoT and enterprise data systems.; Implement data ingestion workflows from IoT devices and integrate with enterprise platforms using Azure Data Factory or similar tools.; Ensure data quality through validation, cleansing, and monitoring processes to address issues such as missing data, duplicates, and inconsistencies.; Define data attributes and formats for IoT device and network data to support seamless integration with existing systems and standards.; Optimise data storage solutions in Azure Data Lake Storage (or equivalent) for structured and unstructured data.; Develop APIs and data interfaces for real-time or near-real-time data transfer between IoT components and enterprise platforms.; Apply advanced analytics techniques to IoT data for performance monitoring, usage profiling, and network management.; Leverage BI tools (e.g., Power BI) to enable business intelligence and operational insights.; Implement robust data security and privacy measures, ensuring compliance with relevant regulations.; Collaborate with cross-functional teams to gather requirements and deliver high-quality, documented solutions.; Required Skills & Qualifications:; Bachelor\u2019s degree in Computer Science, Information Technology, or a related field. Advanced degrees or certifications are advantageous.; Academic or industrial experience in data engineering, including SQL Databases and cloud platforms (Azure, AWS, or GCP).; Experience or interest in IoT technologies and data systems.; Proficiency in data ingestion tools such as Azure Data Factory and ETL processes.; Strong programming skills in Python, SQL, and one or more of Java or Scala.; Familiarity with big data technologies (e.g., Hadoop, Kafka) and enterprise service buses (ESB).; Knowledge of data management systems and integration with enterprise applications.; Understanding of operational data flows, business cycles, and regulatory requirements.; Preferred Skills & Qualifications:; Familiarity with additional Azure ecosystem tools (e.g., Synapse Analytics, Event Hub, Stream Analytics).; Experience with APIs, data interfaces, and integrating IoT systems with enterprise data platforms.; Relevant certifications in Microsoft Azure or other recognised credentials.; Knowledge of DevOps practices and CI\/CD pipelines (e.g., Azure DevOps).; Familiarity with containerisation technologies such as Docker.; Background in implementing Change Data Capture (CDC) designs and scalable data architectures.; Personal Attributes:; Excellent communication and collaboration skills.; Strong analytical and problem-solving mindset.; Proactive approach to continuous professional development.; Ability to work effectively in dynamic, fast-paced environments.; This position offers an opportunity to work at the intersection of IoT data systems and modern cloud engineering, supporting innovation and operational excellence across industries.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84883591","Role":"Data Engineer","Company":"ExpressVPN","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84883591","job_desc":"The Data Engineer will be responsible for designing, developing, and maintaining robust data pipelines and data warehouse architectures. The ideal candidate will have expertise in tools like AWS Redshift, Athena, Snowflake, and other leading databases, with a strong focus on building scalable and efficient data solutions.; What you\u2019ll do; Design and implement scalable and efficient data pipelines to ingest, process, and store large datasets from multiple sources.; Develop and maintain data warehouse solutions using AWS Redshift, Athena, Snowflake, and other modern data platforms.; Optimize data models and queries to ensure high performance and cost-effectiveness.; Collaborate with data analysts, scientists, and cross-functional teams to understand data requirements and translate them into technical solutions.; Ensure data integrity, security, and privacy throughout the pipeline and storage processes.; Monitor data workflows and troubleshoot issues to ensure reliability and accuracy.; Implement best practices for data governance and ensure compliance with data policies.; Stay updated with the latest trends and advancements in data warehousing technologies.; What you\u2019ll need to succeed; Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or related field.; 5+ years of experience as a Data Engineer or similar role with a focus on data warehousing and pipeline development.; Strong proficiency with AWS Redshift, Athena, Snowflake, and other top-tier databases.; Experience with data pipeline tools and frameworks (e.g., Apache Airflow, Glue, or similar).; Proficiency in SQL and scripting languages such as Python or Shell.; Familiarity with cloud services (AWS preferred) and infrastructure management.; Experience with data modeling, schema design, and ETL processes.; Excellent problem-solving skills and attention to detail.; Strong communication skills and the ability to work collaboratively across teams.; Nice to Have:; Experience with BI tools like Tableau, Looker, or Power BI.; Knowledge of data security and privacy best practices.; Experience with DevOps tools and practices.; P.S. Mention Tech in Asia Jobs when you apply! Helps keep the good stuff coming \ud83d\ude09","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85182251","Role":"Big Data Engineer, Data Ingestion","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-26 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85182251","job_desc":"Responsibilities; About the Team The Data Management Suite team is building products that cover the whole lifecycle of data pipeline, including data ingestion and Integration, data development, data catalog, data security and data governance. These products support various businesses, so data engineers and data scientists could greatly boost their productivity.; As a software engineer in the data management suite team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on core systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.; Responsibilities:; Design, develop, and optimize the architecture of large-scale data ingestion systems to support real-time data pipelines, ensuring high throughput, low latency, and fault tolerance.; Enhance the performance, scalability, and reliability of data ingestion pipelines.; Develop and implement automated and intelligent operation and maintenance systems to monitor, diagnose, and ensure the stability and reliability of data ingestion pipelines.; Collaborate with cross-functional teams to deliver event data ingestion, transformation, and storage solutions that meet diverse business requirements.; Troubleshoot and resolve complex issues in production systems, ensuring minimal downtime and optimal performance.; Qualifications; Minimum Qualifications:; Bachelor's degree in Computer Science or equivalent practical experience;; 2+ years of experience in software development with proficiency in one or more programming languages, such as Java, Scala, Python, or; Go.; Strong understanding of data structures, algorithms, and distributed systems principles.; Hands-on experience with big data technologies, such as Hadoop, Flink, Kafka, or similar frameworks.; Preferred Qualifications:; 2+ years of experience in real-time data processing frameworks like Flink.; Contributions to open-source projects are a plus.; Experience in the event tracking domain, including event collection, real-time processing, governance, quality assurance and cost optimization.; Deep understanding of data lakehouse architectures and the integration of stream and batch processing.; Strong problem-solving skills and the ability to work in a fast-paced, collaborative environment.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85579374","Role":"Lead Data Engineer","Company":"AIRR Labs","Location":"Central Region","Publish_Time":"2025-07-07 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85579374","job_desc":"Reporting to the Regional Head of Data & BI, this role requires a hands-on approach to lead a team of data engineers to build and upkeep data pipelines, data warehouse, and analytics platforms to ensure data accuracy, data integrity and security.; Responsibilities; Lead the design, development, and implementation of scalable and efficient data pipelines, databases, and data infrastructure on cloud solutions; Implement ETL processes to integrate data from various sources, ensuring data quality, consistency, and integrity.; Optimize data pipelines, queries, and infrastructure for performance, scalability, and cost-efficiency.; Collaborate with cross-functional teams to gather requirements, assess technological options, and propose architectural solutions.; Mentor, coach, and guide a team of data engineers, providing technical leadership and support.; Requirements; Solid understanding of relational databases.; Extensive experience in Python, SQL, or other scripting languages is required. Experience with AWS services (S3, EC2, EMR, RDS) is a must.; Self-motivated, proactive and excellent communication skills. Experience in ecommerce industry is an advantage.; Bachelor or degrees above in Computer Science, Computer Engineering or other relevant degrees.; 6+ years of experience in data engineering, with at least 3 years in a lead or senior engineering role. Strong technical background in designing and implementing data pipelines, databases, and analytical tools.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85782713","Role":"Data Engineer (IDMC - CAI, CDI, XQuery, API Integration)","Company":"NEPTUNEZ SINGAPORE PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-15 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85782713","job_desc":"About the role:; We are looking for a Data Engineer with strong expertise in Informatica Intelligent Data Management Cloud (IDMC) to architect, build, and optimize scalable, real-time, and batch data integration pipelines. The role requires deep knowledge of Informatica Cloud Application Integration (CAI) and Cloud Data Integration (CDI) within the IDMC platform.; Responsibilities:; Design and implement real-time and batch data pipelines using IDMC\u2013CAI and CDI modules.; Build and manage complex Advanced Taskflows with parallel paths, branching, and exception handling.; Develop CAI processes using the Process Designer to integrate with REST\/SOAP APIs and web services.; Create and configure Service Connectors, App Connections, and Business Services for secure and reusable integrations.; Leverage XQuery for advanced payload transformation and manipulation of XML\/JSON data.; Implement robust version control, deployment strategies, and reusable design patterns for scalable integration.; Monitor data flows, perform incident management, and conduct root cause analysis for process failures.; Develop technical documentation, support runbooks, and conduct code reviews.; Collaborate cross-functionally with business stakeholders and development teams to define integration requirements.; Mentor junior developers on best practices for CAI and CDI design and development.; Requirements; 5+ years of experience in data integration and engineering, with strong experience in Informatica IDMC.; Proven experience building processes with Cloud Application Integration (CAI) and Cloud Data Integration (CDI).; Expertise in XQuery, API integration, and working with structured and semi-structured data (JSON, XML).; Proficient with Snowflake, Oracle, Salesforce, and AWS S3 as data sources\/targets.; Experience with event-driven workflows, scheduling, and monitoring of production pipelines.; Hands-on with task flow orchestration, parameterized pipelines, and deployment automation.; Strong knowledge of data governance, security protocols, and cloud data architectures.; Excellent troubleshooting and performance tuning skills for integration flows.; Familiarity with DevOps tools for deployment and versioning of IDMC assets.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"82451779","Role":"Business Intelligence Platform Architect","Company":"ESR Group","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/82451779","job_desc":"Position Title; Business Intelligence (BI) Platform Architect; Reports to; Group Direction, Business Intelligence and Data Integration; Position Summary; We are seeking a detail-oriented and proactive Business Intelligence (BI) Platform Architect with a strong foundation in data management. In this role, you will be responsible for developing robust BI solutions while ensuring high standards of data integrity, governance, and usability. You will work closely with both technical teams and business stakeholders to deliver meaningful insights and maintain a reliable data ecosystem that supports strategic decision-making.; Key Responsibilities include but not limit to:; BI Development & Reporting; Design, develop, and maintain interactive dashboards and reports using tools like Power BI.; Collaborate with stakeholders to gather reporting requirements and translate them into effective BI solutions.; Create and optimize SQL queries and stored procedures to support reporting needs.; Develop and manage data models and visualizations that support business analysis and operational monitoring.; Data Management & Governance; Maintain data quality, integrity, and consistency across multiple systems and sources.; Define and enforce data management standards, including naming conventions, metadata definitions, and data classification.; Collaborate with data owner and IT to manage data cataloging, lineage, and documentation.; Support the implementation of master data management (MDM), data cleansing, and data validation rules.; Participate in data audits and work to resolve data discrepancies and issues.; Data Integration & Architecture; Assist in building and maintaining data pipelines for ingestion and transformation using ETL\/ELT tools.; Support integration of data from cloud and on-premise sources into centralized data platforms (e.g., Fabric, data lakes, data warehouses).; Work closely with IT infra engineers and architects to ensure optimal performance and scalability of data infrastructure.; User Support & Enablement; Provide user training and support on BI tools, reports, and dashboards.; Create user documentation and data dictionaries for self-service BI.; Troubleshoot and resolve BI\/reporting-related issues.; Requirements; Education:; Bachelor\u2019s degree in Computer Science, Information Systems, Data Science, or a related field; 10+ years of experience as a BI Developer, Data Analyst, or similar role.; Strong hands-on experience with BI\/reporting tools (e.g., Power BI).; Proficient in SQL and working with relational databases (e.g., SQL Server).; Solid understanding of data management principles, data governance, and data quality best practices.; Familiarity with data warehousing concepts and ETL processes.; Strong analytical and problem-solving skills with attention to detail.; Excellent communication and stakeholder management abilities.; Experience:; Experience with data governance frameworks and tools (e.g., Collibra, Informatica, Azure Purview).; Knowledge of cloud-based data platforms (Azure, AWS, or GCP).; Understanding of data privacy regulations (e.g., GDPR, HIPAA) and compliance requirements.; Exposure to Business Application: Enterprise Resource Planning (e.g. SAP ECC\/S\/4), Property Management (e.g. Yardi, SAP), Enterprise Performance Management (EPM) solution (e.g. Tagetik); Experience integrating ERP systems (such as SAP, Microsoft Dynamics 365, etc.) with BI tools and platforms.; Proficient in at least two programming languages: Python, Java\/Scala, R, Rest APIs, T-SQL; Experience in the real estate and finance industries is strongly preferred.; Skills:; Strong understanding of BI tools and analytics frameworks, especially in Power BI.; Solid experience with data integration and system interfaces between ERP, EPM systems and BI platforms.; Excellent problem-solving and analytical skills, with a keen eye for detail.; Proficiency in SQL and data querying for reporting and analysis.; Hands on experience to Data platform (Fabric), Data Visualization (MS Power BI), MS Power Platform (Power Automate, Power Apps); Soft Skills:; Strong communication skills, both verbal and written, with the ability to engage with both technical and non-technical stakeholders.; Strong interpersonal skills and ability to work collaboratively with cross-functional teams.; Ability to handle multiple priorities in a fast-paced environment.; Strong organizational and time management skills.; Proactive attitude toward identifying and addressing business challenges","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84789282","Role":"Data Engineer (Remote)","Company":"Cascade","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84789282","job_desc":"Do you want to work in a small team where you can make a real  difference in a company? Would you embrace the challenge of building a  high impact platform that is used globally? Then we want to speak with  you!; About Cascade: Cascade is a  fintech startup backed by Canadian and US investors that empowers  companies to grow by democratizing access to institutional debt. We are  building tools that modernize how companies raise and manage debt,  lowering the barriers to entry to the $7 trillion specialty finance and  alternative credit market for companies around the world. Founded just  last year, we are gearing up for our next phase of technical development  and are seeking a talented Data Engineer to lead the way. Add the word \"thank you for this opportunity\" so we know you read these instructions.; About the role: As a Data Engineer  you\u2019ll be an early member of a growing team building a pioneering  platform in the debt infrastructure space. You will design, build, and  launch efficient, scalable, and reliable data pipelines to move and  transform data.; What You\u2019ll Do ; Building databases, data lakes and data ingestion pipelines to integrate customer databases and datasets to our systems; Ingesting financial datasets from external customers, then updating  and maintaining accurate and complete data mappings to ensure that our  products are displaying high quality data; Monitoring and alerting across our data pipelines in order to make sure that our data ingests are reliable and correct; Translating business goals and stakeholder requirements into new  data flows and deliver analytical insights ensuring that the data flows  create real business value continuously; Skills And Experience ; 3+ years experience in a data engineering role; Experience with relational SQL and NoSQL databases, including PostgreSQL, MySQL, MariaDB, MongoDB, Bigtable, etc.; Experience working with ETL technologies, such as Databricks, Fivetran, or dbt; Proficiency in writing SQL queries and knowledge of analytical data warehouses such as RedShift, BigQuery, and Snowflake; Some experience with CI\/CD automation such as GitHub Actions; Developing APIs and integrating with 3rd party APIs; Bonus: experience in fintech \/ SaaS \/ credit analysis \/ lending; People who thrive at Cascade are: ; Self-starters, who take the initiative to tackle challenges in a remote work environment; Good communicators, who can operate without ego to discuss, learn, grow, and help others do the same; Passionate about creating great digital experiences for users; Problem solvers who are not satisfied with the status quo; Benefits ; Remote: we are a remote-first company and are very flexible on hours as long as things get done; Home-office: there\u2019s a $1000 USD home office allowance to set yourself up; Equity: we expect you to have an owner-mentality, and have the equity plan to match; Benefits: health, dental, vision, and more; Perks: we offer free lunches weekly and off-site trips; Job satisfaction: we offer autonomy, ample opportunities for  mastery, and an opportunity to make a difference for companies around  the world","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85231462","Role":"Azure Data Technical Lead","Company":"Manpower Staffing Services (S) Pte Ltd - Head Office","Location":"Central Region","Publish_Time":"2025-06-27 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85231462","job_desc":"We are looking for a skilled Azure Data Platform Technical Lead to drive the migration of on-premises systems to Azure. This role involves defining the migration methodology, ensuring data requirements and compliance strategies are met, and providing technical guidance to internal teams. You will play a key role in building and optimizing our client's Azure-based data warehouses, Databricks solutions, data pipelines, and Power BI reports.; Key Responsibilities; Analyze current practices, processes, and procedures to identify opportunities for leveraging Microsoft Azure Data and Analytics services.; Provide technical leadership in areas such as data access, ingestion, integration, processing, modeling, database design, visualization, and advanced analytics.; Collaborate with project managers to estimate technical tasks and deliverables.; Develop best practices, reusable code, libraries, and frameworks for cloud-based data warehousing and ETL processes.; Establish and maintain best practices for cloud-based data warehouse solutions, including naming conventions and development standards.; Job Requirements; Education: Bachelor's degree in Information Technology, Computer Science, Management Information Systems, Banking & Finance, or a related field.; Experience:; At least 10 years in Data Warehousing, Data Analytics, Real-time Data Integration, or Business Intelligence.; Minimum 3 years as a Data Architect, Solution Architect, or Technical Lead.; At least 2 years of experience leading technical teams in Azure data platform implementation.; Technical Skills:; Good understanding of both traditional and modern data architectures (SQL, Hadoop, Spark, Kafka, etc.).; Expertise in Databricks is mandatory.; Hands-on experience with:; Azure database platforms: Azure SQL Database, Azure Databricks, Azure Data Lake Gen2.; Azure data integration tools: Azure Synapse, Azure Data Factory, Azure Event Hub.; Data visualization tools: Power BI, QlikView.; Programming skills: Python, R.; Ability to design data architecture solutions connecting structured and unstructured data sources.; Knowledge of traditional ETL processes is a plus.; Experience in financial sector technologies.; If you are passionate about Azure data solutions and enjoy leading high-impact projects, we invite you to apply!; Gurram Sravanthi EA License No.: 02C3423 Personnel Registration No.: R2197596; Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and\/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit https:\/\/www.manpower.com.sg\/privacy-policy","salary":"10000 - 13000 (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85788052","Role":"Data Engineer Project Intern (Data Platform, TikTok) - 2025 Start (BS\/MS)","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85788052","job_desc":"Responsibilities; About the team The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics & dashboards which will be used to make smarter business decisions to support business growth.; If you're looking for a challenging ground to push your limits, this is the team for you! As a project intern, you will have the opportunity to engage in impactful short-term projects that provide you with a glimpse of professional real-world experience. You will gain practical skills through on-the-job learning in a fast-paced work environment and develop a deeper understanding of your career interests.; Applications will be reviewed on a rolling basis; we encourage you to apply early.; Successful candidates must be able to commit to at least 3 months long internship period. Responsibilities:; Design and implement data warehouse architectures, data modeling, and ETL pipeline development.; Optimize data ETL process and resolve technical issues related to large-scale data ETL.; Participate in data governance under complex data link dependencies and diverse data content ecosystems.; Implement data solutions for business scenarios, leveraging ByteDance's robust mid-tier architecture and product systems.; Qualifications; Minimum Qualifications: - Proficiency in data warehouse implementation methodologies, with in-depth understanding of data warehouse systems and experience supporting business scenarios. - Strong coding skills, with proficiency in multiple tools\/languages including SQL, Python, Java, Hive, Spark, Kafka and Flink.; Preferred Qualifications: - Data-sensitive, meticulous and adept at identifying anomalies in data. - Strong communication skills and excellent ability in integrating technical expertise with business needs.; By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https:\/\/careers.tiktok.com\/legal\/privacy If you have any questions, please reach out to us at apac-earlycareers@tiktok.com.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85379862","Role":"Data Engineer (DST)","Company":"MOH Office for Healthcare Transformation Pte Ltd","Location":"Singapore","Publish_Time":"2025-07-02 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85379862","job_desc":"MOHT envisions a transformed health system that is patient-centric, data-driven and digitally-enabled to better empower health, prevent disease and provide excellent value-based care. To realise this vision, MOHT\u2019s mission is to design and implement innovative solutions essential for the desired health system transformation.; Technology plays a significant role in MOHT\u2019s projects and experiments, and in its operating environment. MOHT adopts an agile approach using rapid and continuous build-measure-learn cycles that identify, develop, deliver and adapt technology to improve health. They work closely with IHiS and implementation partners. This allows MOHT\u2019s teams to be responsive to real needs, as demonstrated by actual data, and nimble in evolving prototypes and scalable solutions.; The main tools being used are:; Agile development on cloud based environment; Digital solution architecture design, development and operation; Data analytics and modelling to understand healthcare flows and resource usage; Artificial Intelligence; Current Initiatives:; Digital application for mental wellness; Passive and active sensing tools for patient lifestyle understanding and improvement; Tele-health monitoring solutions for connected care; Mobile patient and clinical applications; Digital phenotyping; Data analytics, including for patient flow analysis; JOB RESPONSIBILITIES; Lead the design, development, and maintenance of scalable and secure data pipelines and architectures to support healthcare analytics and digital health solutions.; Collaborate with cross-functional teams to understand data needs and translate them into robust data engineering solutions.; Manage and optimize data ingestion, transformation, and storage processes across structured and unstructured data sources.; Ensure data quality, integrity, and governance across all data platforms.; Drive the adoption of best practices in data engineering, including CI\/CD, testing, and monitoring.; Mentor and guide junior data engineers and contribute to team capability building.; Work closely with data scientists, analysts, and application developers to enable data-driven decision-making.; Document data workflows, architecture, and operational procedures for knowledge sharing and continuity.; JOB REQUIREMENTS; Required:; Bachelor\u2019s degree (or above) in Computer Science, Data Engineering, Information Systems, or a related field.; At least 8 years of experience in data engineering, with a strong background in building and managing data pipelines and architectures.; Must have:; Hands-on experience with cloud-based data platforms (AWS preferred or Azure, or GCP).; Proficiency in data pipeline tools (e.g. Apache Airflow, Kafka, Spark).; Strong SQL skills and experience with relational and NoSQL databases.; Strong Python programming skills; Experience with data warehousing solutions (e.g., Snowflake, Redshift, BigQuery).; Familiarity with data governance, security, and compliance in healthcare or regulated environments.; Plus: Experience with healthcare data standards (e.g., FHIR, HL7) and DevOps practices.; Leadership: Ability to lead data engineering initiatives, coordinate with stakeholders, and manage project timelines and deliverables.; Good communication skills, both written and verbal.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84356922","Role":"Senior Data Engineer","Company":"StarHub Ltd","Location":"Singapore","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84356922","job_desc":"JOB PURPOSE; The Data Platform Team is responsible for designing, implementing, and managing a modern data platform that embraces the principles of data mesh, empowering teams to create and manage their own data products. Our mission is to deliver high-quality, scalable data solutions that drive business value across the organization.; As a key member of this team, you will be responsible for building scalable, stable, and secure data pipelines that support both batch and streaming workloads. Your work ensures reliable data delivery across domains and supports the development of reusable, self-serve data products.; In this role, you will collaborate with business owners, engineers, and data stewards to implement ingestion frameworks and transformation jobs that align with the data-as-a-product vision. You will apply best practices in data engineering to enable efficient data integration across cloud and on-prem environments.; KEY RESPONSIBILITIES; Design and develop scalable, secure, and efficient data ingestion pipelines for structured and unstructured data from internal and external systems across AWS and on-prem environments.; Work closely with architects and business domain teams to translate data requirements into robust data pipelines and process workflows.; Design, build, and maintain real-time and batch data pipelines using Kafka, Spark Streaming, AWS EMR, Glue, Lambda, and other AWS services to; ingest and process high-frequency data from diverse internal and external sources.; Implement data partitioning, compaction, and optimization techniques to improve data processing performance and reduce cloud storage costs.; Assist in incident investigations, root cause analysis, and resolution of data pipeline failures or performance bottlenecks.; Document data flow designs, ingestion standards, and transformation logic clearly for use by other engineers, data stewards, and auditors.; QUALIFICATIONS; Required:; Minimum 2 years of experience (or 5 years for a senior position) in Data Engineering, Software Engineering or related fields.; Proven experience building and managing real-time and batch data pipelines on AWS using services such as EMR, Glue, Lambda, S3, and EC2.; Strong knowledge of Python and Spark, with hands-on experience designing low latency ETL\/ELT pipelines.; Experience handling large-scale datasets and optimizing cloud storage formats and query performance.; Familiarity with infrastructure components such as IAM roles, Security Groups, and VPC networking to support secure data access and movement.; Hands-on experience with Linux environments, shell scripting, and AWS CLI for managing data and computation resources.; Strong communication and collaboration skills to work across data, engineering, and network teams.; Ability to maintain clean, structured documentation of ingestion logic, transformation steps, and data flow dependencies.; Preferred:; Certifications in cloud technology platforms (such as cloud architecture, container platforms, systems, and\/or network virtualization).; Knowledge of telecom networks, including mobile and fixed networks, will be an added advantage.; Familiarity with data fabric and data mesh concepts, including their implementation and benefits in distributed data environments, is a bonus.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84393093","Role":"Senior Data Engineer","Company":"Avatar Techno Service","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84393093","job_desc":"Company; Avatar Techno Service; avatartechno.com; Designation; Senior Data Engineer; Date Listed; 21 May 2025; Job Type; Experienced \/ Senior Executive; Full\/Perm; Job Period; Immediate Start, Permanent; Profession; IT \/ Information Technology; Industry; Computer and IT; Location Name; Singapore; Allowance \/ Remuneration; $8,000 monthly; Company Profile; Avatar Techno Services is a global IT Solutions and Services Company established in 2019 with its corporate headquarters in Singapore. We continue to expand our global network while providing value-added cost-effective consulting services to our clients. By 2020 Avatar Techno Services became a leading provider of client-focused IT services and started focusing on IT solutions.; Our services are designed to drive innovation and expansion into new marketplaces while reducing overall costs.; In today\u2019s competitive global market, businesses need technology partners who can understand business strategy and deliver seamless solutions with emerging technologies.; Our team is committed in providing all IT activities right from outsourcing solutions, Infra-structure setup, security consultancy, maintenance, support, project management, software development, testing and much more, which can be tailored on a case-to-case basis.; Our business is committed to offer a resource pool of highly skilled, industry-savvy professionals with a wide range of experience to meet the client\u2019s project requirement or as permanent addition.; Job Description; - Builds and maintains data pipelines.; - Works related to extracting transactional data, transforming for enrichment\/cleansing, and loading into data warehouses or reconciliation tools.; - Works closely with TLM (Transaction Lifecycle Management) teams for accurate and timely data integration.; Key Responsibilities:; ETL Pipeline Design and Development:; Design, develop, and maintain robust ETL processes and pipelines to extract data from diverse banking systems (e.g., CRM, transaction systems, loan management systems).; Data Transformation and Validation:; Implement data cleansing, transformation, and validation steps to ensure data quality and consistency.; Data Warehouse Management:; Work with data warehouse load and manage transformed data, optimizing performance and scalability.; Design and implement data models to support business reporting and analytics needs.; Integration with Existing Systems:; Collaborate with other teams to integrate new ETL processes with existing banking systems.; Data Security and Governance:; Implement data security measures and ensure compliance with regulatory requirements related to data protection and privacy.; Monitoring and Optimization:; Monitor ETL pipeline performance, identify bottlenecks, and optimize processes for efficiency and scalability.; Troubleshooting and Support:; Provide technical support for ETL processes, troubleshoot issues, and resolve data-related problems.; Documentation:; Maintain comprehensive documentation of ETL processes, data models, and data flows.; Collaboration:; Collaborate with other data engineers, data scientists, and business stakeholders to understand requirements and deliver solutions.; Required Skills:; ETL Tools and Technologies: Proficiency in ETL tools (e.g., Talend, Informatica, SSIS), scripting languages (e.g., Python, SQL), and data warehouse technologies; Data Modeling: Understanding of data modeling principles and techniques, including relational and dimensional modeling.; Data Quality and Governance: Knowledge of data quality principles and data governance frameworks.; Database Management: Experience with database systems (e.g., Oracle, SQL Server, MySQL) and SQL.; Programming and Scripting: Proficiency in programming languages like Python or Scala.; Communication and Collaboration: Strong communication and collaboration skills to work effectively with cross-functional teams.; Experience:; Seven years of experience in data engineering, with a focus on ETL processes in a banking or financial services environment.; Experience with data warehousing,; Application Instructions; Please apply for this position by submitting your text CV using InternSG.; Kindly note that only shortlisted candidates will be notified.; Apply for this position","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85483082","Role":"DATA ENGINEER","Company":"KAVESSAA CONSULTANCY PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-04 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85483082","job_desc":"Key Responsibilities:; 1. ETL\/ELT Development & Data Integration:; \u2022Design, develop, and implement ETL\/ELT pipelines using Informatica IDMC, PowerCenter, IICS (Informatica Intelligent Cloud Services).; \u2022Integrate data from multiple sources, including databases, cloud storage, APIs, and streaming services.; \u2022Optimize data transformations, mappings, workflows, and parameterized sessions.; \u2022Implement real-time and batch data processing solutions.; 2. Cloud & On-Premises Data Integration:; \u2022Work with IDMC (Informatica Cloud) to integrate data across AWS, And Databricks.; \u2022Design data pipelines for hybrid cloud environments (on-prem to cloud migrations).; \u2022Utilize Cloud Data Integration (CDI), Cloud Application Integration (CAI), and Data Quality (CDQ) modules.; \u2022Leverage Informatica Data Governance, Metadata Management, and Axon Data Governance.; 3. Performance Optimization & Troubleshooting:; \u2022Monitor and optimize ETL\/ELT jobs for performance, scalability, and efficiency.; \u2022Troubleshoot data integration failures, bottlenecks, and error handling.; \u2022Optimize SQL queries, session parameters, and pushdown optimization.; 4. Data Governance & Security:; \u2022Implement data quality rules, profiling, cleansing, and standardization.; \u2022Manage role-based access control (RBAC), encryption, and audit logs.; 5.Collaboration & Documentation:; \u2022Work with data analysts, business intelligence (BI) teams, and cloud engineers to ensure high-quality data availability.; \u2022Document ETL\/ELT processes, technical specifications, and best practices.; \u2022Provide training and support to data teams on Informatica tools and cloud data integration best practices.; Required Skills & Qualifications:; Technical Skills:; \u2022Strong experience with Informatica IDMC, PowerCenter, IICS (CDI, CAI, CDQ), and Informatica Cloud.; \u2022Expertise in SQL, PL\/SQL, and relational databases (Oracle, SQL Server, PostgreSQL, databricks, Redshift).; \u2022Experience with cloud data services (AWS Glue, Databricks).; \u2022Knowledge of APIs, RESTful services, JSON, XML, and web service integrations.; \u2022Proficiency in performance tuning, pushdown optimization, and parallel processing.; \u2022Familiarity with data governance, data lineage, and metadata management tools.; Soft Skills:; \u2022Strong problem-solving and analytical skills.; \u2022Ability to work independently and collaboratively with cross-functional teams.; \u2022Excellent communication, documentation, and presentation skills.; \u2022Strong attention to detail and ability to manage multiple projects simultaneously.; Qualifications:; \u2022Informatica Certified Professional (ICP) or IDMC certification.; \u2022Experience with Python, Spark, or Shell scripting for automation.; By submitting the application, you have agreed and consented to us collecting, using, retaining, and disclosing your personal date to prospective employers for their consideration.; EA Reg. No: R24122248 |EA License No. 24C2237","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85220289","Role":"AVP - Data Platform Operations","Company":"The Great Eastern Life Assurance Company Limited","Location":"Central Region","Publish_Time":"2025-06-27 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85220289","job_desc":"We\u2019re looking for a motivated Platform Engineer to help design, build, and maintain scalable data platform infrastructure that supports smooth operations across our hybrid cloud environment. The role involves close collaboration with database, network, infrastructure, and business teams.; Data & AI Platform Operation and Support ; Configure and administer data platforms including security, performance, and scalability ; Create and manage user accounts and permissions, and manage data access ; Support the administration and daily operations of the data and AI platform, including issue resolution as needed ; Plan and execute upgrades, patches, and maintenance ; Develop and implement backup and recovery strategies ; Collaborate with IT teams to ensure integration with other systems ; Create and maintain SOP documentation ; Align with systems engineering to deploy\/ expand environments ; Collaborate with application teams for OS installations and updates ; Platform Optimization, Automation & Developer Enablement ; Drive continuous improvement in automation, optimization, and developer experience ; Explore and implement new data platform capabilities aligned with business needs ; Optimize platform performance and cost ; Champion \u201ccode base first\u201d DevOps\/ DataOps\/ MLOps practices and build CI\/CD pipelines for reliable Data & AI workflows ; Observability and Reliability ; Monitor platform performance and troubleshoot issues ; Responsible for high availability and performance of applications on platforms ; Capacity planning and scaling ; 24x7 monitoring of server performance, connectivity, and security ; File system management and monitoring ; Teaming with infrastructure, network, and BI teams to ensure data quality and availability ; Governance and Compliance ; Ensure smooth operations and support for the Data & AI platform ; Drive platform optimization, automation, and developer enablement ; Strengthen observability and system reliability ; Bachelor\u2019s Degree in Computer Science, Information Systems, or a related field ; At least 10 years of experience in platform implementation and administration with mandatory 2 years of hands-on experience in Tableau, Hadoop\/Cloudera, Informatica, Dataiku and AWS or equivalent technologies. ; Practical experience with DevOps practices including automation, CI\/CD, infrastructure as code, and code-first approaches for data workflows and deployments; Strong expertise in implementing comprehensive monitoring solutions using tools like Prometheus, Grafana, Dynatrace and Datadog, combined with deep experience in SRE practices including SLI\/SLO definition, incident response automation, chaos engineering, and distributed tracing across microservices architectures; Skills in driving continuous improvement through automation tools, optimizing platform performance and costs, and enhancing developer experience; Good understanding of OS concepts, process management and resource scheduling; Basics of networking, CPU, memory and storage; Good hold of shell scripting","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85219825","Role":"Core Engineering, Data Software Engineer, Analyst\/ Associate, Singapore","Company":"Goldman Sachs","Location":"Singapore","Publish_Time":"2025-06-27 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85219825","job_desc":"Core Engineering, Data Software Engineer, Analyst\/ Associate, Singapore; Goldman Sachs employs thousands of engineers across many divisions. We write software that powers every aspect of our business. It's no surprise that we collect and analyze vast amounts of data relating to the efficiency of our development processes, the value that we drive through software, and the effectiveness of how we leverage our internal tooling and services to empower development. Our data allows our internal businesses to optimize, focus their attention and manage costs. It allows us to assess the impact and performance of developer productivity initiatives, cost saving initiatives, and manage our huge software inventory.; What We Need; We are seeking a highly skilled Data Software Engineer to design, implement, and maintain robust data systems and pipelines that empower our organization to leverage data effectively. The ideal candidate will come from a software engineering background, with commercial development experience in one or more object-oriented languages (Python, Go, Java, C#). Knowledge of data modeling, pipeline construction, data normalization and sanitization, and data governance would be highly advantageous. They will collaborate with cross-functional teams to ensure the availability, quality, and security of data to support business objectives.; Key Responsibilities; Data Pipeline Development; Design, build, and maintain scalable and efficient data pipelines for processing and transforming large datasets.; Ensure pipelines are optimized for reliability and performance.; Data Modeling and Architecture; Develop and maintain logical and physical data models tailored to business needs.; Optimize data storage solutions for scalability and performance.; Data Quality and Sanitization; Implement processes for data normalization, deduplication, and cleaning to ensure high-quality datasets.; Identify and resolve data inconsistencies, errors, and anomalies.; Data Governance and Security; Establish and enforce data governance standards, including policies for data access, compliance, and privacy.; Implement security measures to protect sensitive data and ensure compliance with regulatory requirements.; Monitoring and Optimization; Develop monitoring solutions to ensure the health and reliability of data pipelines and systems.; Continuously optimize performance, storage, and costs of data infrastructure.; Qualifications; Education:; Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, Data Science, or a related field.; Experience:; Min. 1 year (for Analyst)\/ 3 years (for Associate) of experience in software engineering, data engineering or a related role.; Proven experience with data modeling, ETL\/ELT pipelines, and data architecture design.; Proficiency in programming languages such as Python, Java, or Scala.; Strong knowledge of SQL and relational databases (e.g., PostgreSQL, Sybase, SQL Server).; Desirable Technical Skills:; Experience with big data technologies (e.g., Hadoop, Spark) and cloud platforms (e.g., AWS, GCP, Azure).; Familiarity with data integration tools (e.g., Apache Airflow, Talend, Informatica) and streaming technologies (e.g., Kafka, Flink).; Experience with data warehouse technologies (e.g., Snowflake, Redshift, BigQuery).; Soft Skills:; Strong analytical and problem-solving abilities.; Effective communication and collaboration skills to work with diverse teams.; Attention to detail and a proactive approach to ensuring data integrity.; Preferred Qualifications; Experience in conforming to data governance frameworks.; Knowledge of data lake architectures and unstructured data processing.; Familiarity with machine learning workflows and AI-driven data applications.; Certifications in relevant technologies (e.g., AWS Certified Data Analytics, Google Professional Data Engineer).; ABOUT GOLDMAN SACHS; At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world. ; We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com\/careers. ; We\u2019re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https:\/\/www.goldmansachs.com\/careers\/footer\/disability-statement.html; \u00a9 The Goldman Sachs Group, Inc., 2023. All rights reserved.; Goldman Sachs is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, national origin, age, veterans status, disability, or any other characteristic protected by applicable law.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84249971","Role":"Data Engineer, Associate\/Senior Associate, Data & AI, Technology Consulting","Company":"Ernst & Young Solutions LLP","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84249971","job_desc":"At EY, you\u2019ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we\u2019re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. ; The opportunity; EY DnA is the data and advanced analytics capability within EY Asia-Pacific, with over 500 specialist employees working across multiple industry sectors.; We implement information-driven strategies, data platforms and advanced data analytics solution systems that help grow, optimize and protect client organizations. We go beyond strategy and provide end to end design, build and implementation of real life data environments and have some of the best architects, project managers, business analysts, data scientists, big data engineers, developers and consultants in the region.; We are looking for a Data Engineer (Associate\/Senior Associate) within the DnA team in our Singapore office. This role is offered on a full time basis.; Your key responsibilities; Design, build, and maintain efficient, reusable, and scalable ETL\/ELT pipelines for structured and unstructured data.; Develop and optimize data workflows to support advanced analytics, machine learning models, and reporting tools.; Collaborate with data scientists, analysts, and business stakeholders to gather requirements and ensure data quality and availability; Work with cloud and on-prem data platforms (e.g., AWS, Azure, GCP, Hadoop, or on-prem SQL\/NoSQL systems).; Ensure data integrity, governance, and security best practices across pipelines and data lakes\/warehouses.; Troubleshoot and resolve data issues and performance bottlenecks in real-time and batch pipelines.; Monitor job performance and implement automation and alerting for data operations.; Contribute to documentation, code reviews, and development best practices.; Skills and attributes for success; 2\u20136 years of experience in data engineering or related roles.; Proficient in SQL, Python, or Scala for data processing.; Experience with data orchestration tools like Apache Airflow, DBT, or Luigi.; Familiarity with cloud platforms (AWS Glue, Azure Data Factory, GCP Dataflow, etc.).; Hands-on experience with data warehouses such as Snowflake, BigQuery, or Redshift.; Understanding of data modeling, normalization, and data warehousing concepts.; Exposure to CI\/CD, version control (Git), and agile development practices.; To qualify for the role, you must have; Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, or related field.; Knowledge of streaming data frameworks (Kafka, Spark Streaming, Flink) is a plus.; Experience working in consulting or client-facing environments (for Senior Associate roles).; Certifications in AWS\/Azure\/GCP or specific data tools.; What we look for; Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry.; An effective communicator, you\u2019ll be a confident leader equipped with strong people management skills and a genuine passion to make things happen in a dynamic organization.; What we offer; EY offers a competitive remuneration package commensurate with your work experience where you\u2019ll be rewarded for your individual and team performance. We are committed to being an inclusive employer and are happy to consider flexible working arrangements, where this may be needed, guided by our FWA Policy.; Plus, we offer:; Continuous learning: You\u2019ll develop the mindset and skills to navigate whatever comes next.; Success as defined by you: We\u2019ll provide the tools and flexibility, so you can make a meaningful impact, your way.; Transformative leadership: We\u2019ll give you the insights, coaching and confidence to be the leader the world needs.; Diverse and inclusive culture: You\u2019ll be embraced for who you are and empowered to use your voice to help others find theirs.; If you can demonstrate that you meet the criteria above, please contact us as soon as possible.; The exceptional EY experience. It\u2019s yours to build.; Apply now.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85667318","Role":"Infrastructure Engineer","Company":"HCL Singapore Pte Ltd","Location":"Central Region","Publish_Time":"2025-07-11 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85667318","job_desc":"Responsibilities; Design, implement, and maintain observability solutions using Datadog tools including:; Infrastructure Monitoring, Log Management, APM, RUM, Synthetic Monitoring, Network Monitoring, Dashboards, and Alerts; Configure and maintain Datadog Agents, custom integrations, and support cloud-native (AWS, Azure, GCP) and on-premises workloads; Develop custom dashboards and monitors to support SRE and DevOps teams; Implement correlation of metrics, logs, traces, and events for end-to-end visibility; Lead performance monitoring, outage analysis, and root cause investigations; Work with application developers, infrastructure, and security teams to improve observability maturity; Ensure optimal Kubernetes monitoring setup via Datadog Cluster Agent and integration with Helm, Prometheus, and custom metrics; Automate deployment and configuration using IaC tools (Terraform preferred); Optimize usage and cost of Datadog through tagging strategy, metric hygiene, and data retention policies; Requirements; Bachelor\u2019s degree in computer science\/ information technology or equivalent; 3 years of hands-on experience with Datadog in a production environment; Strong understanding of core observability concepts and distributed systems monitoring; Cloud Platforms (AWS, GCP, or Azure); Kubernetes \/ EKS \/ GKE \/ AKS monitoring with Datadog; Log aggregation and parsing (Groks, pipelines, enrichment); RUM and Synthetic Monitoring setup and tuning; CI\/CD and DevOps toolchains; Proficiency with Datadog Agent, integrations, APIs, and CLI tools; Scripting and automation skills (Python, Bash, or similar); Familiarity with Infrastructure as Code (Terraform, Ansible, or similar); Excellent problem-solving and communication skills; Datadog certifications (e.g., Datadog Fundamentals, APM, Infrastructure); Experience working in regulated or high-compliance environments; Background in SRE, DevOps, or Platform Engineering roles; Knowledge of additional monitoring tools (e.g., Prometheus, Grafana, Splunk)","salary":"$4,500 \u2013 $6,500 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85176733","Role":"Data Engineer - Singapore","Company":"Shopline","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85176733","job_desc":"Data Engineer - SHOPLINE Singapore; SHOPLINE is Asia\u2019s largest smart commerce platform. With our customers in mind, we strive to deliver scalable commerce solutions to merchants of all sizes. We\u2019re a full-featured platform with services including online store opening, O2O solution, retail POS systems, advertising placement, business strategy consultation, marketing, and more to empower merchants to succeed in omnichannel retailing and cross-border commerce.; What you\u2019ll be doing:; Responsible for collecting, designing, storing and processing payments data in the eCommerce business. In charge of unifying and standardizing data to create holistic business digital assets.; Play a leading role in constructing business evaluation metrics, developing tactics in data services and creating data-driven tools in alignment with Products and Operations objectives.; Define underlying business data requirements. Build fitted models to enhance data quality and stability. Standardize and maintain data integrity to provide an efficient way in accessing data.; Who we are looking for:; 5+ years of experience as a data engineer with a bachelor or advanced in Computer Science. Proven track record in data warehousing.; Demonstrated strength in data modeling, development and governance. Preferred experience with building ETL pipelines.; Expert skills in SQL and Python. Familiarity with big data technologies and solutions (Spark, Hadoop, Hive, etc.). Nice to have a background in Machine Learning.; Proven success in communicating across different functions and synthesizing resources to push through projects in a dynamic environment.; Preferred experience in tech firms, especially in the payments industry.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85837188","Role":"Core Engineering, SDLC \u2013 Developer Collaboration Software Engineer,...","Company":"Goldman Sachs Bank AG","Location":"Singapore","Publish_Time":"2025-07-17 08:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85837188","job_desc":"Core Engineering, SDLC \u2013 Developer Collaboration Software Engineer, Associate\/ Vice President, Singapore location_on Singapore; OVERVIEW:; At Goldman Sachs, our Engineers don\u2019t just build things \u2013 we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.; Engineering, which is comprised of our Technology Division and Global Strategist groups, is at the center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions.; CORE ENGINEERING \u2013 DEVELOPER COLLABORATION; The Developer Collaboration team owns the Atlassian toolset, focusing on JIRA and Confluence at Goldman Sachs. Our teampartners withinternal stakeholders across business units andfunctional groupsgloballyto drive strategic engineering and collaboration initiatives that deliver end user outcomes, while creating andmaintainingan outstanding customer experience, at scale.; SDLC @ GS:; The SDLC organization is the base and platform on which all technology solutions across the firm are managed. You will be working in the heart of developer experience, ensuring code that is written by thousands of GS engineers is versioned securely, reviewed expertly, compiles fast, is comprehensively tested, compliant, and distributed widely. We empower thousands of developers and all teams across the firm to innovate better, faster, more securely, and in a fully compliant manner, all while striving to create an easy to use, stable, performant, and frictionless ecosystem.; RESPONSIBILITIES:; Own, manage and automate infrastructure and deployments across a variety of environments, including development, testing and production.; Own, implement and maintain continuous integration and delivery pipelines.; Design, configure and manage observability for our systems to ensure application availability and performance.; Own relationships with senior stakeholders and our client development teams to ensure that their needs are met as well as those of the firm.; Implement and maintain security controls and compliance requirements.; Ensure that production issues are addressed in a timely manner, including post mortem and longer term steps to avoid repetition.; Stay current with emerging technologies and tools in the DevOps space.; Advocate for improvements to product quality, security, reliability, and performance.; Develop custom integrations and interfaces between external tooling and Jira\/Confluence infrastructure as needed.; SKILLS AND EXPERIENCE WE ARE LOOKING FOR:; 3+ years (Associate) \/ 8+ years (VP) of experience in a software development, DevOps or related role.; Professional experience with CI \/CD tools such as GitLab, Jenkins, CircleCI or Bitbucket.; Professional experience with cloud deployment patterns. Specifically AWS cloud constructs, Terraform, Docker, Kubernetes, and Kafka.; General knowledge of multiple languages and expert in-depth knowledge of at least one of: Golang, Java, Python, C, C++.; Strong software engineering and system design fundamentals.; Experience with all stages of SDLC.; Experience with SRE principles, as well as diagnosis, prevention, performance management, and availability of large distributed systems.; Strong written and verbal communication.; Excellent problem-solving and analytical skills.; Ability to work collaboratively in a team environment.; PREFERRED QUALIFICATIONS:; BSc, MSc, PhD in relevant field (Computer Science, Information Systems, or similar).; Experience with Prometheus and Grafana, as well as knowledgeable about networking protocols (TCP, UDP, ICMP, ARP, DNS, TLS, HTTP, SSH, etc.); Experience with the use of ML and\/or agentic AI, especially in relation to facilitating the SDLC.; Experience in stakeholder management.; ABOUT GOLDMAN SACHS; At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.; We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com\/careers.; We\u2019re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https:\/\/www.goldmansachs.com\/careers\/footer\/disability-statement.html; Goldman Sachs is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, national origin, age, veterans status, disability, or any other characteristic protected by applicable law.; Healthcare & Medical Insurance; We offer a wide range of health and welfare programs that vary depending on office location. These generally include medical, dental, short-term disability, long-term disability, life, accidental death, labor accident and business travel accident insurance.; We offer competitive vacation policies based on employee level and office location. We promote time off from work to recharge by providing generous vacation entitlements and a minimum of three weeks expected vacation usage each year.; Financial Wellness & Retirement; We assist employees in saving and planning for retirement, offer financial support for higher education, and provide a number of benefits to help employees prepare for the unexpected. We offer live financial education and content on a variety of topics to address the spectrum of employees\u2019 priorities.; Health Services; We offer a medical advocacy service for employees and family members facing critical health situations, and counseling and referral services through the Employee Assistance Program (EAP). We provide Global Medical, Security and Travel Assistance and a Workplace Ergonomics Program. We also offer state-of-the-art on-site health centers in certain offices.; Fitness; To encourage employees to live a healthy and active lifestyle, some of our offices feature on-site fitness centers. For eligible employees we typically reimburse fees paid for a fitness club membership or activity (up to a pre-approved amount).; Child Care & Family Care; We offer on-site child care centers that provide full-time and emergency back-up care, as well as mother and baby rooms and homework rooms. In every office, we provide advice and counseling services, expectant parent resources and transitional programs for parents returning from parental leave. Adoption, surrogacy, egg donation and egg retrieval stipends are also available.; Benefits at Goldman Sachs; Read more about the full suite of class-leading benefits our firm has to offer.; #J-18808-Ljbffr","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84542865","Role":"Senior Data Engineer","Company":"Plaud AI","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84542865","job_desc":"PLAUD AI is a pioneering AI-native hardware and software company that turns meetings and conversations into actionable insights with AI devices like PLAUD NOTE and PLAUD NotePin. By recording, transcribing, and summarizing real-life conversations, our solutions boost productivity and save time. Designed for precision and flexibility, whether in meetings or on the go, our products empower you to focus on creative, high-value work while AI handles the details.; We are a growing global team of hardware and software experts seeking advanced AI innovations that integrate with real-life user scenarios. Our newly established headquarters in San Francisco will collaborate with our teams in Shenzhen, Beijing, and Tokyo to extend AI benefits to users globally.; Visit https:\/\/www.plaud.ai to learn more.; WHY JOIN US; Join a skyrocketing team where your impact drives success and your career reaches new heights, along with what we have achieved, as shared below.; Global Leadership: Positioned uniquely to lead the future of work by leveraging innovative AI-driven devices and solutions.; Founded in December 2021: Bootstrapped, profitable, and experiencing explosive growth.; 10x Revenue Growth: Achieved 10x revenue growth for two consecutive years, reaching a $100 million run rate, with expectations for even greater expansion in 2025.; Proven Product-Market Fit: Over 700,000 devices shipped globally since November 2023, with users engaging for an average of 30 hours per month to enhance productivity.; New Initiatives: Expanding from consumer-focused products to industry-specific solutions and enterprise-level services.; Loved by Professionals: Our products are trusted by professionals in sectors such as healthcare and sales, where conversations drive success.; WHAT YOU WILL DO; Infrastructure Design and Maintenance: Design, build, and maintain the infrastructure for big data platforms.; ETL Workflow Development: Develop and maintain efficient ETL preprocessing workflows to ensure smooth data extraction, transformation, and loading.; Data Warehouse Design and Optimization: Design, implement, and optimize data warehouses to ensure data is easily accessible and well-organized for analysis.; Data Analysis and Reporting: Conduct detailed data analysis, including data modeling, dashboard development, and data mining, to extract actionable insights for the business.; Optimization and Performance Tuning: Continuously monitor and optimize the performance of data pipelines and systems to ensure data processing is efficient and scalable.; WHAT YOU WILL BRING; Programming Expertise: Proficient in at least one object-oriented programming language, such as Python, Java, or Scala.; Analytical and Problem-Solving Skills: Strong analytical abilities with innovative thinking, capable of independently solving complex technical problems.; Experience: Over 6 years of experience in big data development, including real-time and offline data processing, modeling, ETL development, and data analysis.; Big Data Technologies Knowledge: Deep understanding and practical experience with big data technologies, including Spark, Flink, Hive, and other mainstream big data processing frameworks.; Collaboration and Communication: Strong self-motivation, excellent teamwork spirit, and communication skills. Able to thrive in a fast-paced and dynamic work environment.; Language Proficiency: Proficient in both English and Mandarin for effective work communication in a bilingual environment.; P.S. Mention Tech in Asia Jobs when you apply! Helps keep the good stuff coming \ud83d\ude09","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85068770","Role":"Lead Full Stack Data Engineer (2 year contract)","Company":"StarHub Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85068770","job_desc":"We seek a seasoned Full Stack developer with strong interest and hands-on data engineering skills to design, develop, and deploy AI-powered, cloud-based products. You will own frontend\/backend development, database\/schema design, data pipelines, and integrate user-facing features with data services, collaborating closely with data science and infrastructure teams to deliver production-grade solutions.; As a Lead Full Stack Data Engineer, you will:; \u00b7 Architect & Build Full Stack Applications; \u2022 Design responsive UIs using Next.js, React, Vue, or Angular; \u2022 Implement server-side logic, REST\/GraphQL APIs, and microservices with Nest.js, Node.js, or Express; \u2022 Ensure seamless data flow, authentication (JWT\/OAuth2), and caching (Redis); \u00b7 Design & Maintain Data Pipelines & Databases \u2022 Define data models for relational (PostgreSQL, Redshift) or document stores (MongoDB); \u2022 Develop ETL\/ELT pipelines (PySpark, Airflow) to load data into warehouses; \u2022 Implement scalable storage (tables, indexes, partitions, materialized views) and tune queries; \u00b7 Integrate with Data Services & APIs; \u2022 Consume analytics\/ML endpoints and real-time streams (Kafka, Kinesis); \u2022 Implement efficient data-fetching on the frontend (pagination, caching, debouncing); \u2022 Design endpoints serving aggregated or pre-processed data; manage API versioning\/documentation (Swagger); \u00b7 Implement CI\/CD & DevOps Collaboration; \u2022 Define CI\/CD pipelines (GitLab CI\/CD) for both applications and data workflows; \u2022 Containerize components with Docker; orchestrate with Kubernetes, Docker Compose, or ECS Fargate; \u2022 Collaborate on cloud provisioning (Terraform, CloudFormation) and manage secrets (AWS Secrets Manager); \u00b7 Develop Dashboards & Visualizations; \u2022 Build dynamic charts with D3.js, ECharts, or Recharts to surface key metrics; \u2022 Create real-time data displays using WebSockets or polling; \u2022 Implement frontend data validation (date pickers, filters, drill-downs); \u00b7 Mentorship & Collaboration; \u2022 Mentor junior engineers; conduct code reviews and share best practices; \u2022 Work with product, infra, delivery\/sales specialist teams to refine requirements, automate tests, and enforce security standards; \u00b7 Bachelor\u2019s or Master\u2019s in CS, Software Engineering, Data Science, or equivalent experience; \u00b7 6+ years as a Full Stack developer with demonstrable data engineering involvement; \u00b7 Proficient in JS\/TypeScript frameworks: Next.js, React, Vue, or Angular; \u00b7 Strong Server-side Rendering (Next.js). Node.js experience with Nest.js or Express; RESTful\/GraphQL API design;; \u00b7 ETL\/ELT pipeline development (PySpark, Airflow) and data modeling for PostgreSQL, Redshift, or MongoDB; \u00b7 Experience integrating real-time streams (Kafka, Kinesis) and consuming ML\/analytics endpoints; \u00b7 Define scalable storage (tables, indexes, partitions, materialized views) and perform query tuning (sort keys, distribution keys, vacuum); \u00b7 CI\/CD pipeline creation (GitLab CI\/CD) and containerization (Docker, Kubernetes); \u00b7 Infrastructure as Code: Terraform or CloudFormation; secret management (AWS Secrets Manager); \u00b7 Cloud experience (AWS) deploying full stack apps and data pipelines (S3, EMR, Redshift); \u00b7 Unit\/integration testing (Jest, Mocha, pytest) and E2E testing (Cypress, Playwright); \u00b7 Strong problem-solving, attention to detail, and ability to mentor and collaborate cross-functionally; Nice to Have; \u00b7 Familiarity with serverless architectures (AWS Lambda) and PWA principles; \u00b7 Exposure to vector databases, data mesh or lakehouse architectures; \u00b7 Participation in GenAI POCs (RAG pipelines, Agentic AI demos); \u00b7 Passion for UI\/UX patterns, accessibility, and developer productivity; \u00b7 Client-facing experience in data-driven or AI\/ML projects; \u00b7 Ability to travel 10\u201330%; This is a Malaysia-based role collaborating closely with Singapore team","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85543032","Role":"Senior Data Solutions Architect","Company":"Systems on Silicon Manufacturing Co Pte Ltd","Location":"Singapore","Publish_Time":"2025-07-07 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85543032","job_desc":"SSMC (Systems on Silicon Manufacturing Company Pte. Ltd.), is a Joint Venture between NXP and TSMC. We offer flexible and cost effective semiconductor fabrication solutions by maintaining fully equipped SMIF cleanroom environment, 100% equipment automation and proven wafer-manufacturing processes.; At SSMC, every career journey is unique and rewarding. We're looking for innovative, passionate, and talented people like you to join our team.; We\u2019re searching for a Senior Data Solutions Architect to be part of our IT Department diverse team of talent. You will be responsible in Engineering Analytic Systems Software development, Design and Support. This is a 1-year contract role.; What you will be working on:; Design and architect scalable data lakehouse and data warehouse solutions. ; Implement and manage data storage formats and table formats using Apache Iceberg and Apache Hudi. ; Integrate and optimize Hadoop-based data processing pipelines. ; Deploy and manage MinIO for object storage on premise or cloud-native environments. ; Collaborate with data engineers, analysts, and business stakeholders to define data models and governance strategies. ; Ensure data quality, lineage, and security across the data lifecycle. ; Evaluate and recommend emerging technologies and tools in the data ecosystem. ; Collaborate with cross-functional teams to understand requirements and provide technical guidance. ; Implement Service Request related to internal applications ; Provide support for Internal IT department and External customers ; More About You:; Minimum 5 years good experiences in design and implementation of ETL framework for data lakehouse and data warehouse or related projects ; Proven experience as a Data Architect or similar role in large-scale data environments. ; Deep understanding of Apache Iceberg and Apache Hudi for managing large-scale datasets. ; Hands-on experience with Hadoop ecosystem (HDFS, YARN, Hive, Spark, etc.). ; Proficiency in deploying and managing MinIO for high-performance object storage. Excellent troubleshooting skills.; Strong knowledge of data modeling, ETL\/ELT processes, and data governance. ; Familiarity with cloud platforms (AWS, Azure, GCP) and containerization (Docker, Kubernetes) is a plus. ; Excellent problem-solving, communication, and collaboration skills. ; Working knowledge of semiconductor industry ; Experience with BI reporting such as tableau or PowerBI or equivalent will be advantageous ; Good team player with pro-activeness and good initiatives Must be able to work independently.; Good communication and interpersonal skill.; SSMC is committed to equal employment opportunities and abides by the Tripartite Guidelines on Fair Employment Practices (TGFEP). All qualified applicants will receive non-discriminatory consideration for employment on the basis of merit and regardless of age, race, gender, religion, marital status and family responsibilities, or disability, or any other attributes as protected by the relevant laws.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85742158","Role":"Site Reliability Engineer - Data Management Suite","Company":"TikTok Pte. Ltd.","Location":"Central Region","Publish_Time":"2025-07-14 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85742158","job_desc":"About TikTok; TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and we also have offices in New York City, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.; Why Join Us; Inspiring creativity is at the core of TikTok's mission. Our innovative product is built to help people authentically express themselves, discover and connect \u2013 and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and bring joy - a mission we work towards every day.; We strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. Every challenge is an opportunity to learn and innovate as one team. We're resilient and embrace challenges as they come. By constantly iterating and fostering an \"Always Day 1\" mindset, we achieve meaningful breakthroughs for ourselves, our company, and our users. When we create and grow together, the possibilities are limitless. Join us.; Diversity & Inclusion; TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Job highlights; Industry experts, Meals provided, Competitive compensation, Flexible hours; Responsibilities; About the Team; The Data Management Suite team is building products that cover the whole lifecycle of data pipeline, including data ingestion and Integration, data development, data catalog, data security and data governance. These products support various businesses, so data engineers and data scientists could greatly boost their productivity.; As a software engineer in the data management suite team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on core systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.; Responsibilities:; Be responsible for the production stability for big data development and governance systems;; Engage in and improve the whole lifecycle of service, from inception and design, through to deployment, operation and refinement;; Maintain services once they are live by measuring and monitoring availability, latency and overall system health. Practice sustainable incident response and blameless postmortems;; Establish best engineering practice for engineers as well as non-technical people;; Design and implement reliable, scalable, robust and extensible big data systems that support core products and business;; Qualifications; Minimum Qualifications; Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience; Experience with site reliability engineering, monitoring, alerting for big data related systems; Experience writing code in Java, Go, Python or a similar language; Preferred Qualifications; Knowledge about a variety of strategies for ingesting, modeling, processing, and persisting data, ETL design, job scheduling and dimensional modeling;; Familiarity with running production grade services at scale and understanding cloud native technologies and networking;; Experience developing tools and APIs to reduce human interaction with systems and applications using a variety of coding and scripting standards;; Expertise in designing, analyzing, and troubleshooting large-scale distributed systems is a plus (Hadoop, M\/R, Hive, Spark, Presto, Flume, Kafka, ClickHouse, Flink or comparable solutions);; Systematic problem-solving approach, coupled with effective communication skills and a sense of drive;","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85312773","Role":"Data Solutions Architect","Company":"CAPGEMINI SINGAPORE PTE. LTD.","Location":"Marina South","Publish_Time":"2025-07-01 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85312773","job_desc":"Choosing Capgemini means choosing a company where you will be empowered to shape your career in the way you\u2019d like, where you\u2019ll be supported and inspired by a collaborative community of colleagues around the world, and where you\u2019ll be able to reimagine what\u2019s possible. Join us and help the world\u2019s leading organizations unlock the value of technology and build a more sustainable, more inclusive world.; YOUR ROLE; Are you passionate about designing innovative data solutions that align with business strategies and drive organizational transformation? We are seeking a seasoned Data Solutions Architect to lead the design, development, and implementation of enterprise data strategies and architectures. If you have extensive experience in data engagements and a strong background in banking domains, we\u2019d love to hear from you.; Architecture and Strategy; \u2022 Understand existing landscapes, client capabilities, and requirements to design scalable, high-performance, and reliable data solutions.; \u2022 Build data pipelines to ingest, store, process and publish data, data models and Unit testing; Develop enterprise data strategies aligned with business objectives, including data roadmaps and transformation projects.; \u2022 Design and implement various data architecture models, including data warehouse, integration, and business information models.; \u2022 Provide strategic guidance, roadmaps, and detailed implementation plans for data solutions.; Leadership and Development; \u2022 Lead cross-functional teams to design and develop data solutions as per proposed architectures.; \u2022 Act as the primary point of contact for architecture design and development queries.; \u2022 Identify and adopt new technologies and methodologies to enhance performance, automation, and scalability.; Business Development Support; \u2022 Collaborate with the sales team to shape and design solution architectures for proposals.; \u2022 Participate in client meetings, addressing technical and strategic concerns.; Governance and Compliance; \u2022 Define and implement data governance frameworks, including assessments, roadmaps, and execution plans.; \u2022 Ensure compliance with analytical, regulatory, and compliance reporting requirements.; Experience and Qualifications; Primary Skills; \u2022 15+ years of experience in data engagements, including leading data strategies, roadmaps, and implementations.; \u2022 Expertise in data architecture methodologies, including enterprise data strategy, data models (ER, star schema, normalized\/denormalized), and lifecycle management.; \u2022 Proven banking domain knowledge and experience with regulatory compliance and reporting.; \u2022 Strong experience in data migration strategies, including planning, costing, and execution.; \u2022 Master Data Management expertise, with tools such as Informatica MDM, Stibo PIM, Talend Data Fabric.; Technical Proficiencies; \u2022 Required Skills: Spark SQL (Python) +ADO CICD; Spark Structure Streaming (Python) + ADO CICD, Java + Spark Scala + ADO CICD; \u2022 Data and Architecture Tools: PowerDesigner, ArchiMate, Toad, ERWin.; \u2022 Databases: PostgreSQL, Oracle, SQL Server, DB2, Teradata, Hive, Pig, Impala, MongoDB, Cassandra, HBase, Snowflake.; \u2022 Programming and Scripting: SQL, PL\/SQL, NoSQL, Shell scripting, T-SQL, DAX.; \u2022 Design Methodologies: Inmon and Kimball methodologies, hierarchical models.; \u2022 Cloud and Web Tools: Amazon AWS, WordPress, Google Analytics\/GTM.; Additional Skills; \u2022 Familiarity with TOGAF for architecture frameworks and DAMA-DMBOK for data management.; \u2022 Experience in tools like MS Project, JIRA, and rLean for management.; WHAT YOU\u2019LL LOVE ABOUT WORKING HERE; \u2022 We promote Diversity & Inclusion as we believe diversity of thought fuels excellence and innovation.; \u2022 In Capgemini, you are the architect of your career growth. We equip people in maximizing their full potential by providing wide array of career growth programs that empower them to get the future they want.; \u2022 Capgemini fosters impactful experiences for its people that would aid in bringing out the best in them for them, for the company, and for their clients.; Disclaimer:; Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin gender identity\/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.; This is a general description of the Duties, Responsibilities, Qualifications required for this position. Physical, mental, sensory, or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity. Capgemini will consider reasonable accommodations that might involve varying job requirements and\/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship. Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.; Click the following link for more information on your rights as an Applicant http:\/\/www.capgemini.com\/resources\/equal-employment-opportunity-is-the-law; ABOUT CAPGEMINI; Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, cloud and data, combined with its deep industry expertise and partner ecosystem. The Group reported 2023 global revenues of \u20ac22.5 billion.; Get the future you want | www.capgemini.com","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84359312","Role":"Vice President, Data Engineer, Group Technology","Company":"United Overseas Bank Limited (UOB)","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84359312","job_desc":"United Overseas Bank Limited (UOB) is a leading bank in Asia with a global network of more than 500 branches and offices in 19 countries and territories in Asia Pacific, Europe and North America. In Asia, we operate through our head office in Singapore and banking subsidiaries in China, Indonesia, Malaysia and Thailand, as well as branches and offices. Our history spans more than 80 years. Over this time, we have been guided by our values \u2013 Honorable, Enterprising, United and Committed. This means we always strive to do what is right, build for the future, work as one team and pursue long-term success. It is how we work, consistently, be it towards the company, our colleagues or our customers.; ; Group Technology and Operations (GTO) provides software and system development, information technology support services and banking operations.; We have centralized and standardized the technology components into Singapore, creating a global footprint which can be utilized for supporting our regional subsidiaries and the branches around the world. We operate and support 19 countries with this architecture to provide a secure and flexible banking infrastructure.; Our Operations divisions provide transactional customer services for our businesses while also focusing on cost efficiency through process improvements, automation and straight through processing.; You will be responsible for the end-to-end software development and support for all work related to Enterprise Data Warehouse (EDW) projects, quarterly change requests, L3 production fixes. This includes software product implementation and administration, application design, development, implementation, testing and support. You will be expected to work on Data team.; ; You will also be responsible for quality assurance of the team\u2019s delivery in conformance with the Bank-defined software delivery methodology and tools. You will partner with other technology functions to help deliver required technology solutions.; Create frameworks, technical features which helps in faster operationalisation of Data models, Analytical models(including AI\/ML) and user generated contents (dashboards, reports etc); Effectively partner with citizen data scientists in enabling faster adoption of AL\/ML model based systems; Independently install, customise and integrate software packages and programs; Carry out POCs involving new data technologies; Design and develop application frameworks for data integration; Create technical documents such as solution design, program specifications for target solutions; Perform design and development of applications which may not be limited to: Software Applications, Data Integration, User Interfaces, Automation Maintain and recommend software improvements to ensure a platform centric management of software applications; Performance tuning; Work with production support team members to conduct root cause analysis of issues, review new and existing code and\/or perform unit testing; Perform tasks as part of a cross functional development team using agile or other methodologies and utilising project management software; Hands-on experience in implementing large scale data warehouse, Data mart & analytics platforms in financial services industry with good functional knowledge of products & services offered in Retail bank \/ Wholesale \/ Global Markets covering some of the following analytics domains:; Experience in Data Modeling, Data mapping for Data Warehouse and Data Marts solutions; Expertise in FSLM or similar industry models; Expertise in Reference data management \u2013 Tools experience such as MDM (Master Data Management); Experience in functional domain - Retail , Wholesale, Compliance , Digital; Experience in analytics - Retail Analytics; Expertise in design of role based fine grained access control; Designing cloud ready data solutions, Virtualization  ; Technical skillsets -ML Model operationalization, Building Data Pipelines and Hadoop based Data marts; Expertise in implementing Big Data frameworks using multiple SQL engine such as Spark, Impala, Hive, etc; Expertise in implementing Hadoop based Data mart using Spark based framework (Java, Scala, Pyspark); Leverage LLM model to build intelligent data applications (eg: Natural Language based SQL generation); Experience in end to end AI \/ ML life cycle (Data pipeline, model training, Model development, deployment, fine tuning, etc); Expertise in building Data federation solution(Trino, Presto, Dremio, Query Grid) along with Data caching \/ Indexing; Experience in working with any of Data Catalog tools and Automating Data Quality checks using frameworks; Good Working experience in core technical area using Python, Java, PySpark and Scala; Expertise in Cloudera CDP components; Good knowledge in developing Spark based ingestion framework (Java, Scala, Pyspark); Experience in building and operationalising feature pipeline to support AI\/ML model execution, data pipelines for supporting large scale data warehouse\/data marts; Additional requirements -   2 to 3 technical certifications from enclosed list:; Cloudera Hadoop distribution     \u2013 Hive, Impala, Spark, Kudo, Kafka, Flume; Teradata             \u2013 Bteq, Query Grid, GCFR, MDM, TAS, Data Mover, BAR; Informatica Data Integration     \u2013 PC, IDR, BDM, MM, IDQ, EDC; Data modelling tools (Erwin); QlikSense; Microsoft \u2013 R; Data science workbenches \u2013 Cloudera Machine Language, Jupyter, DataRobot, H2O.AI, IBM DSX; Data Virtualization tool (Denodo, Dremio); AS400; Language \u2013 SQL, Java, Python, Scala, Pyspark; Automation \/ scripting \u2013 CtrlM, Shell Scripting, Groovy ; UOB is an equal opportunity employer. UOB does not discriminate on the basis of a candidate's age, race, gender, color, religion, sexual orientation, physical or mental disability, or other non-merit factors. All employment decisions at UOB are based on business needs, job requirements and qualifications. If you require any assistance or accommodations to be made for the recruitment process, please inform us when you submit your online application.; Apply now and make a difference.; Competencies; 1. Strategise; 2. Engage; 3. Execute; 4. Develop; 5. Skills; 6. Experience","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85810846","Role":"Data Engineer, Global E-Commerce (Governance Service - Risk Control Platform)","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85810846","job_desc":"Responsibilities; Global E-Commerce is a content e-commerce business with international short video product as the carrier. It is committed to becoming the first choice for users to discover and purchase good products with affordable prices. Global E-Commerce business team hopes to provide users with more tailored and efficient consumption experience, enabling merchants to receive reliable platform services in different scenarios such as live e-commerce, short video content e-commerce, thereby making more affordable and high-quality products easily accessible and improving lives.; The Global E-Commerce Risk Control Team is committed to combating risks with groups in the underground black industry, building a risk protection system for the platform, identifying current and future risk trends through human-machine collaboration, and promoting the prevention and control of business to support the rapid development of TikTok's e-commerce business. We are seeking passionate data engineers with strong problem-solving abilities to work hand in hand with talented cross-functional partners (business operations, data science, engineering, and product management) to efficiently solve some highly challenging data development and construction tasks. In this position, you will contribute to the company's core business, and your daily work will directly impact the company's and customers' financial security and business strategic planning.; Responsibilities:; Collaborate closely with product managers, strategic operations, internal engineering teams, etc. to understand data requirements and provide data solutions that meet business needs.; Evaluate, implement, and maintain data infrastructure tools and technologies to support efficient data processing, storage, and querying.; Design, build, and optimise scalable data pipelines to ingest, process, and transform large volumes of data to support complex analytical queries and reporting requirements.; Ensure data integrity, accuracy, and consistency by implementing data quality checks, validation processes, and monitoring mechanisms.; Continuously optimise data pipelines, queries, and processes to improve performance, reduce latency, and enhance scalability.; Build and maintain the data assets for the risk control business at a high level, serving as the foundation for engineering and product applications.; Qualifications; Minimum Qualifications:; Bachelor's or higher degree in Computer Science, Information Technology, Programming & System Analysis, Science (Computer Studies) or related discipline.; Have experience as a data engineer or similar role supporting data-centric businesses.; Solid knowledge of SQL and work experience with relational and non-relational databases.; Proficiency in at least one programming language such as Python, Java, Go, etc.; Solid mastery of data modeling and data warehouse concepts, data integration, and ETL\/ELT technologies.; Effective communication skills and the ability to collaborate effectively with cross-functional teams.; Excellent problem-solving skills, attention to detail, and the ability to thrive in a fast-paced environment.; Preferred Qualifications:; Experience in using big data technologies (such as Apache Hadoop, Spark, Kafka, Flink) and working experience in handling data ranging from TB to PB levels.; Experience in data governance, e-commerce data, data privacy, and compliance.; Experience in the cross-border\/payment\/e-commerce\/risk control industries.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85206352","Role":"Data Engineer","Company":"MERIDIAN & SATURN CAPITAL PTE. LTD.","Location":"Singapore","Publish_Time":"2025-06-26 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85206352","job_desc":"MS Capital is a private fund management company with a strong founding team of long-accumulated experience in strategy modelling, trading system and platform development, adopting advanced artificial intelligence technology as the cornerstone, and enforcing strict investment management, to achieve sustained and stable returns. We are expending the team, searching for experienced candidates have strong background & skills in programing, statistics modelling, data analysis, etc.; Roles & Responsibilities:; Ingest, standardize, and maintain global equity datasets from multiple third-party vendors (e.g., Bloomberg, Refinitiv, FactSet, S&P Global, Exegy, etc.).; Structure and align data to support quantitative research, factor modeling, and portfolio construction.; Develop systems to track and handle complex corporate actions including ticker changes, delistings, mergers, spin-offs, dual listings, ADR\/local shares.; Collaborate closely with PMs, quantitative researchers, and trading infrastructure engineers to define and fulfill data requirements.; Understand prime brokers\u2019 internal ticker conventions and develop robust mappings across trading venues, custodians, and OMS\/EMS systems.; Ensure data quality through rigorous validation, monitoring pipelines, and anomaly detection.; Help maintain symbol mapping libraries across time zones, exchanges, and asset classes.; Qualifications:; Bachelor's degree or above in Computer Science, Engineering or related field.; Deep familiarity with global equity markets, including North America, Europe, and Asia-Pacific exchanges.; Proficient in Python (Pandas, NumPy), SQL, and data pipeline orchestration tools (e.g., Airflow, Luigi).; Knowledge of major data vendors and experience working with financial reference and pricing data.; Strong understanding of market microstructure and security identifiers (e.g., ISIN, CUSIP, SEDOL, RIC, Bloomberg Ticker).; Ability to navigate prime brokerage data and internal ticker mapping for order execution and post-trade reconciliation.; experience in a data engineering or quantitative data operations role at a hedge fund, proprietary trading firm, or asset manager.; Prior experience working with tick- or bar-level data, especially for intraday equity strategies.; Familiarity with buy-side OMS\/EMS systems and order flow handling.; Interested applicants please apply directly here or send your resume to hr@mscapital.sg","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84360660","Role":"Data Engineer","Company":"Avatar Techno Services","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84360660","job_desc":"Company; Avatar Techno Services; avatartechno.com; Designation; Data Engineer; Date Listed; 20 May 2025; Job Type; Experienced \/ Senior Executive; Full\/Perm; Job Period; Immediate Start, Permanent; Profession; IT \/ Information Technology; Industry; Computer and IT; Location Name; Singapore; Allowance \/ Remuneration; $8,000 monthly; Company Profile; Avatar Techno Services is a global IT Solutions and Services Company established in 2019 with its corporate headquarters in Singapore. We continue to expand our global network while providing value-added cost-effective consulting services to our clients. By 2020 Avatar Techno Services became a leading provider of client-focused IT services and started focusing on IT solutions.; Our services are designed to drive innovation and expansion into new marketplaces while reducing overall costs.; In today\u2019s competitive global market, businesses need technology partners who can understand business strategy and deliver seamless solutions with emerging technologies.; Our team is committed in providing all IT activities right from outsourcing solutions, Infra-structure setup, security consultancy, maintenance, support, project management, software development, testing and much more, which can be tailored on a case-to-case basis.; Our business is committed to offer a resource pool of highly skilled, industry-savvy professionals with a wide range of experience to meet the client\u2019s project requirement or as permanent addition.; Job Description; Experience 7 + years; Builds and maintains data pipelines.; - Works related to extracting transactional data, transforming for enrichment\/cleansing, and loading into data warehouses or reconciliation tools.; - Works closely with TLM (Transaction Lifecycle Management) teams for accurate and timely data integration; Required Skills:; ETL Tools and Technologies: Proficiency in ETL tools (e.g., Talend, Informatica, SSIS), scripting languages (e.g., Python, SQL), and data warehouse technologies (e.g., Snowflake, Redshift, BigQuery).; Data Modeling: Understanding of data modeling principles and techniques, including relational and dimensional modeling.; Data Quality and Governance: Knowledge of data quality principles and data governance frameworks.; Database Management: Experience with database systems (e.g., Oracle, SQL Server, MySQL) and SQL.; Big Data Technologies: Familiarity with big data technologies such as Hadoop, Spark, Cloud-based platforms.; Programming and Scripting: Proficiency in programming languages like Python or Scala.; Communication and Collaboration: Strong communication and collaboration skills to work effectively with cross-functional teams.; Experience:; Seven years of experience in data engineering, with a focus on ETL processes in a banking or financial services environment.; Experience with data warehousing, data lakes, or big data platforms.; Experience with data modeling and database design.; Experience with ETL tools and technologies.; Experience with big data technologies (e.g., Hadoop, Spark).; Application Instructions; Please apply for this position by submitting your text CV using InternSG.; Kindly note that only shortlisted candidates will be notified.; Apply for this position","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85215301","Role":"Customer Engineer, Data Analytics and AI, Google Cloud","Company":"Google","Location":"Singapore River","Publish_Time":"2025-06-27 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85215301","job_desc":"Google will be prioritizing applicants who have a current right to work in Singapore, and do not require Google's sponsorship of a visa.; ; Minimum qualifications:; Bachelor's degree or equivalent practical experience.; 10 years of experience with cloud native architecture in a customer-facing or support role.; Experience with practical application and architectural considerations of AI\/ML, including Machine Learning (ML) lifecycle, ML frameworks (e.g., TensorFlow, PyTorch) and MLOps principles.; Experience in developing data warehouses, data lakes, batch\/real-time event processing, streaming, data processing (ETL\/ELT), data migrations, data visualization and data governance on cloud native architectures.; Experience in conducting technical discovery, business and technical requirements and translating them into efficient and innovative technical architectures that leverage data and AI services.; ; Preferred qualifications:; Experience implementing MLOps best practices, CI\/CD pipelines for ML models and infrastructure as code for deploying data and AI solutions.; Experience in integrating data and AI solutions with existing enterprise systems, on-premises infrastructure and third-party applications.; Experience in optimizing performance, cost-efficiency and scalability of large-scale data processing pipelines and ML inference systems.; Experience with hybrid cloud architectures and multi-cloud strategies, particularly in data integration and migration.; Experience with architectural design and implementation of solutions involving LLMs, Generative AI models or AI agents (e.g., Vertex AI Agent Engine, ADK, LangChain, LlamaIndex).; About the job; The Google Cloud Platform team helps customers transform and build what's next for their business \u2014 all with technology built in the cloud. Our products are developed for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping our customers \u2014 developers, small and large businesses, educational institutions and government agencies \u2014 see the benefits of our technology come to life. As part of an entrepreneurial team in this rapidly growing business, you will play a key role in understanding the needs of our customers and help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.; As a Customer Engineer, you will collaborate with technical sales teams as a data analytics and Artificial Intelligence expert to showcase Google Cloud's value.You will help customers and partners leverage Google Cloud by designing solutions, conducting proofs-of-concept and resolve technical issues related to data migrations and lifecycle management. You will understand customer needs, present tailored solutions and demonstrate technical and communications skills while working with a team of Googlers that fosters equal opportunities for success.; Google Cloud accelerates every organization\u2019s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google\u2019s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.; Responsibilities; Design and implement solutions that cover the entire data lifecycle from ingestion, storage and processing in both batch and real-time to advanced analytics and Machine Learning (ML) model deployment.; Guide customers in building and integrating collaborative AI agents using tools like Vertex AI agent engine and Agent Development Kit (ADK) and understand the Agent2Agent protocol can facilitate seamless communication and data exchange between these agents across systems.; Identify opportunities where AI agents can automate tasks, enhance decision-making and create value, ensuring solutions are technically sound and deliver tangible business outcomes.; Communicate architectural concepts effectively to technical stakeholders and executive leadership, demonstrate Google Cloud's data and AI offerings address and unlock new possibilities.; Leverage the latest advancements in Google Cloud's data and AI portfolio to provide solutions and competitive differentiation.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85703612","Role":"Big Data Engineer (Libra) - Data Platform","Company":"TikTok Pte. Ltd.","Location":"Central Region","Publish_Time":"2025-07-13 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85703612","job_desc":"About TikTok; TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and we also have offices in New York City, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.; Why Join Us; Inspiring creativity is at the core of TikTok's mission. Our innovative product is built to help people authentically express themselves, discover and connect \u2013 and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and bring joy - a mission we work towards every day.; We strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. Every challenge is an opportunity to learn and innovate as one team. We're resilient and embrace challenges as they come. By constantly iterating and fostering an \"Always Day 1\" mindset, we achieve meaningful breakthroughs for ourselves, our company, and our users. When we create and grow together, the possibilities are limitless. Join us.; Diversity & Inclusion; TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Job highlights; Positive team atmosphere, Career growth opportunity, Meals provided; Responsibilities; About the team; Libra is a large-scale online one-stop A\/B testing platform developed by TikTok Data Platform. Some of its features include:; - Provides experimental evaluation services for all product lines within the company, covering solutions for complex scenarios such as recommendation, algorithm, function, UI, marketing, advertising, operation, social isolation, causal inference, etc.; - Provides services throughout the entire experimental lifecycle from experimental design, experimental creation, indicator calculation, statistical analysis to final evaluation launch.; - Supports the entire company's business on the road of rapid iterative trial and error, boldly assuming and carefully verifying.; Responsibilities; - Responsible for data system of experimentation platform operation and maintenance.; - Construct PB-level data warehouses, participate in and be responsible for data warehouse design, modeling, and development, etc.; - Build ETL data pipelines and automated ETL data pipeline systems.; - Build an expert system for metric data processing that combines offline and real-time processing.; Qualifications; Minimum Qualifications; - Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience.; - Proficiency with big data frameworks such as Presto, Hive, Spark, Flink, Clickhouse, Hadoop, and have experience in large-scale data processing.; - Minimum 1 year of experience in Data Engineering.; - Experience writing code in Java, Scala, SQL, Python or a similar language.; - Experience with data warehouse implementation methodologies, and have supported actual business scenarios.; Preferred Qualifications; - Knowledge about a variety of strategies for ingesting, modeling, processing, and persisting data, ETL design, job scheduling and dimensional modeling.; - Expertise in designing, analyzing, and troubleshooting large-scale distributed systems is a plus (Hadoop, M\/R, Hive, Spark, Presto, Flume, Kafka, ClickHouse, Flink or comparable solutions).; - Work\/internship experience in internet companies, and those with big data processing experience are preferred.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85603062","Role":"AVP, Data Engineer, Group Asset Management - Business Technology","Company":"United Overseas Bank Limited (UOB)","Location":"Singapore","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85603062","job_desc":"United Overseas Bank Limited (UOB) is a leading bank in Asia with a global network of more than 500 branches and offices in 19 countries and territories in Asia Pacific, Europe and North America. In Asia, we operate through our head office in Singapore and banking subsidiaries in China, Indonesia, Malaysia and Thailand, as well as branches and offices.; Our history spans more than 80 years. Over this time, we have been guided by our values \u2013 Honorable, Enterprising, United and Committed. This means we always strive to do what is right, build for the future, work as one team and pursue long-term success. It is how we work, consistently, be it towards the company, our colleagues or our customers.; Established in 1986, UOB Asset Management (UOBAM) is a wholly owned subsidiary of United Overseas Bank. Headquartered in Singapore, UOBAM has grown extensively across Asia with local presence in Brunei, Indonesia, Japan, Malaysia, Taiwan, Thailand and Vietnam. Our network includes UOB Islamic Asset Management in Malaysia and a joint venture with China\u2019s Ping An Trust to form Ping An Fund Management Company. We have also forged a strategic alliance with Wellington Management Singapore.; Our experienced team of more than 90 investment professionals conduct rigorous fundamental research within a proven investment framework to provide our clients with innovative investment solutions. The strength of our team lies in our commitment to investment excellence. Our performance has been recognised by the industry and we have garnered over 340 awards regionally since 1986.; Through our regional network, we offer global investment management expertise to individuals, institutions and corporations. Our comprehensive suite of products ranges from retail unit trusts and exchange-traded funds to customised portfolio management services for institutional clients. A leader in innovation, UOBAM offers a digital option to manage investments with UOBAM Invest robo-adviser, making investing simpler, smarter and safer.;   UOBAM Technology provides software and system development, as well as information technology support services and banking operations.;   We have centralized and standardized the technology components into Singapore, creating a global footprint which can be utilized for supporting our regional subsidiaries and the branches around the world. We operate and support 8 countries with this architecture to provide a secure and flexible Asset Management infrastructure.; Develop and maintain infrastructure for enterprise data platforms and machine learning.; Collaborate with business stakeholders to gather requirements and translate them into effective data visualizations and reporting solutions.; Design, build, and maintain scalable and interactive dashboards using BI tools such as Power BI, Tableau, or Looker.; Implement and manage data governance frameworks, including data cataloging, lineage, quality, and access controls using cloud-native tools (e.g., AWS Glue, Azure Purview, Google Cloud Data Catalog).; Data Platform Development & Management:; Design, develop, and maintain data platforms that support large-scale data ingestion, storage, and processing using cloud-based data infrastructure.; Implement and manage data warehousing and centralized data solutions tailored for asset management.; Evaluate and integrate new data technologies and tools to enhance data platform capabilities.; Data Pipeline Development:; Build and maintain robust and efficient data pipelines for data ingestion, processing, and transformation.; Develop and implement data quality checks and validation processes to ensure data accuracy, timeliness, and consistency.; Utilize ETL\/ELT tools and techniques to transform and load data into target systems.; Employ exceptional problem-solving skills, with the ability to see and solve issues before they snowball into problems.; Learn and share knowledge and experience in a multi-disciplinary team.; Bachelor's or Master's degree in Computer Science, Data Science, Engineering, or a related field.; At least 5 years of experience in data engineering, business intelligence, machine learning engineering, or a related role in a production environment.; Familiarity with data governance frameworks (e.g., DAMA-DMBOK) and regulatory compliance (e.g., GDPR, CCPA).; Hands-on experience in Python and SQL. Experience with other programming languages (e.g., Java, Scala, C++) is a plus.; Experience in best practices such as DataOps and MLOps; Experience with big data technologies and cloud platforms such as BigQuery, Kafka, GCP, AWS and their data engineering and machine learning products and services.; Strong understanding of software development best practices, including version control (Git), testing, and CI\/CD.; Excellent communication and organizational skills, and the ability to stay focused on completing tasks and meeting goals within a busy workspace.; Skilled at working in tandem with a team of engineers, or alone as required.; Strong troubleshooting and analytical skills.; Cloud and data certifications are a plus.; UOB is an equal opportunity employer. UOB does not discriminate on the basis of a candidate's age, race, gender, color, religion, sexual orientation, physical or mental disability, or other non-merit factors. All employment decisions at UOB are based on business needs, job requirements and qualifications. If you require any assistance or accommodations to be made for the recruitment process, please inform us when you submit your online application.; ; Apply now and make a difference.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84370049","Role":"Cloud Infrastructure Engineer","Company":"OLA TECHNOLOGIES SDN BHD","Location":"East Region","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84370049","job_desc":"Job Responsibilities:; Proficient in managing resource, cost and security in one of mainframe cloud provider like aws, gcp, azure.; Develop and optimize continuous integration and continuous deployment (CI\/CD) pipelines for the mobile app development team. Automate the build, testing, and deployment processes to accelerate delivery and reduce time-to-market.; Implement monitoring tools and practices to proactively identify and address performance bottlenecks and system issues. Collaborate with the development team to optimize app performance and enhance user experience.; Collaborate with cross-functional teams, including mobile app developers, QA, product managers, and IT operations, to ensure seamless communication and alignment of objectives.; Advocate for DevOps best practices and foster a culture of continuous improvement and learning within the team and the organization.; Identify opportunities to automate manual processes and tasks, reducing manual intervention and increasing productivity.; Maintain clear and comprehensive documentation of infrastructure, configurations, and processes.; Awareness of relevant data protection and compliance regulations pertaining to mobile app development and data handling.; Requirements:; Bachelor's degree in Computer Science, Software Engineering, or a related field.; Proven experience working as a DevOps Engineer or similar role in a mobile app development environment.; Strong expertise in managing cloud infrastructure and experience with infrastructure as code (IaC) tools like Terraform, CloudFormation, or equivalent.; Proficiency in setting up and maintaining CI\/CD pipelines using tools such as Jenkins, GitLab CI\/CD, CircleCI, or similar.; Solid programming skills in scripting languages like Python, Bash, or Ruby, and experience with automation tools like Ansible, Chef, or Puppet.; Familiarity with mobile app development processes, including iOS and Android platforms; Understanding of security best practices and experience in implementing security measures in cloud environments.; Strong communication and collaboration skills, able to work effectively in a team-oriented environment.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85478295","Role":"Data Engineer - Applied AI - Data Cycling Centre","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-07-04 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85478295","job_desc":"Responsibilities; About the team The Machine Learning Engineering (MLE) team focused on the application of multimodal LLMs, unsupervised learning, and clustering algorithms. The ideal candidate will work closely with product, operations, and engineering teams to apply advanced natural language processing, computer vision, and deep learning technologies to solve business challenges and extract actionable insights. Responsibilities; Collaborate closely with data scientists, machine learning engineers, and software developers to build scalable data pipelines.; Support the development and deployment of machine learning models by ensuring high-quality, reliable data infrastructure.; Drive innovation in data processing, storage, and retrieval to optimize model training and inference.; Work in an agile environment focused on continuous integration and delivery of ML solutions.; Contribute to the design and implementation of data governance and security best practices.; Qualifications; Minimum Qualifications: 1. Bachelor\u2019s degree in Computer Science, Engineering, or a related field along with proven experience in data engineering, preferably within a machine learning or AI-focused team. 2. Strong proficiency in programming languages such as Python, Java, or Scala.; 3. Hands-on experience with big data technologies (e.g., Hadoop, Spark, Kafka) along with strong expertise in designing, building, and maintaining ETL\/ELT pipelines. 4. Familiarity with cloud platforms (AWS, GCP, or Azure) and their data services. 5. Solid understanding of database systems, both SQL and NoSQL.; 6. Experience optimizing performance in big data and fully understanding data skew along with familiarity with data governance, lineage, and real-time data processing practices. 7. Knowledge of machine learning workflows and data requirements along with excellent problem-solving skills and ability to work collaboratively in cross-functional teams.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84067715","Role":"Senior Data Engineer","Company":"Tencent International Service Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84067715","job_desc":"About the Hiring Team; Tencent Overseas IT has the mission to empower Tencent\u2019s rapid global growth with future ready, global IT platforms, applications and services. We are chartered to lead the Overseas IT strategy, architecture, roadmap and execution. Satisfying our internal\/external customers and becoming a world class global IT team are our top aspirations. What the Role Entails; Tencent Overseas IT aims to empower its rapid global growth with future-ready, global IT platforms, applications, and services. We are chartered to lead the Overseas IT strategy, architecture, roadmap, and execution. Our top aspirations are to satisfy our internal\/external customers and become a world-class global IT team.; Data platform architecture design and pipeline development, ensuring system stability and scalability; Work closely with analysts and product teams to define data standards and key metrics support business decisions; Own the deployment, management, and optimization of big data components such as Airflow, Spark, Flink and data warehouse; Continuously improve data workflows and promote automation and engineering efficiency; Who We Look For; Bachelor\u2019s degree or above in Computer Science or related fields\uff0c3+ years in data engineering; Experience with SQL and Python; and at least one of Java or Scala; Familiar with ETL pipeline design, scheduling, and performance tuning; Familiar with databases and data warehouses such as PostgreSQL, MySQL, StarRocks, ClickHouse; 5Experience with using and managing big data tools like Airflow, Spark, and Flink; Cross-team communication, able to independently engage with business teams; Fluent in Chinese and English is preferred in order to communicate with various stakeholders in headquarters; Equal Employment Opportunity at Tencent; As an equal opportunity employer, we firmly believe that diverse voices fuel our innovation and allow us to better serve our users and the community. We foster an environment where every employee of Tencent feels supported and inspired to achieve individual and common goals.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84036464","Role":"Data Scientist - Data Acquisition","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84036464","job_desc":"Responsibilities; The success of TikTok's data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. The Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. The Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management. About the Role We are seeking a Data Scientist to lead the development of intelligent decision-making capabilities that enhance operational efficiency, workforce utilization, and task allocation. You will be at the center of a cross-functional initiative to improve how data signals are captured, transformed, and used to guide critical assignments within a scaled delivery framework. This role requires fluency in building data-driven allocation systems, deep comfort with experimentation and analysis, and the ability to translate real-world challenges into technical solutions using machine learning and statistical modeling. Responsibilities: 1. Optimization Modelling: Design and develop data-driven models and frameworks that support intelligent assignment, prioritization, and resource utilization across operational workflows. 2. Feature Engineering: Build and maintain pipelines that transform raw signals such as behavioral data, labelling task attributes, and performance metrics into structured features for decision-making. 3. Project Planning and Execution: Develop and manage project plans, timelines, and budgets for data science initiatives. 4. Stakeholder Management: Communicate project progress, challenges, and results to stakeholders and senior management. Qualifications; Minimum Qualifications: 1. At least 5 years of experience applying machine learning, statistical modeling, or optimization to operational or business challenges. 2. Strong skills in data wrangling, feature development, and exploratory analysis. 3. Proficient in Python and SQL; experience working with large-scale or distributed data systems. 4. Track record of owning end-to-end data projects, from requirements gathering to implementation. Preferred Qualifications: 1. Background in decision science, resource allocation models, or workflow optimization. 2. Experience working within structured operational environments such as service delivery, content review, or quality control systems. 3. Understanding of experimentation infrastructure, including A\/B testing and metric design. 4. Ability to communicate technical insights clearly to both technical and business audiences.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85607474","Role":"Data & Quality Assurance Engineer Executive","Company":"Surbana Technologies","Location":"Singapore","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85607474","job_desc":"We are looking for a Data & Quality Assurance Engineer who will play a hybrid role in data analytics, software testing, and documentation management. This role is ideal for someone with a strong analytical mindset, attention to detail, and technical expertise in both data science and software testing. You will ensure data accuracy, optimize testing processes, and maintain high-quality documentation to support product development and business decisions.; Key Responsibilities; 1. Data Analytics & Data Science; Analyze and interpret large datasets to extract meaningful insights and support business decisions.; Develop data models, machine learning algorithms, and predictive analytics solutions.; Design and implement ETL (Extract, Transform, Load) pipelines for data processing.; Collaborate with stakeholders to define data-driven strategies and improve decision-making.; Utilize SQL, Python, or R for data analysis, visualization, and automation.; 2. Software Testing & Quality Assurance; Develop and execute test strategies for data-driven applications, APIs, and software systems.; Perform functional, regression, performance, and automated testing.; Identify, document, and track bugs to resolution using test management tools (Jira, TestRail, etc.).; Implement automation frameworks to improve efficiency in software testing.; Ensure data accuracy and integrity in software outputs and reports.; 3. Documentation & Process Management; Maintain clear and comprehensive documentation for data models, testing processes, and technical workflows.; Create test plans, test cases, and user guides to ensure product quality and knowledge transfer.; Document best practices for data governance, security, and compliance.; Support cross-functional teams with well-structured reports and documentation.; Qualifications & Skills; Bachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, Software Engineering, or a related field.; Strong experience in SQL, Python, and data visualization tools (Tableau, Power BI, Matplotlib, etc.).; Hands-on experience with software testing methodologies, test automation, and defect tracking.; Knowledge of machine learning frameworks (Scikit-learn, TensorFlow, PyTorch) is a plus.; Experience with version control (Git) and Agile methodologies.; Excellent analytical, problem-solving, and communication skills.; Strong documentation skills with experience in Confluence, Markdown, or technical writing tools.; Preferred Qualifications; Experience in cloud platforms (AWS, Azure, GCP) for data processing and model deployment.; Familiarity with CI\/CD pipelines and DevOps tools for software testing.; Exposure to API testing tools such as Postman or RestAssured.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84522772","Role":"Site Reliability Engineer - Data Management Suite","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84522772","job_desc":"Responsibilities; The Data Management Suite team is building products that cover the whole lifecycle of data pipeline, including data ingestion and Integration, data development, data catalog, data security and data governance. These products support various businesses, so data engineers and data scientists could greatly boost their productivity. As a software engineer in the data management suite team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world.; You'll have the opportunity to gain hands-on experience on core systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users. Responsibilities:; Be responsible for the production stability for big data development and governance systems; Engage in and improve the whole lifecycle of service, from inception and design, through to deployment, operation and refinement; Maintain services once they are live by measuring and monitoring availability, latency and overall system health.; Practice sustainable incident response and blameless postmortems; Establish best engineering practice for engineers as well as non-technical people; Design and implement reliable, scalable, robust and extensible big data systems that support core products and business;; Qualifications; Minimum Qualifications; Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience; Experience with site reliability engineering, monitoring, alerting for big data related systems; Experience writing code in Java, Go, Python or a similar language; Preferred Qualifications; Knowledge about a variety of strategies for ingesting, modeling, processing, and persisting data, ETL design, job scheduling and dimensional modeling;; Familiarity with running production grade services at scale and understanding cloud native technologies and networking;; Experience developing tools and APIs to reduce human interaction with systems and applications using a variety of coding and scripting standards;; Expertise in designing, analyzing, and troubleshooting large-scale distributed systems is a plus (Hadoop, M\/R, Hive, Spark, Presto, Flume, Kafka, ClickHouse, Flink or comparable solutions);; Systematic problem-solving approach, coupled with effective communication skills and a sense of drive;","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85633289","Role":"Devops Cloud Engineer","Company":"PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd)","Location":"Clementi Central","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85633289","job_desc":"Key Responsibilities:; Infrastructure Automation (Full Stack):; Automate the setup and management of cloud infrastructure for enterprise apps using tools and programming languages like Python, Node.js, CI\/CD pipelines, and GitOps practices.; Cloud Setup & App Modernization:; Configure AWS environments for enterprise applications.; Migrate legacy apps to more cloud-native, platform-aligned architectures to boost productivity.; Troubleshooting in AWS (On-Call):; Support and debug issues in the AWS cloud environment.; Be part of a 24\/7 on-call rotation to handle urgent system issues.; Automation Solutions:; Develop tools or scripts to automate repetitive tasks, thereby improving team efficiency.;  Skills Required:; Core AWS & DevOps:; At least 5+ years working with AWS and DevOps principles.; Hands-on with services like EC2, Lambda, RDS, S3, API Gateway, etc.; Programming & Automation:; At least 3 years experience coding with Python, NodeJS, TypeScript, or PowerShell.; Familiarity with REST APIs and GitOps methodologies.; Infrastructure as Code (IaC):; Experience using Terraform, CloudFormation, or AWS CDK to manage cloud resources.; CI\/CD Pipelines:; Deep experience with tools like Jenkins, AWS CodeBuild, CodeDeploy.; Monitoring & Observability:; Familiarity with tools like Splunk, Dynatrace, Catchpoint for logs and performance monitoring.; Bonus Skills:; Linux command-line knowledge.; API development with Java or NodeJS.; AWS Certification is a plus.; Interested candidates may apply through the application system. We regret to inform only Shortlisted candidates will be notified.; EA License No. 01C4394 \u2022 RCB No. 200007268E \u2022Derrick Tiew Yong Han EA Registration No. R1877971; By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy available at https:\/\/www.persolkelly.com.sg\/policies. You acknowledge that you have read, understood, and agree with the Privacy Policy.","salary":"$7,000 \u2013 $10,000 per month (SGD)","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85068650","Role":"Associate, Full Stack Data Engineer (Singapore)","Company":"Nomura Singapore Limited","Location":"Singapore","Publish_Time":"2025-06-20 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85068650","job_desc":"Job title:        Full Stack Data Engineer; Corporate Title:    Associate; Department:        Chief Data Office; Location:        Singapore; Company overview; Nomura is an Asia-based financial services group with an integrated global network spanning over 30 countries. By connecting markets East & West, Nomura services the needs of individuals, institutions, corporates and governments through its three business divisions: Retail, Asset Management, and Wholesale (Global Markets and Investment Banking). Founded in 1925, the firm is built on a tradition of disciplined entrepreneurship, serving clients with creative solutions and considered thought leadership. For further information about Nomura, visit www.nomura.com; Department overview:; The Chief Data Office plays a key role in defining and implementing the firm's data, cloud and AI strategy, driving change through these capabilities, enforcing data, cloud and AI governance for the firm, and elevating Nomura's data culture. Governance remains a critical focus area, and the Chief Data Office, in partnership with Business and Corporate functions, is responsible for ensuring that the firm's data assets are managed in line with the firm's data management framework, policy and standards.; Role Description:; Job Responsibilities:; \u2022    Information delivery & analytics. State-of-the-art expertise across, data\/information preparation, data insight & visualization using BI (or similar tools), and advanced data prediction using AI, ML, DL, etc.; \u2022    AI\/ML Ops. Responsible for integration, deployment and monitoring of AI\/ML products and solutions,; \u2022    Data management. Demonstrate expertise in data management to ensure the analytics products are appropriate\/ethical and well-controlled. Enabling data architecture and delivery of data-analytics platforms and Solutions- on-premises, cloud, and hybrid ensuring adherence and conformance to Nomura standards and policies; \u2022    Be a trusted partner. Shape the information & analytics agenda at Nomura, and work with all of Nomura\u2019s businesses in laying out their information & analytics adoption roadmaps.; \u2022    Risk Mindset: Familiar with risk and controls frameworks and ability to operate with a control mindset; Skills, experience, qualifications and knowledge required:; Core Skills requirement:; \u2022    Designing and developing scalable data pipelines to collect and process large volumes of data from multiple sources.; \u2022    Building physical data models and ETL processes to ensure data quality, integrity, and accessibility.; \u2022    Microservices Development: Building and maintaining highly scalable and fault tolerant microservice, including efficient server-side APIs.; \u2022    Deployment: Hands on with CI\/CD, Jenkins, Ansible, DevOps process, Enterprise integration patterns.; \u2022    Hands-on with programming languages (Python, SQL, Java, Unix scripting etc.) and with orchestration tools like Airflow or Autosys; \u2022    Experience with cloud technologies such as EC2, EMR, Snowflake or similar tools with ability to drive design and data model discussions, hybrid data architecture. ; \u2022    Proficiency in React with hands-on experience in UI development a plus.; \u2022    Ability to understand and integrate cultural differences and work effectively with virtual cross-cultural, cross-border teams.; \u2022    Flexibility to adjust to multiple demands, shifting priorities, ambiguity, and rapid change.; \u2022    Experience with senior stakeholder management will be an added advantage.; \u2022    Excellent communication (verbal, written, listening), presentation, and interpersonal skills.; \u2022    Able to analyze complex situations and derive workable actions.; \u2022    Able to constructively challenge requirements and current state to increase overall value to the firm.; Education and experience; Wide variety of degrees will be considered, however work experience will be of equal, if not greater importance; \u2022    At least 4-year Bachelor\u2019s degree in quantitative fields with minimum of 5 years of relevant data experience in data engineering \/ MLOps, full stack engineering, preferably in financial organizations or Masters in quantitative fields (Computer Science, Statistics or similar) ; \u2022    Experience of working with a multi-cultural, multi-disciplined, globally dispersed teams; \u2022    Certifications in relevant technologies or frameworks are a plus.; Diversity Statement; Nomura is committed to an employment policy of equal opportunities, and is fundamentally opposed to any less favourable treatment accorded to existing or potential members of staff on the grounds of race, creed, colour, nationality, disability, marital status, pregnancy, gender or sexual orientation.; ; DISCLAIMER:  This Job Description is for reference only, and whilst this is intended to be an accurate reflection of the current job, it is not necessarily an exhaustive list of all responsibilities, duties, skills, efforts, requirements or working conditions associated with the job.  The management reserves the right to revise the job and may, at his or her discretion, assign or reassign duties and responsibilities to this job at any time.  ;                                                                                                         Nomura is an Equal Opportunity Employer","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85002445","Role":"AVP, Platform SRE Engineer, SRE, Group Technology - (WD72793)","Company":"DBS Bank Limited","Location":"Downtown Core","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85002445","job_desc":"Business Function; Group Technology enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group Technology, we manage the majority of the Bank's processes and inspire to delight our business partners through our multiple banking delivery channels.; Job Objective; DBS Bank is looking for a Platform SRE Engineer with experience working on enterprise level data engineering, analytics, and observability applications. The SRE engineer would be responsible for ensuring high availability of the platform services and perform continuous improvements to increase the platform\u2019s efficiency and resiliency. The SRE engineer will also perform automation development tasks to remove toil and increase the team\u2019s productivity.; Responsibilities; Develop monitoring and onboarding guidelines for various applications using observability platform stack, ensuring accurate monitoring and data collection.; Drive Observability standards, best practices, operations and processes for the Enterprise in AppDynamics & other observability tools; Automate routine tasks and reporting processes using APIs and scripting, reducing manual effort and improving efficiency in AppDynamics & other observability tools; Identify and resolve performance issues through detailed analysis of transaction traces, application logs, and system metrics.; Collaborate with stakeholders to define performance metrics and monitoring requirements aligned with business goals.; Contribute to internal knowledge bases, create documentation, and share insights with the team to promote a culture of learning and collaboration.; Design and implement monitoring solutions to track application performance, identifying bottlenecks and optimising system efficiency.; Conduct performance tuning and capacity planning to ensure applications meet scalability and reliability requirements.; Develop custom dashboards and reports to provide actionable insights and drive decision-making processes.; Collaborate with development and operations teams to integrate Observability platform stack with CI\/CD pipelines and other DevOps tools.; Configure and fine-tune alerts to proactively detect and address performance issues before they impact end-users.; Continuously review and enhance monitoring processes and methodologies to improve efficiency and effectiveness.; Work with application teams to develop long-term monitoring strategies that align with business goals and technology roadmaps.; Create data retention polices and access controls (RBAC) to manage user permissions.; Perform application maintenance, patching, upgrading controller versions, agents etc and ensure EOS\/EOL is maintained.; Deliverables; Ensure on-time delivery of tasks and projects.; Ensure continuous uptime of applications and services.; Ensure no security or audit issues.; Job Dimensions; Comply to bank standards to track and follow up on the assigned projects.; Cover all areas in application and infrastructure operations of the platform.; Requirements; You should be a university graduate (computer science or related field) with good experience working with contemporary technologies and scripting languages.; Strong communication skills and ability to explain protocol and processes with team and management; A passion for learning and using new technologies in the open-source communities.; A passion for coding.; Min 10 years of IT work experience.; Working knowledge in AppDynamics, ELK Stack, Grafana, Open Telemetry (OTEL); In-depth experience in Unix\/Linux\/Shell\/Python scripting with quality, scalability, and extensibility.; Experience in triaging and troubleshooting application problems quickly in monitoring tools by using various techniques - Transaction snapshots, Diagnostic Sessions, Data Collectors; Knowledgeable and experienced in SRE (Site Reliability Engineering) practices covering monitoring, observability, performance management, automation, and resiliency.; Knowledge in Confluent Kafka, Prometheus & other APM tools (Dynatrace, Datadog, New Relic, Splunk) is a plus.; Knowledge in AI\/ML capabilities to automate RCA\u2019s and shorter MTTR when issues arise.; Good understanding of Network routing, Load balancing and Networking protocols; a base knowledge of TCP\/IP, with an understanding of HTTP and DNS; Ability to contribute to discussions on design and strategy.; Adequate knowledge of database systems (RDBMS, MariaDB, SQL, NOSQL), Object Oriented Programming and web application development.; Good problem diagnosis and creative problem-solving skills; Experience in NodeJS, Spring boot could be a plus.; Apply Now; We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155117","Role":"Big Data Engineer (Libra) - Data Platform","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155117","job_desc":"Responsibilities; Libra is a large-scale online one-stop A\/B testing platform developed by TikTok Data Platform. Some of its features include:; Provides experimental evaluation services for all product lines within the company, covering solutions for complex scenarios such as recommendation, algorithm, function, UI, marketing, advertising, operation, social isolation, causal inference, etc.; Provides services throughout the entire experimental lifecycle from experimental design, experimental creation, indicator calculation, statistical analysis to final evaluation launch.; Supports the entire company's business on the road of rapid iterative trial and error, boldly assuming and carefully verifying.; Responsibilities; Responsible for data system of experimentation platform operation and maintenance.; Construct PB-level data warehouses, participate in and be responsible for data warehouse design, modeling, and development, etc.; Build ETL data pipelines and automated ETL data pipeline systems.; Build an expert system for metric data processing that combines offline and real-time processing.; Qualifications; Minimum Qualifications; Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience.; Proficiency with big data frameworks such as Presto, Hive, Spark, Flink, Clickhouse, Hadoop, and have experience in large-scale data processing.; Minimum 1 year of experience in Data Engineering.; Experience writing code in Java, Scala, SQL, Python or a similar language.; Experience with data warehouse implementation methodologies, and have supported actual business scenarios.; Preferred Qualifications; Knowledge about a variety of strategies for ingesting, modeling, processing, and persisting data, ETL design, job scheduling and dimensional modeling.; Expertise in designing, analyzing, and troubleshooting large-scale distributed systems is a plus (Hadoop, M\/R, Hive, Spark, Presto, Flume, Kafka, ClickHouse, Flink or comparable solutions).; Work\/internship experience in internet companies, and those with big data processing experience are preferred.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85453980","Role":"DevOps Platform Engineer APAC (F\/M\/D)","Company":"Flowdesk Asia","Location":"Singapore","Publish_Time":"2025-07-04 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85453980","job_desc":"Job description; Do you want to see what infrastructures supporting a global high-frequency market maker look like? Are you interested in building resilient and efficient systems? Ready to tackle technical challenges?; You will be part of the infrastructure team. Reporting to Flowdesk's Lead of Infrastructure and in permanent interaction with the Engineering\/Trading\/Data teams, your mission is to improve, scale, and maintain Flowdesk's infrastructures.; Your mission will be to; Improve and add new features to our CI\/CD systems (FluxCD, Github actions, python scripting ...).; Work on the Kubernetes operators to make them more efficient, and more integrated with other systems and put in place update processes such as Blue\/Green or Canary.; Work on an in-house workload orchestrator solution built using Rust language.; Develop internal tooling for our platform; You will also work on developing DevOps practices, application-level reliability, observability, performance tuning, FinOps, incident management, supporting development processes, and non-core systems.; Participate in the day-to-day operational activities.; Discuss needs with Flowdesk's teams and answer those needs.; Propose improvements and bring new ideas to the table.; Our tech stack: Kubernetes, GCP, Terraform, Ansible, NATS, Rust, Golang, Python, FluxCD, Github actions, Prometheus, Grafana, Vault, Kong.; Requirements:; Background and experience; English is mandatory; Experience with Kubernetes Operators and Kubernetes globally.; Strong backend engineering experience (python, node, golang, rust); Experience using Ansible, Terraform Google Cloud, or AWS.; Experience working with CI\/CD pipelines, fluxCD, and Github actions would be a plus.; Excellent communication skills and ability to explain technical concepts to non-technical people; Good organizational and time management skills with the ability to prioritize tasks and meet deadlines; Basic knowledge of monitoring solutions (Prometheus, Grafana, etc ...) and development (python, node); Strong interest in technology and eagerness to learn new technologies and concepts; Benefits; International environment (English is the main language); An allowance of 400 SGD \/ per month \/ per person in the household; Top-of-the-range equipment Macbook, keyboard, laptop stand, 4K monitor & headphones; Team events and offsites; Are you interested in this job but feel you haven't ticked all the boxes? Don't hesitate to apply and tell us in the cover letter section why we should meet!; Here's what you can expect if you apply; HR Call with the Tech Talent Acquisition (30'); Technical round with the Lead of the Infrastructure team (45\u2019); Technical interview with the Head of the Infrastructure department (60\u2019); Culture fit with the Lead Talent Acquisition (30'); We focus on conversations, not trick questions. These discussions will help you understand how Flowdesk operates and allow you to share your journey and what you\u2019re looking for in your next role.; So... Ready to Join Us?; If you\u2019re excited by the opportunity to shape crypto's future and directly impact our cutting-edge infrastructure, we\u2019d love to hear from you! Apply today and let\u2019s explore how we can build great things together.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85002417","Role":"AVP, Platform SRE Engineer, SRE, Group Technology - (WD72789)","Company":"DBS Bank Limited","Location":"Downtown Core","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85002417","job_desc":"Business Function; Group Technology enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group Technology, we manage the majority of the Bank's processes and inspire to delight our business partners through our multiple banking delivery channels.; Job Objective; DBS Bank is looking for a Platform SRE Engineer with experience working on enterprise level data engineering, analytics, and observability applications. The SRE engineer would be responsible for ensuring high availability of the platform services and perform continuous improvements to increase the platform\u2019s efficiency and resiliency. The SRE engineer will also perform automation development tasks to remove toil and increase the team\u2019s productivity.; Responsibilities; Develop monitoring and onboarding guidelines for various applications using observability platform stack, ensuring accurate monitoring and data collection.; Drive Observability standards, best practices, operations and processes for the Enterprise in AppDynamics & other observability tools; Automate routine tasks and reporting processes using APIs and scripting, reducing manual effort and improving efficiency in AppDynamics & other observability tools; Identify and resolve performance issues through detailed analysis of transaction traces, application logs, and system metrics.; Collaborate with stakeholders to define performance metrics and monitoring requirements aligned with business goals.; Contribute to internal knowledge bases, create documentation, and share insights with the team to promote a culture of learning and collaboration.; Design and implement monitoring solutions to track application performance, identifying bottlenecks and optimising system efficiency.; Conduct performance tuning and capacity planning to ensure applications meet scalability and reliability requirements.; Develop custom dashboards and reports to provide actionable insights and drive decision-making processes.; Collaborate with development and operations teams to integrate Observability platform stack with CI\/CD pipelines and other DevOps tools.; Configure and fine-tune alerts to proactively detect and address performance issues before they impact end-users.; Continuously review and enhance monitoring processes and methodologies to improve efficiency and effectiveness.; Work with application teams to develop long-term monitoring strategies that align with business goals and technology roadmaps.; Create data retention polices and access controls (RBAC) to manage user permissions.; Perform application maintenance, patching, upgrading controller versions, agents etc and ensure EOS\/EOL is maintained.; Deliverables; Ensure on-time delivery of tasks and projects.; Ensure continuous uptime of applications and services.; Ensure no security or audit issues.; Job Dimensions; Comply to bank standards to track and follow up on the assigned projects.; Cover all areas in application and infrastructure operations of the platform.; Requirements; You should be a university graduate (computer science or related field) with good experience working with contemporary technologies and scripting languages.; Strong communication skills and ability to explain protocol and processes with team and management; A passion for learning and using new technologies in the open-source communities.; A passion for coding.; Min 10 years of IT work experience.; Working knowledge in AppDynamics, ELK Stack, Grafana, Open Telemetry (OTEL); In-depth experience in Unix\/Linux\/Shell\/Python scripting with quality, scalability, and extensibility.; Experience in triaging and troubleshooting application problems quickly in monitoring tools by using various techniques - Transaction snapshots, Diagnostic Sessions, Data Collectors; Knowledgeable and experienced in SRE (Site Reliability Engineering) practices covering monitoring, observability, performance management, automation, and resiliency.; Knowledge in Confluent Kafka, Prometheus & other APM tools (Dynatrace, Datadog, New Relic, Splunk) is a plus.; Knowledge in AI\/ML capabilities to automate RCA\u2019s and shorter MTTR when issues arise.; Good understanding of Network routing, Load balancing and Networking protocols; a base knowledge of TCP\/IP, with an understanding of HTTP and DNS; Ability to contribute to discussions on design and strategy.; Adequate knowledge of database systems (RDBMS, MariaDB, SQL, NOSQL), Object Oriented Programming and web application development.; Good problem diagnosis and creative problem-solving skills; Experience in NodeJS, Spring boot could be a plus.; Apply Now; We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85788862","Role":"Core Engineering, SDLC \u2013 Developer Collaboration Software Engineer,...","Company":"Goldman Sachs","Location":"Singapore","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85788862","job_desc":"OVERVIEW:; At Goldman Sachs, our Engineers don\u2019t just build things \u2013 we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.; Engineering, which is comprised of our Technology Division and Global Strategist groups, is at the center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions.; CORE ENGINEERING \u2013 DEVELOPER COLLABORATION; The Developer Collaboration team owns the Atlassian toolset, focusing on JIRA and Confluence at Goldman Sachs. Our team partners with internal stakeholders across business units and functional groups globally to drive strategic engineering and collaboration initiatives that deliver end user outcomes, while creating and maintaining an outstanding customer experience, at scale.; SDLC @ GS:; The SDLC organization is the base and platform on which all technology solutions across the firm are managed. You will be working in the heart of developer experience, ensuring code that is written by thousands of GS engineers is versioned securely, reviewed expertly, compiles fast, is comprehensively tested, compliant, and distributed widely. We empower thousands of developers and all teams across the firm to innovate better, faster, more securely, and in a fully compliant manner, all while striving to create an easy to use, stable, performant, and frictionless ecosystem.; RESPONSIBILITIES:; Own, manage and automate infrastructure and deployments across a variety of environments, including development, testing and production.; Own, implement and maintain continuous integration and delivery pipelines.; Design, configure and manage observability for our systems to ensure application availability and performance.; Own relationships with senior stakeholders and our client development teams to ensure that their needs are met as well as those of the firm.; Implement and maintain security controls and compliance requirements.; Ensure that production issues are addressed in a timely manner, including post mortem and longer term steps to avoid repetition.; Stay current with emerging technologies and tools in the DevOps space.; Advocate for improvements to product quality, security, reliability, and performance.; Develop custom integrations and interfaces between external tooling and Jira\/Confluence infrastructure as needed.; SKILLS AND EXPERIENCE WE ARE LOOKING FOR:; 3+ years (Associate) \/ 8+ years (VP) of experience in a software development, DevOps or related role.; Professional experience with CI \/CD tools such as GitLab, Jenkins, CircleCI or Bitbucket.; Professional experience with cloud deployment patterns. Specifically AWS cloud constructs, Terraform, Docker, Kubernetes, and Kafka.; General knowledge of multiple languages and expert in-depth knowledge of at least one of: Golang, Java, Python, C, C++.; Strong software engineering and system design fundamentals.; Experience with all stages of SDLC.; Experience with SRE principles, as well as diagnosis, prevention, performance management, and availability of large distributed systems.; Strong written and verbal communication.; Excellent problem-solving and analytical skills.; Ability to work collaboratively in a team environment.; PREFERRED QUALIFICATIONS:; BSc, MSc, PhD in relevant field (Computer Science, Information Systems, or similar).; Experience with Prometheus and Grafana, as well as knowledgeable about networking protocols (TCP, UDP, ICMP, ARP, DNS, TLS, HTTP, SSH, etc.); Experience with the use of ML and\/or agentic AI, especially in relation to facilitating the SDLC.; Experience in stakeholder management.; ABOUT GOLDMAN SACHS; At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world. ; We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com\/careers. ; We\u2019re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https:\/\/www.goldmansachs.com\/careers\/footer\/disability-statement.html; \u00a9 The Goldman Sachs Group, Inc., 2023. All rights reserved.; Goldman Sachs is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, national origin, age, veterans status, disability, or any other characteristic protected by applicable law.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84725676","Role":"Backend Software Engineer - (Data Integration)","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84725676","job_desc":"Responsibilities; About the Team The Data Management Suite team is building products that cover the whole lifecycle of data pipeline, including data ingestion and Integration, data development, data catalog, data security and data governance. These products support various businesses, so data engineers and data scientists could greatly boost their productivity.; As a software engineer in the data management suite team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on core systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.; Responsibilities: - Responsible for the design and development of the computing architecture of data integration , and support data integration requirements delivery across different business lines in whole ByteDance;; - Work closely with partner teams across the company and all over the world; - Optimize the performance and stability of real-time data integration services; - Participate in the customization and improvement of the Flink kernel, and maintain cooperation with the open source community; Qualifications; Minimum Qualifications:; Bachelor's degree in Computer Science or equivalent practical experience;; 3+ years of experience in at least one backend language, like Java, Scala, Go etc;; 3+ years of experience in software development, and with data structures\/algorithms;; 3+ years of experience with design and architecture, and testing and launching software products;; Preferred Qualifications:; Be familiar with web frameworks will be a plus, like Spring boot etc.; 2 year experience in Storm\/SparkStreaming\/Flink real-time computation and development experience, to the community contribution patch is preferred ;; 2 year experience in data platform related product development or big data technologies (such as Flink, Clickhouse, kafka etc.) will be a plus;","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85206596","Role":"Senior Platform Engineer \u2013 Trading Systems (Commodities)","Company":"Menrva","Location":"Marina South","Publish_Time":"2025-06-26 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85206596","job_desc":"Senior Platform Engineer \u2013 Trading Systems (Energy\/Commodities); A leading global energy trading firm is expanding its in-house technology team in Singapore. As part of a strategic shift from vendor-reliant systems to internal platform ownership, we are seeking a Senior Platform Engineer to help build, extend, and integrate critical trading and risk infrastructure across the commodities lifecycle (LNG, coal, and others).; You will work closely with traders, risk managers, and product teams to develop new features, streamline workflows, and scale mission-critical systems such as ETRM and credit risk platforms (e.g., CubeLogic). This is a hands-on role suited for an engineer who enjoys full-stack problem-solving and wants to own platform evolution from within.; Key Responsibilities; Design, develop, and enhance trading and risk management systems using Python, C#, SQL Server, and modern Azure-based architecture (Databricks, ADF, Functions, etc.); Build integrations, APIs, and automation tools across systems including ETRM, CubeLogic, and internal decision-support platforms.; Collaborate directly with business users to understand commodity trading workflows and translate them into scalable, production-grade features.; Lead efforts to refactor legacy vendor customizations, improve test coverage, and modernize development pipelines with CI\/CD and DevOps practices.; Contribute to BI\/reporting initiatives using Power BI and support a broader cloud-based data strategy.; Work in a hybrid team with consultants and internal stakeholders, while gradually taking full ownership of the platform.; What We're Looking For; 5\u201310 years of experience in software engineering, ideally within trading, commodities, or financial services.; Strong backend development skills in Python and C#\/.NET, with hands-on experience in SQL and data modeling.; Familiarity with cloud-native development on Azure: Data Factory, Databricks, ADLS, Functions, and automation with PowerShell.; Experience with ETRM systems (e.g., Allegro, Endur) or risk platforms (e.g., CubeLogic) is highly advantageous.; Ability to work in fast-paced environments, engage directly with end users, and take ownership of technical challenges from design through delivery.; Strong engineering fundamentals, attention to detail, and a proactive mindset toward automation and quality delivery.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85685127","Role":"Software Integration Engineer - AWS (Services Planning)","Company":"Synapxe","Location":"One North","Publish_Time":"2025-07-11 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85685127","job_desc":"Position Overview; We are seeking a highly skilled and motivated software integration engineer - AWS to join our team. The ideal candidate will have a strong background in cloud computing and application development, with a focus on designing, developing, and deploying cloud-based applications. The potential candidate will work closely with cross-functional teams, include the operational and data teams, partners and vendors to ensure the successful implementation and maintenance of cloud solutions. This is a year two year direct contract with Synapxe. ; Role & Responsibilities; Design, develop, deploy cloud-based and integrate non-cloud-based applications using industry best practices and cloud technologies; Collaborate with software engineers, architects, and other stakeholders to gather requirements and define application specifications; Implement security measures to protect cloud-based applications and data; Troubleshoot and resolve issues related to cloud infrastructure and applications; Optimize cloud-based applications for performance, scalability, and cost-efficiency; Provide technical guidance and support to team members and stakeholders; Assist in managing and monitoring of cloud-based assets hosted on Singapore GCC platforms; Requirements; Bachelor's degree in Computer Science, Engineering, or a related field; More than 6 years experience in coding with cloud technologies environment; At least 3 years of experience in working as AWS cloud developer; Strong experience in cloud computing platforms such as AWS, Azure, or Google Cloud; Experience with Singapore GCC hosting platform will be of advantage but not essential; Experience with containerization technologies such as Docker and Kubernetes; Familiarity with CI\/CD pipelines and automation tools; Experience with Apache Hadoop and Apache Spark; Proficiency in programming languages such as Java, Python, JavaScript and\/or C#; Knowledge of cloud security best practices and compliance standards; Experience working with version control and repository tools like Git, Maven; Strong background working with Linux\/UNIX environments; Working knowledge with SQL and NoSQL databases preferred; Strong collaboration and communication skills within project teams; Excellent problem-solving and troubleshooting skills; Apply Now; NOTE: It only takes a few minutes to apply for a meaningful career in HealthTech - GO FOR IT!!; #LI-SYNX34","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85640039","Role":"Data Engineer - Sanderson-iKas Singapore Pte Ltd","Company":"Sanderson-Ikas","Location":"Singapore","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85640039","job_desc":"Responsibilities; Design, develop, and maintain backend systems and data pipelines.; Support data integration, transformation, and delivery processes.; Implement solutions using Java, Scala, or Python.; Work within Agile development teams using tools such as Git, Bitbucket, Jenkins, and Jira.; Troubleshoot, optimize, and ensure performance of data systems.; Engage in code reviews and contribute to system documentation.; Skills; 4-10 years of experience in backend development or data engineering.; Proficiency in Java or Scala (ability to work with both is preferred).; Strong understanding of data modeling and data architecture.; Experience with cloud platforms (AWS, Azure, or GCP).; Familiarity with Databricks, Snowflake, or similar platforms is a plus.; Ability to work with both legacy and modern systems.; Strong analytical and problem-solving skills.; Bachelor's or Master's degree in Computer Science, Engineering, or a related field.; Prior experience in regulatory or risk-related systems is advantageous but not mandatory.; For a confidential discussion, please reach out to me at ali.zaidi@sanderson-ikas.sg; Personal data collected will be used for recruitment purposes only.; Only shortlisted candidates will be notified \/ contacted.; EA Registration No: R1988468; \"Sanderson-iKas\" is the brand name for iKas International (Asia) Pte Ltd, a company incorporated in Singapore under Company UEN No.: 200914065E with EA license number 16S8086.; Website: www.sanderson-ikas.sg; ; information_technology","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85272536","Role":"Backend software engineer - Privacy and Security (Data Protection...","Company":"TikTok Pte. Ltd.","Location":"Central Region","Publish_Time":"2025-06-30 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85272536","job_desc":"About TikTok; TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and we also have offices in New York City, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.; Why Join Us; Inspiring creativity is at the core of TikTok's mission. Our innovative product is built to help people authentically express themselves, discover and connect \u2013 and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and bring joy - a mission we work towards every day.; We strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. Every challenge is an opportunity to learn and innovate as one team. We're resilient and embrace challenges as they come. By constantly iterating and fostering an \"Always Day 1\" mindset, we achieve meaningful breakthroughs for ourselves, our company, and our users. When we create and grow together, the possibilities are limitless. Join us.; Diversity & Inclusion; TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Job Highlights; Career growth opportunity; Flat organization; 100+ mil users; Responsibilities; Team introduction:; Build a first-class privacy compliance R & D team, create a high-security, high-stability, and high-efficiency globalization multi-data center data transmission platform, and provide strong technical support for TikTok to become the best privacy protection and most trustworthy product for users.; Responsibilities:; Design, develop, and maintain CI\/CD release pipelines leveraging Kubernetes (K8s) to ensure seamless deployment and delivery processes.; Develop and enhance Kubernetes cluster management capabilities, including cluster upgrades, resource pool management, and lifecycle automation.; Build and maintain tools for Kubernetes operations and maintenance, such as web-based shells, container log access, and debugging utilities.; Lead the development of observability features, including system monitoring, centralized logging, and automated alerting to ensure high platform reliability.; Develop and implement Kubernetes security features, such as cluster certificate management and related compliance capabilities.; Support the day-to-day operations and maintenance of the platform to ensure stability, performance, and availability.; Qualifications; Minimum Qualifications:; BS\/MS Degree in Computer Science or equivalent majors; Proficiency in at least one of the following languages: Go, Java;; Deep understanding of computer architectures, data structures and algorithms;; Solid communication and teamwork skills, with the ability to work effectively with cross-functional teams;; Preferred Qualifications:; \u2022 Experience in high-traffic & high-concurrency server systems is preferred","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85028967","Role":"DevOps (ShipHats) Engineer \/ Senior Associate, Data & AI, Technology Consulting","Company":"Ernst & Young Solutions LLP","Location":"Singapore","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85028967","job_desc":"Job Description: DevOps (ShipHats) Engineer, Senior Associate,  AI Data, Technology Consulting; At EY, we develop you with future-focused skills and equip you with world-class experiences. We empower you in a flexible environment, and fuel you and your extraordinary talents in a diverse and inclusive culture of globally connected teams.; We work together across our full spectrum of services and skills powered by technology and AI, so that business, people and the planet can thrive together. ; We\u2019re all in, are you?; Join EY and shape your future with confidence.; About the opportunity; EY AI & Data is the data and advanced analytics capability within EY Asia-Pacific, with over 500 specialist employees working across multiple industry sectors. We implement information-driven strategies, data platforms and advanced data analytics solution systems that help grow, optimize and protect client organizations. We go beyond strategy and provide end to end design, build and implementation of real-life data environments and have some of the best architects, project managers, business analysts, data scientists, big data engineers, developers and consultants in the region. ; We are seeking a DevOps Engineer (Senior Associate) with proven experience delivering Government Commercial Cloud (GCC) projects for Singapore government agencies and ministries. The ideal candidate will have hands-on expertise in implementing SHIP-HATS frameworks and designing\/maintaining robust CI\/CD pipelines across multiple projects.; Your key responsibilities:; Design, implement, and maintain CI\/CD pipelines to support efficient and secure application deployment in GCC environments.; Lead or contribute to end-to-end DevOps projects for Singapore government agencies or ministries.; Implement and enhance solutions aligned with SHIP-HATS compliance standards.; Collaborate with application teams, architects, and security specialists to ensure smooth delivery and operation of cloud-native and container-based applications.; Perform troubleshooting, monitoring, and performance tuning of DevOps toolchains and infrastructure.; Document solutions, create deployment guides, and support knowledge transfer to client or internal teams.; Skills & attributes for success:; 3\u20135 years of experience in DevOps, with senior-level contributions in at least 1\u20132 GCC projects involving Singapore government agencies.; Strong experience in implementing and optimizing CI\/CD pipelines (e.g., Jenkins, GitLab CI, Azure DevOps).; Practical experience with SHIP-HATS framework implementation.; Proficient with tools such as Docker, Kubernetes, Terraform, Ansible (or similar).; Familiarity with security best practices in government cloud environments.; Strong communication skills for stakeholder engagement and technical documentation.; Familiarity with agile delivery frameworks, including Scrum or equivalent.; Certified in AWS and\/or Talend.; What we look for; Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you\u2019ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.; What working at EY offers; EY offers a competitive remuneration package where you\u2019ll be rewarded for your individual and team performance. We are committed to being an inclusive employer and are happy to consider flexible working arrangements. Plus, we offer:; Continuous learning: You\u2019ll develop the mindset and skills to navigate whatever comes next.; Success as defined by you: We\u2019ll provide the tools and flexibility, so you can make a meaningful impact, your way.; Transformative leadership: We\u2019ll give you the insights, coaching and confidence to be the leader the world needs.; Diverse and inclusive culture: You\u2019ll be embraced for who you are and empowered to use your voice to help others find theirs.; Company description; EY is building a better working world by creating new value for clients, people, society and the planet, while building trust in capital markets.; Enabled by data, AI and advanced technology, EY teams help clients shape the future with confidence and develop answers for the most pressing issues of today and tomorrow.; EY teams work across a full spectrum of services in assurance, consulting, tax, strategy and transactions. Fueled by sector insights, a globally connected, multi-disciplinary network and diverse ecosystem partners, EY teams can provide services in more than 150 countries and territories.; All in to shape the future with confidence.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85608121","Role":"(Senior) Software Engineer, Infrastructure & Productivity","Company":"Airwallex","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85608121","job_desc":"(Senior) Software Engineer - Infrastructure & Productivity Team; Hiring Location: Shanghai & Singapore; Airwallex is a rapidly growing fintech unicorn, founded in 2015 and now flourishing at the Series E financing stage. With a global footprint across Asia-Pacific, Europe, North America, and APAC, we specialize in providing diverse financial payment solutions for B2B merchants, empowering businesses to operate seamlessly anywhere, anytime.; Who We Are? About the Team:; As Airwallex's engineering capabilities continue to scale, our infrastructure teams are at the forefront of propelling us into a future of seamless global operations. Our seven specialized domain teams are not just technical powerhouses but the architects of innovation and efficiency, driving unparalleled engineer productivity and resource optimization.; Tier-X Cloud Infrastructure owns our globally distributed service infrastructure for standard domain teams.; Tier-0 Cloud Infrastructure specializes in building and maintaining critical product services which requires five-9s of availability or above.; Productivity owns our CICD, testing and development tools for our software engineers; Observability focuses on providing the best monitoring and alerting tools; Data Infrastructure is tasked with providing our data engineering and analytics teams with the right tools.; Database owns the multitude of different database solutions from SQL to Redis.; Networking provides a reliable and secure cloud and hardware network infrastructure; Our teams work to provide the best possible experience for our developers and customers while providing a safe and secure environment to ensure that our financial solutions are always available.; In this role, you will:; Enhance Developer Productivity with AI: Utilize AI and machine learning to streamline developer workflows, automate repetitive tasks, and improve code quality.; Optimize CI\/CD Pipelines: Design, implement, and continuously enhance Continuous Integration and Continuous Deployment pipelines to improve software delivery efficiency.; Multi-Tenant Test Environment Development: Architect and implement scalable, multi-tenant test environments to support automated testing and integration processes.; Automated Project Scaffolding: Develop and maintain project scaffolding tools to standardize development practices and accelerate project setup within the organization.; Custom IDE Plugin Development: Design and build IDE plugins to improve developer productivity, ensuring seamless integration with internal tools and workflows.; Internal Developer Platform: Develop and maintain an internal developer platform that enhances self-service capabilities, enabling engineers to work more efficiently.; Engineering Metrics & Insights: Build a comprehensive engineering metrics system to identify bottlenecks and areas for improvement across the software development lifecycle.; Security Best Practices: Implement and enforce security best practices across CI\/CD pipelines, test environments, and software development frameworks to ensure system integrity and compliance.; Cross-Team Collaboration & Technical Leadership: Partner with engineering teams, DevOps, and product managers to define best practices, drive adoption of developer tooling, and provide technical guidance.; Innovation & Emerging Technologies: Research, evaluate, and integrate emerging technologies to enhance developer productivity, streamline workflows, and reduce development friction.; You might be a great fit if you:; Strong proficiency in backend programming languages such as Python, Java, Go, Rust, or Node.js and their corresponding frameworks;; Undergraduate and above in key colleges, computer science, and related majors;; Infrastructure & Cloud Expertise: Familiarity with cloud services (AWS, GCP, Aliyun) and infrastructure management tools (Terraform, Kubernetes, Docker); Experience in developing code scaffolding tools and designing custom IDE plugins (e.g., JetBrains, Visual Studio Code) to enhance developer productivity.; Strong understanding of secure software development practices, including authentication, authorization, and vulnerability scanning in CI\/CD and developer tooling.; Bonus if you have:; Experience with Developer Productivity Engineering (DPE): Background in building tools and frameworks specifically aimed at increasing software development efficiency.; Familiarity with Developer Experience (DevEx) Principles: Understanding of friction points in the software development lifecycle and strategies to enhance developer workflows.; Previous Contributions to Open Source Projects: Experience building open-source tools or contributing to developer tooling communities is a plus.; At Airwallex, you can make an impact in a rapidly growing, global fintech. We want you to share in our success, which is why you\u2019ll be offered a competitive salary plus valuable equity within Airwallex. We also like to ensure we create the best environment for our people by providing collaborative open office space with a fully stocked kitchen. We organise regular team-building events and we give our people the freedom to be creative.; Airwallex is proud to be an equal-opportunity employer. We value diversity and anyone seeking employment at Airwallex is considered based on merit, qualifications, competence, and talent. We don\u2019t regard color, religion, race, national origin, sexual orientation, ancestry, citizenship, sex, marital or family status, disability, gender, or any other legally protected status. If you have a disability or special need that requires accommodation, please let us know.; Airwallex does not accept unsolicited resumes from search firms\/recruiters. Airwallex will not pay any fees to search firms\/recruiters if a candidate is submitted by a search firm\/recruiter unless an agreement has been entered into concerning the specific open position(s). Search firms\/recruiters submitting resumes to Airwallex on an unsolicited basis shall be deemed to accept this condition, regardless of any other provision to the contrary.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84620205","Role":"Google Cloud Engineer - DSC\/ MC","Company":"ST Engineering Cloud & Data Centre Solutions Pte Ltd","Location":"Ang Mo Kio","Publish_Time":"2025-06-27 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84620205","job_desc":"About ST Engineering; ST Engineering is a global technology, defence, and engineering group with offices across Asia, Europe, the Middle East, and the U.S., serving customers in more than 100 countries. The Group uses technology and innovation to solve real-world problems and improve lives through its diverse portfolio of businesses across the aerospace, smart city, defence, and public security segments. Headquartered in Singapore, ST Engineering ranks among the largest companies listed on the Singapore Exchange.;  Our history spans more than 50 years, and our strategy is underpinned by our core values \u2013 Integrity, Value Creation, Courage, Commitment and Compassion. These 5 core values guide every aspect of our business and are embedded in our ST Engineering culture \u2013 from the people we hire, to working with each other, to our partners and customers.;  About our Line of Business \u2013 Cloud & Data Centre Solutions; ST Engineering Cloud and Data Centre Solutions Pte Ltd provides all aspects of cloud management, services, and solutions, from initial setup and migration to ongoing operations and optimization. Services include engineering works to design, build and provide facility management service for mission critical environments such data centers, disaster recovery, and business continuity sites.;  Together, We Can Make A Significant Impact ; We are seeking a skilled and certified Google Cloud Engineer to join our growing team. The ideal candidate will have hands-on experience with Google Cloud Platform (GCP) services and extensive knowledge of Kubernetes for container orchestration. You will be responsible for designing, deploying, and maintaining cloud infrastructure and containerized applications in a scalable, secure, and cost-efficient manner.;  Be Part of Our Success ; Design, implement, and manage scalable cloud infrastructure on Google Cloud Platform.; Build and deploy containerized applications using Kubernetes (GKE).; Automate infrastructure provisioning using Infrastructure as Code (IaC) tools such as Terraform or Deployment Manager.; Collaborate with DevOps, development, and security teams to ensure best practices in CI\/CD pipelines, logging, and monitoring.; Monitor system performance, troubleshoot issues, and ensure high availability and disaster recovery.; Optimize cloud resources for performance and cost-efficiency.; Maintain and improve security practices in accordance with compliance standards.; Document architecture, processes, and procedures.;  Qualities We Value ; Strong expertise in containerization and orchestration using Kubernetes (preferably GKE).; Experience with DevOps tools (e.g., Git, Jenkins, Cloud Build).; Proficiency in scripting or programming (Python, Bash, or Go preferred).; Familiarity with infrastructure automation tools such as Terraform, Ansible, or equivalent.; Excellent problem-solving skills and ability to work independently or as part of a team.; Google Cloud certification (Associate Cloud Engineer or similar).; Kubernetes certification (CKA \u2013 Certified Kubernetes Administrator or CKAD \u2013 Certified Kubernetes Application Developer).; Redhat Certification (Redhat System Administrator); Proven experience with GCP services (e.g., Compute Engine, Cloud Storage, Cloud Functions, Pub\/Sub, BigQuery, etc.).;  Our Commitment That Goes Beyond the Norm; An environment where you will be working on cutting-edge technologies and architectures.; Safe space where diverse perspectives are valued, and everyone\u2019s unique contributions are celebrated. ; Meaningful work and projects that make a difference in people\u2019s lives.; A fun, passionate and collaborative workplace.; Competitive remuneration and comprehensive benefits.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85173408","Role":"Data Engineer Intern","Company":"Millipede Pte Ltd","Location":"Raffles Place","Publish_Time":"2025-06-25 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85173408","job_desc":"Company; Millipede Pte Ltd; millipede.sg; Designation; Data Engineer Intern; Date Listed; 19 Jun 2025; Job Type; Entry Level \/ Junior Executive; Intern\/TS; Job Period; Immediate Start, For At Least 6 Months; Profession; IT \/ Information Technology; Industry; Computer and IT; Location Name; Raffles Place, Singapore; Address; Raffles Pl, Singapore; Map; Allowance \/ Remuneration; $800 - 1,200 monthly; Company Profile; Millipede Pte Ltd is a Singapore-based technology company specialising in Integrated Digital Delivery (IDD) solutions for the construction and real estate development sectors. Established in 2022, Millipede aims to enhance efficiency, safety, and quality across construction projects by providing a connected platform that facilitates real-time data collection and stakeholder collaboration.; What Millipede Offers; Millipede\u2019s platform is designed to integrate seamlessly into existing workflows, offering tools that cater to various stakeholders in the built environment:; Mobile App: Allows on-site workers & supervisors to report progress, complete checklists in real-time and manage approvals, ensuring accurate and timely data collection.; Web Portal: Provides project managers and administrators with a centralised dashboard to monitor activities, manage stakeholders, and track project timelines across multiple sites.; Milli-Tools*: A suite of customisable tools that aid in accurate progress tracking, safety compliance and quality assurance.; By leveraging these tools, Millipede enables firms to optimise processes, reduce turnaround times, and improve overall project outcomes.; Job Description; We are looking for a skilled and detail-oriented Data Engineer \/ BI Engineer Intern to join our team. This role requires a strong foundation in SQL, data engineering, and dashboard development, along with a passion for data-driven solutions, automation, and exploring data science applications.; At Millipede, we encourage innovation and technical exploration. The construction industry presents a unique mix of challenges and opportunities, where problems are rarely straightforward but always exciting to solve. If you're someone who enjoys tackling complex problems, you'll have the freedom to experiment with cutting-edge tools, frameworks, and technologies to streamline workflows, drive automation, and extract powerful data insights. Millipede is a place where curiosity meets impact - come build something meaningful with us.; Responsibilities; Explore, clean, and manage datasets efficiently with minimal supervision.; Develop and enhance custom customer-facing reports and dashboards tailored to specific client needs.; Set up and manage pipelines for handling large-scale data processing, model execution, and performance monitoring. Experience with workflow automation and optimizing model-driven systems is beneficial; Experiment with new tools and frameworks to streamline data workflows and improve automation.; Work closely with engineering and product teams to ensure data accuracy and consistency.; Required Skills; SQL proficiency \u2013 experience with BigQuery or equivalent.; Strong experience in data transformation and pipeline setup.; Resourceful self-starter with the ability to understand datasets proactively.; Highly meticulous and sensitive to data accuracy.; Strong communication skills \u2013 ability to explain technical concepts to a range of audiences.; Basic UI\/UX familiarity for designing intuitive dashboards.; Problem-solving mindset with a structured approach to open-ended challenges.; Familiarity with Agile methodologies and iterative development processes.; Technologies you\u2019ll work with:; SQL\/ BigQuery; Google Cloud Platform \u2013 Cloud Functions, BigQuery, Firebase etc; Excel \/ Google Sheets; Visualization Tools \u2013 Looker Studio, Tableau, Power BI etc.; Scripting Languages \u2013 JavaScript, Bash, TypeScript; Python \u2013 Pandas, SciPy, Scikit-learn, TensorFlow\/PyTorch etc.; This role requires on-site presence. We value in-person collaboration, as it allows us to better understand and design for the people we serve.; This position is already closed and no longer available.  You may like to view the other latest internships here.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85482964","Role":"Senior Data Test Engineer","Company":"Tech Mahindra","Location":"Changi","Publish_Time":"2025-07-04 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85482964","job_desc":"KEY ACCOUNTABILITIES; Maintain and adopt Agile best practices and lifecycles for process workflows (e.g., Kanban, CI\/CD); Collaborate with business users and business analysts to refine and understand both functional and non-functional requirement during SIT & UAT stages.; Develop automated test scripts to validate functional and technical requirements in data processing pipeline and to perform data quality checks; Collaborate with data analysts in profiling data and monitoring data trends; Collaborate with Developers\/DevOps Engineers on code management, peer review, continuous integrated testing in CI\/CD pipelines; Assure quality at different phases of SDLC by adhering to process and strategies defined by Eastspring IT; Execute manual \/ automated \/ exploratory tests and provide QA sign-off to business users for releases; Maintain test process, design and execution artifacts in test management system complying the audit regulations; Prepare testing traceability reports and other testing metrics; QUALIFICATIONS \/ EXPERIENCE; Recognized degree or higher in Computer Science or related Engineering fields.; At least 8 years of working experience in Test Automation, using test frameworks for Database (ETL Testing) and Data analytical testing.; Working knowledge in testing Data management platform tools same-as\/similar-to \u2018Golden Source\u2019; Sound knowledge in Java programming, SQL queries and Cucumber (Java) testing framework.; Good knowledge in testing scheduling\/orchestration tools (like Control-M, Azure Data Factory); Working knowledge of relational databases and comfortable with testing SQL jobs and stored procedures with awareness of data security.; Basic understanding of data quality, profiling, and analytics concepts.; Working experience with test management tools such as Jira with Xray \/ Zephyr; Working knowledge of tools such as bitbucket, Jenkins, confluence and familiar with Git branching model; Working experience in Agile projects, Behavior Driven Development (BDD) approach to software development and testing.; Good to have basic programming knowledge in Python; Good to have knowledge of Azure cloud platform.; Good to have working experience in investment Bank or Asset Management industry.; OTHER TRAITS; Positive attitude and collaborative mindset.; Willing to work across projects and perform manual \/ automation \/ exploratory testing; Highly motivated to keep abreast with the latest development in technology and to acquire deep technical knowledge and skills.; Excellent communication, presentation, and interpersonal skills.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85005477","Role":"VP, Specialist, AI Governance, Transformation & Data, Group COO - (WD74069)","Company":"DBS Bank Limited","Location":"Downtown Core","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85005477","job_desc":"Business Function; Here at the DBS Transformation Group, we focus on nurturing the culture of the \u201cWorld\u2019s Best Digital Bank\u201d (Euromoney, 2016 & 2018) and Best Bank in the World (Euromoney 2019). Our approach is a combination of both science and art; we immerse our stakeholders in the world of design thinking and experimentation, drive rigorous creativity along our pipeline, and build connections between corporate entrepreneurs and start-ups. We are a cross-disciplinary team focused on the invention of solutions that will radically improve the way people live, work and play. We are passionate and committed to make banking joyful (while having lots of fun)!; Responsibilities; Lead the development and implementation of AI governance policies and frameworks to ensure the ethical, safe and compliant use of AI across DBS Bank; Evaluate AI use cases and provide advice to use-case teams on use-case specific governance; Run bank-wide AI governance processes; Work with technical teams to establish and improve central tools and training to support AI governance implementation and control; Engage stakeholders across business and technology units to foster a culture of responsible AI, and advise on governance best practices; Represent DBS Bank on industry initiatives and forums related to AI ethics, governance and regulation; Requirements; Degree in a relevant field such as computer science, engineering, mathematics, or data science; 10+ years of experience in technology management, risk management or regulatory compliance; Strong understanding of AI technologies such as machine learning, deep learning, GenAI and Agentic AI; Expert knowledge of data privacy regulations such as PDPA and emerging AI governance standards; Ability to develop practical solutions and provide strategic guidance to senior stakeholders; Apply Now; We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85790972","Role":"Digital, Cloud, Data (Data) Consulting Year-End Internship (Dec 2025 - Feb 2026)","Company":"PricewaterhouseCoopers","Location":"Singapore","Publish_Time":"2025-07-15 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85790972","job_desc":"Line of Service; Advisory; Industry\/Sector; Not Applicable; Specialism; Technology Strategy; Management Level; Intern\/Trainee; Job Description & Summary; At PwC, we help clients build trust and reinvent so they can turn complexity into competitive advantage. We\u2019re a tech-forward, people-empowered network with more than 370,000 people in 149 countries. Across audit and assurance, tax and legal, deals and consulting we help clients build, accelerate and sustain momentum. Find out more at www.pwc.com.; The Cloud, Digital, Data (Data) team helps clients optimise data and analytical assets to make better decisions, work more efficiently, and find new sources of revenue.; The team seeks to understand our clients\u2019 challenges and identify ways of using data through data mining, modelling and advanced predictive and simulation analytics to assist them in navigating the impact of various financial or operational changes to their business.; We have a supportive and diverse team who strongly believes in learning and growing as a team. By joining the team, you will have the opportunity to be exposed to a range of industry and clients and solve interesting problems with data.; We are looking for candidates to join us for our year-end internship from December 2025 to January\/February 2026 (min. 8 weeks); Responsibilities: ; You will understand and analyse complex client commercial, operational and financial data ; You will design, build and review analytical models to find solutions for our client\u2019s business challenges ; You will translate complex findings into simple language and communicate them to internal and external stakeholders, such as your clients and team members ; Requirements: ; Penultimate year Computer Science, Computer Engineering, Engineering, Information Systems or other related disciplines that have an analytical component and quantitative focus students from local or overseas universities ; Pro-active, adaptable, and flexible. Able to apply new tools and techniques such as proprietary analytical software, data models and programming languages ; Strong analytical and critical thinking skills. Able to analyse and break down complex concepts and technical findings into clear and simple language ; It will be required to have basic competency in one or more of the following: ;                 (a) Analytical software and languages (e.g. PowerBI, Python, R)             ;                 (b) Relational or graph databases and tools (eg. SQL, SSMS, MySQL) ;                 (c) Knowledge of simulation or optimisation software and theory (e.g. discrete choice, agent based) ; Note:  ; Please note we accept only one application per candidate. You may indicate your second preference in the same application. We recommend that you apply to your preferred position that closely aligns with your skills, passions and interests ; You can indicate another role on the same application form. Duplicate entries will slow down your application with us ; Kindly upload both your resume and degree audit or transcript in PDF format.  ; Kindly note that only shortlisted candidates will be contacted. ; Got a question? Email to sg_graduate_recruitment@pwc.com; Education (if blank, degree and\/or field of study not specified); Degrees\/Field of Study required:Degrees\/Field of Study preferred:; Certifications (if blank, certifications not specified); Required Skills; Optional Skills; Accepting Feedback, Accepting Feedback, Active Listening, Algorithm Development, Alteryx (Automation Platform), Analytic Research, Big Data, Business Data Analytics, Communication, Complex Data Analysis, Conducting Research, Customer Analysis, Customer Needs Analysis, Dashboard Creation, Data Analysis, Data Analysis Software, Data Collection, Data-Driven Insights, Data Integration, Data Integrity, Data Mining, Data Modeling, Data Pipeline, Data Preprocessing, Data Quality {+ 33 more}; Desired Languages (If blank, desired languages not specified); Travel Requirements; Not Specified; Available for Work Visa Sponsorship?; Yes; Government Clearance Required?; No; Job Posting End Date","salary":"","work_type":"","country":"singapore"}
{"Job_ID":"85155306","Role":"Backend Engineering Lead - Global E-Commerce (Commercial Platform - Data...","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155306","job_desc":"Responsibilities; About TikTok TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok sponsorship of a visa. --- TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo. --- Why Join Us Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. Join us. --- About The e-commerce industry has seen tremendous growth in recent years and has become a hotly contested space amongst leading Internet companies, and its future growth cannot be underestimated. With millions of loyal users globally, we believe TikTok is an ideal platform to deliver a brand new and better e-commerce experience to our users. We aim to bring discovery, inspiration, and joy back to shopping by making TikTok the commerce channel of choice for merchants, creators, and affiliates.With millions of loyal users globally, we believe TikTok is an ideal platform to deliver a brand new and better e-commerce experience to our users. We are looking for passionate and talented people to join our product and operations team, to build an e-commerce ecosystem that is innovative, secure and intuitive for our users and brands. --- About the team The Data Intelligence team is responsible for development of data analytics & data-empowered platform capabilities across Global E-Commerce. Our mission is to empower our users to leverage and extract actionable insights from data to maximise their potential and efficiency on the global e-commerce platform. In essence, we want to extract facts, attribute causes and predict the future from oceans of data; and our fundamental goals are to reflect business impact, leverage data to support key decisions by lowering decision making complexity and optimising decision making efficacy and efficiency. --- Responsibilities 1. Develop a top-tier data product system that offers dependable insights and analytical diagnostics for both internal and external business users, fostering ongoing growth. 2. Steadily advance the development and enhancement of our data system architecture, focusing on reliability, reusability, scalability among others. 3. Work in tandem with upstream and downstream departments to jointly design and construct data production pipelines as well as data management platforms for efficient and adaptable metrics management. 4. Research, design, and develop computer and network software or specialised utility programs. 5. Analyse user needs and develop software solutions, applying principles and techniques of computer science, engineering, and mathematical analysis. 6. Update software, enhances existing software capabilities, and develops and direct software testing and validation procedures. Qualifications; 1. Bachelor's or higher degree in Computer Science, Information Technology, Programming & System Analysis, Science (Computer Studies) or related discipline. 2. At least 2+ years of experience managing or tech-leading a software engineering team and at least 5 years of experience in constructing large-scale, high-availability distributed backend systems. 3. Proficient in software programming with a deep understanding of data structures and algorithms; demonstrates excellent code design and coding style. 4. Well-understanding with mainstream distributed system platforms and tools: programming languages (Java\/Golang\/Python\/C++), databases and caches (Mysql\/PostgreSQL\/Redis), message queue platforms (Kafka\/RocketMQ) etc. 5. [Optional] Familiarity with big data technology stack including Flink, Spark, ClickHouse, Hive. Ideal Candidate 1. Agile, quick learner with a strong sense of product ownership and a knack for creative problem-solving. 2. Expertise in both product and data science, capable of merging technical and data perspectives to provide fresh insights and directions for the team 3. Skilled at leading teams through technical breakthroughs and resolving complex issues. 4. An empathetic leader focused on results, adept at mentoring others. 5. A great collaborator who thrives in fast-paced, culturally diverse global team environments. --- TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. ---","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85666337","Role":"DevOps Engineer (AI Infrastructure)","Company":"OOm Pte Ltd","Location":"Central Region","Publish_Time":"2025-07-11 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85666337","job_desc":"\ud83d\ude80 Join Our AI-Powered Mission \u2013 DevOps Engineer Wanted!; About Us; We\u2019re a fast-growing digital agency building next-gen, AI-powered products that solve real-world problems. As our AI team rapidly expands, we\u2019re looking for a DevOps Engineer who\u2019s passionate about automation, cloud infrastructure, and scalable systems. If you're excited by the idea of enabling cutting-edge AI workflows and building systems that scale intelligently\u2014you\u2019ll fit right in.; The Opportunity; As our DevOps Engineer, you\u2019ll be the backbone of our AI\/ML infrastructure. You\u2019ll own the CI\/CD pipelines, cloud infrastructure, and automation processes that bring powerful AI models and digital products to life. This role is perfect for someone who thrives in a fast-paced environment, enjoys solving complex problems, and wants to play a key role in shaping how scalable AI is delivered.; What You\u2019ll Be Doing; Design, build, and manage CI\/CD pipelines for AI models, APIs, and supporting services; Architect and maintain cloud infrastructure (AWS\/GCP) with a focus on scalability, cost-efficiency, and security; Support containerized environments using Docker and Kubernetes (EKS, GKE, etc.); Collaborate with AI engineers and developers to automate data pipelines, model deployment, and system monitoring; Implement Infrastructure as Code (IaC) with tools like Terraform or Pulumi; Ensure system reliability, performance, and quick issue resolution; Champion DevOps best practices across security, version control, and documentation; What We\u2019re Looking For; 3+ years of experience in DevOps, SRE, or infrastructure engineering; Strong hands-on expertise with AWS and\/or GCP; Solid experience with CI\/CD tools (GitHub Actions, GitLab CI, Jenkins, etc.); Proficient with Docker, Kubernetes, and container orchestration; Bonus: Familiarity with AI\/ML workflows, observability tools, and performance tuning; Why Join Us?; Be part of an AI-driven team shaping the future of digital solutions; Work on high-impact projects with cutting-edge tools and technologies; Collaborate in a fast-paced, agile environment that values experimentation and innovation; Competitive salary, flexible work setup, and real opportunities for growth; Ready to scale what\u2019s next?; Apply now and help us build the future\u2014one automated deployment at a time.","salary":"$4,000 \u2013 $4,500 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"84571722","Role":"Senior Software Engineer, Developer Experience","Company":"Airwallex","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84571722","job_desc":"About Airwallex; Airwallex is the only unified payments and financial platform for global businesses. Powered by our unique combination of proprietary infrastructure and software, we empower over 150,000 businesses worldwide \u2013 including Brex, Rippling, Navan, Qantas, SHEIN and many more \u2013 with fully integrated solutions to manage everything from business accounts, payments, spend management and treasury, to embedded finance at a global scale.; Proudly founded in Melbourne, we have a team of over 1,700 of the brightest and most innovative people in tech across 26 offices around the globe. Valued at US$6.2 billion and backed by world-leading investors including Visa, Airtree, Blackbird, Sequoia, DST Global, Greenoaks, Salesforce Ventures, Lone Pine, and Square Peg, Airwallex is leading the charge in building the global payments and financial platform of the future. If you\u2019re ready to do the most ambitious work of your career, join us.; About the team; The Developer Experience (DevX) team oversees our customer\u2019s developer journey from discovery to building at scale. We aim to provide an onboarding experience so intuitive and well-organized that developers can discover product details, learn implementation specifics, and develop independently. During build and scale, our customers have developer affordances that are comprehensive, ergonomic and delightful.; We achieve this by providing structured channels to collect feedback and use data analytics informing us on how we can provide the best experience.; What you\u2019ll do; Responsibilities:; Collaborate with product, engineering, customer-success, and technical support teams to refine & streamline the developer experience for our customers.; Ensure our APIs meet the highest standards and conventions.; Create next-in-class user and data analytics pipeline.; Build world-class developer portal and docs with AI as a core feature; Contribute to open source and fostering a developer community; Incorporate the latest technologies and up-leveling our tech stack.; Develop external tools and services that get released to our customers.; Who you are; We\u2019re looking for people who meet the minimum qualifications for this role. The preferred qualifications are great to have, but are not mandatory.; Minimum qualifications:; Bachelor degree or above in computer science or engineering related majors.; A passion for building delightful developer-facing products.; Advanced knowledge of one or more programming languages, including but not limited to Java, Kotlin, Python, Typescript.; Strong communication and collaboration skills.; Evidence of working on high-volume distributed systems.; Strong cloud experience with GCP (preferred) or AWS (EC2, RDS, ELB, CloudFront, etc.) with Docker and Kubernetes.; Preferred qualifications:; Released and maintained well-known APIs or have API design experience.; Experience within the financial domain.; Led major migrations in software that involved breaking changes.; Worked in both early-stage startups (<20) and 1000+ sized companies.; Deep proven technical knowledge of either front-end and\/or backend systems.; Worked in developer experience or other customer-facing engineering roles.; Equal opportunity; Airwallex is proud to be an equal opportunity employer. We value diversity and anyone seeking employment at Airwallex is considered based on merit, qualifications, competence and talent. We don\u2019t regard color, religion, race, national origin, sexual orientation, ancestry, citizenship, sex, marital or family status, disability, gender, or any other legally protected status when making our hiring decisions. If you have a disability or special need that requires accommodation, please let us know.; Airwallex does not accept unsolicited resumes from search firms\/recruiters.  Airwallex will not pay any fees to search firms\/recruiters if a candidate is submitted by a search firm\/recruiter unless an agreement has been entered into with respect to specific open position(s).  Search firms\/recruiters submitting resumes to Airwallex on an unsolicited basis shall be deemed to accept this condition, regardless of any other provision to the contrary.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155197","Role":"Backend Software Engineer (Data Management Suite) - 2025 Start","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155197","job_desc":"Responsibilities; About the Team The Data Management Suite team is building products that cover the whole lifecycle of data pipeline, including data ingestion and Integration, data development, data catalog, data security and data governance. These products support various businesses, so data engineers and data scientists could greatly boost their productivity.; As a software engineer in the data management suite team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on core systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.; Responsibilities:; Design and implement a unified data development platform that improves the efficiency of globalization data producers, which includes intelligence IDE, workflow management, multiple engine integration etc.; Fingure out efficient ways to manage distributed states, and sync metadata between centralized place and regions globally;; Design and develop a high-performance and distributed scheduling system that manages large-scale tasks across different business lines in whole ByteDance;; Work closely with partner teams across the company and all over the world;; Responsible for the design and development of integration with other systems in the big data area; Qualifications; Minimum Qualifications:; Bachelor's degree in Computer Science or equivalent practical experience;; Be familiar with at least one backend language, like Java, GO, Python etc;; Experience in software development, and with data structures\/algorithms;; Experience with design and architecture, and testing and launching software products;; Preferred Qualifications:; Be familiar with web frameworks will be a plus, like Spring boot etc.; Experiences in data platform related product development or big data technologies (such as Hadoop, Clickhouse, Flink etc.) will be a plus;; By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https:\/\/careers.tiktok.com\/legal\/privacy. If you have any questions, please reach out to us at apac-earlycareers@tiktok.com","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"83897177","Role":"Backend Software Engineer, Ads Data (Data Platform)","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83897177","job_desc":"Responsibilities; Team Introduction Ad Data is the cornerstone of every business decision that millions of advertisers make every day on TikTok. Therefore, we are tasked with innovating on daily basis to create and maintain complex systems at large scale and continue expanding the capacity to better serve advertisers growing at exponential pace. Our ads data platform team work closely with our product managers and data analysts by building state of the art streaming and batch data processing solution. The entire data pipeline is supporting both the TikTok ads platform and our internal business intelligence platform. In this role, you will see a direct link between your work, and the company's business success. You will have opportunities to deal with Petabyte-level data warehouse. Some of the world's most challenging technical and business problems are waiting for you to solve. Responsibilities: - Plan and push forward large-scale technical projects to lay the foundation for the iterative platform development - Develop core data platform\/product features based on open source and in-house technologies to empower TikTok's Ads data - Continuously invest in cutting-edge OLAP technologies and scale our systems as business grows - Iterate our development and operational toolsets to improve R&D productivity, and participate in infrastructure oncall rotations Qualifications; Minimum Qualifications: - Fluency in at least one programming language such as Java\/Scala\/C\/C++\/Python - Working experience of distributed storage engines (Elasticsearch\/Druid\/ClickHouse\/Doris) or computational frameworks (Hadoop\/Spark\/Flink\/Hive\/Presto) - Able to work closely with diverse stakeholders and have good communication skills \u2022 Passionate about building reliable infrastructure Preferred Qualifications - Understanding of ads technology\/product is helpful but not required","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84983757","Role":"Sales - Software Engineer (Data), PART","Company":"Apple Inc.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84983757","job_desc":"Summary; Posted: Jun 16, 2025; Weekly Hours: 38; Role Number:200608513; Imagine what you could do here. The people at Apple don\u2019t just create products \u2014 they create the kind of wonder that\u2019s revolutionized entire industries. It\u2019s the diversity of those people and their ideas that inspires the innovation that runs through everything we do. Bring passion and dedication to your job and there's no telling what you could accomplish! Apple's Finance Process, Analytics, Reporting, and Technology (PART) team is looking for a passionate and highly motivated Software Engineer. As part of this team, you will support Apple\u2019s growth, both top and bottom line, by applying the same level of innovation toward financial matters as we do toward our products and services. The PART team is seeking an experienced Software Engineer to build high quality, scalable and resilient distributed systems that power Apple's cloud analytics platforms and data pipelines. Apple's Enterprise Data Warehouse landscape caters to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are an integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing and Internet Services, enabling business drivers to make critical decisions. We use proprietary and open source technologies, Kafka, Spark, Iceberg, Airflow, Presto, etc. If you are looking to tackle infrastructure problems at scale, both on-prem or in cloud, focusing on ease of use, ease of maintenance and most importantly implement solutions that are scalable, you will enjoy working in PART!; Description; We engineer high-quality, scalable and resilient distributed systems on cloud that power data exploration, analytics, reporting and production models. Our core systems are diverse and come with an unusual intersection of high data volumes with systems distributed across cloud and on-premise infrastructure. This role will build solutions that integrate open source software with Apple\u2019s internal ecosystem. You will drive development of new components and features from concept to release: design, build, test, and ship at a regular cadence. You will work closely with internal customers to understand their requirements and workflows, and propose new features and ecosystem changes to streamline their experience of using the solutions on our platform. This is a challenging software engineering role, where a large part of an engineer's time is spent in writing code and designing\/developing applications on cloud, with the remainder being spent on tuning and debugging codebase, supporting production applications and supporting our application end users. This role requires in-depth knowledge of innovative technologies and cloud data platform with the ability to independently learn new technologies and contribute to the success of various initiatives.; Minimum Qualifications; 4 or more years of experience building enterprise-level data applications on distributed systems; Knowledge of BI concepts and Implementation experience on Cloud with databases like SnowFlake or Big Query; Programming experience with Python, Scala or Java.; Experience in developing highly optimized SQLs, procedures & semantic process for distributed data applications; Bachelor\u2019s degree in Computer Science or equivalent experience; Preferred Qualifications; Hands-on experience in designing and development of cloud-based applications that include compute services, database services, APIs to design RESTful services, ETL, queues and notification services.; Experience in cloud data warehousing platforms like Snowflake is highly valued; Hands-on knowledge of Spark cluster-computing framework & Kubernetes or similar containerization technologies.; Experience developing Big Data applications using Java, Spark, Kafka is a huge plus; Understanding of fundamentals of object-oriented design, data structures, algorithm design, and problem solving; Cloud technology experience on platforms like AWS, Microsoft Azure, Google Cloud; Data Visualization Tools: experience in software such as Streamlit, Superset, Tableau, Business Objects, and Looker; Data Insights and KPIs: Working experience on generating and visualizing data insights, metrics, and KPIs. Usage of basic ML models in the space of anomaly detection, forecasting, GenAI.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85616032","Role":"VP\/AVP, Cloud Security Engineer, Information Security Services, Group Technology","Company":"DBS Bank Limited","Location":"Singapore River","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85616032","job_desc":"DBS is a leading financial services group in Asia, with over 280 branches across 18 markets. Headquartered and listed in Singapore, DBS has a growing presence in the three key Asian axes of growth: Greater China, Southeast Asia and South Asia. The bank's capital position, as well as \"AA-\" and \"Aa1\" credit ratings, is among the highest in Asia-Pacific. DBS has been recognised for its leadership in the region, having been named \u201cAsia\u2019s Best Bank\u201d by The Banker, a member of the Financial Times group, and \u201cBest Bank in Asia-Pacific\u201d by Global Finance. The bank has also been named \u201cSafest Bank in Asia\u201d by Global Finance for seven consecutive years from 2009 to 2015.; Business Function; Group Technology enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group Tech, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.;   Responsibilities; This candidate will be responsible for the implementation and governance of cloud and container security controls and tooling across platforms, while driving risk assessments, incident response, and compliance in cloud-native and containerized environments.; Lead the evaluation, implementation, and operationalization of security controls for public clouds and container platforms such as (AWS, GCP, Azure, OpenShift, PCF, VIC).; Define and enforce security baselines, architecture patterns, and hardening standards for cloud workloads and container platforms.; Participate, perform threat modelling and risk assessments for cloud projects, identifying security gaps and defining effective controls aligned with regulatory and industry frameworks.; Review and assess cloud implementations, defined through Infrastructure as Code (IaC) and CI\/CD pipelines, to identify security gaps and ensure alignment with access control best practices and compliance requirements.; Serve as a trusted security advisor to stakeholders and senior management, translating technical risks into actionable strategies for secure cloud adoption.; Continuously evaluate emerging threats and technologies, driving the adoption of new technologies and processes to enhance the bank\u2019s cloud security posture without compromising performance or usability.; Develop and manage monitoring and alerting systems, perform incident triage, vulnerability scans, and execute root-cause analysis.; Design and implement automated detection, alerting, and remediation workflows using scripting, IaC, and SOAR platforms.; Requirements; Bachelor\u2019s or Master\u2019s degree in Computer Science or equivalent; Working experience developing applications or managing infrastructure services for public cloud such as AWS, GCP or Azure; Programming skills in at least one programming language: Python, Javascript, Java, C\/C++; Working experience in the information technology domain (computer\/mobile application, APIs, container technology such as Dockers, public cloud, data science etc) and preferably in the information security (public cloud) domain; Experience performing system analysis and design requirements gathering.; Professional certification such as CISSP, GIAC GISP will be an added advantage; Public cloud certifications; Possess good technical knowledge in various security tools (end-point, network, authentication etc); Good understanding of regulatory requirements (e.g. MAS Technology Risk Management Guidelines, PCI DSS, Personal Data Protection Act); Knowledge of tactics, techniques, and procedures associated with malicious insider activity, organized crime\/fraud groups and both state and non-state sponsored threat actors.; Able to perform coding on need-to basis to build or enhance existing security solution; Knowledge and working experience of financial security standards such as EMV, PCI DSS, is advantageous.; Good networking with other security professionals in the financial industry; Apply Now; We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155024","Role":"Backend Software Engineer - TikTok Live (Data Platform) - Singapore","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155024","job_desc":"Responsibilities; TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy; a mission we all believe in and aim towards achieving every day.; To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact; for ourselves, our company, and the communities we serve.; Join us. With the enormous growth of live streaming in recent years, our mission is to inspire real-time interactions and help live streamers connect to people from all corners of the globe. We are looking for passionate and talented engineers to join us to build and optimize a real-time, high-performance, large-scale distributed infrastructure for live streaming in TikTok.; You will be deeply involved in the developmental lifecycle of critical product features and collaborate closely with product managers to deliver the best live streaming experience for all live streamers and audience alike. TikTok Live Data Platform is building the Index Platform, Label Platform, Portrait Platform, Diagnostic Platform, Data Asset Management Platform, Data Suite and in-place solutions for business. Which involves compute(Streaming processing, Offline pipeline) and storage(OLAP: Clickhouse\/Doris, KV store).; Now we're supporting end-users TikTok app and Agency's Backstage data applications, enhancing internal platforms with data suites, analysis, diagnosis. We're always encouraging R&D to deliver tech-driven projects to enrich business with insights from data. You will:; Plan and lead large-scale technical projects to lay the foundation for the iterative development and scale of early products; Develop robust, efficient technology products that serve 1 billion users; Contribute to engineering strategy, tooling, processes, and culture; Research and apply cutting-edge domain and technical knowledge into products; Qualifications; - As a world-class engineer, you have rich working experience in scalable, highly available, distributed and mission-critical systems. - Deep understanding of computer architectures, data structures and algorithms. - Able to work closely with diverse stakeholders and have good communication skills; - Self-driven, positive, cooperative and willing to keep learning enthusiasm at all times Preferred Qualification Minimum 3 years relevant work experience from a large-scale internet business; TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy.; To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. #LI-JG1","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85612748","Role":"ETL Test Architect","Company":"Tech Mahindra","Location":"Singapore","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85612748","job_desc":"Skill Set : API testing; Total Experience : 4.00 to 12.00 Years; No of Openings : 1; Job Post Date : 09\/07\/2025; Job Expiry Date : 09\/08\/2025; Domain : IT; Location : SINGAPORE [Singapore]; Job Reference No : 1054930; Job Summary; Senior Data Test Engineer KEY ACCOUNTABILITIES Maintain and adopt Agile best practices and lifecycles for process workflows (e.g., Kanban, CI\/CD); Collaborate with business users and business analysts to refine and understand both functional and non-functional requirement during SIT & UAT stages. Develop automated test scripts to validate functional and technical requirements in data processing pipeline and to perform data quality checks Collaborate with data analysts in profiling data and monitoring data trends; Collaborate with Developers\/DevOps Engineers on code management, peer review, continuous integrated testing in CI\/CD pipelines Assure quality at different phases of SDLC by adhering to process and strategies defined by Eastspring IT Execute manual \/ automated \/ exploratory tests and provide QA sign-off to business users for releases; Maintain test process, design and execution artifacts in test management system complying the audit regulations Prepare testing traceability reports and other testing metrics QUALIFICATIONS \/ EXPERIENCE; Recognized degree or higher in Computer Science or related Engineering fields. At least 8 years of working experience in Test Automation, using test frameworks for Database (ETL Testing) and Data analytical testing. Working knowledge in testing Data management platform tools same-as\/similar-to \u2018Golden Source\u2019; Sound knowledge in Java programming, SQL queries and Cucumber (Java) testing framework. Good knowledge in testing scheduling\/orchestration tools (like Control-M, Azure Data Factory) Working knowledge of relational databases and comfortable with testing SQL jobs and stored procedures with awareness of data security.; Basic understanding of data quality, profiling, and analytics concepts. Working experience with test management tools such as Jira with Xray \/ Zephyr Working knowledge of tools such as bitbucket, Jenkins, confluence and familiar with Git branching model; Working experience in Agile projects, Behavior Driven Development (BDD) approach to software development and testing. Good to have basic programming knowledge in Python Good to have knowledge of Azure cloud platform.; Good to have working experience in investment Bank or Asset Management industry. OTHER TRAITS Positive attitude and collaborative mindset.; Willing to work across projects and perform manual \/ automation \/ exploratory testing Highly motivated to keep abreast with the latest development in technology and to acquire deep technical knowledge and skills. Excellent communication, presentation, and interpersonal skills.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85108231","Role":"Senior Cloud Engineer","Company":"Manpower Staffing Services (S) Pte Ltd - Head Office","Location":"Central Region","Publish_Time":"2025-06-23 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85108231","job_desc":"Job Responsibilities; Take ownership of engineering the secure development environment, ensuring infrastructure security, compliance, and efficiency.; Work closely with solution architect and drive the engineering of Azure Cloud infrastructure including DevBox and contribute to the project.; Ensure best practices are followed, provide technical guidance to the team and deliver robust and innovative cloud infrastructure solutions.; Provide technical expertise and guidance on Azure Cloud infrastructure solutions and services, experience with Intune is a plus.; Collaborate with cross-functional teams to design, implement and optimize cloud infrastructure.; Develop and implement automation solution to streamline infrastructure process and improve productivity.; Effective communication for status, key decisions to stakeholders, including senior management, and provide updates on risk plus dependencies.; Monitor and manage cloud infrastructure, ensuring high availability and performance.; Stay updated with the latest Azure infrastructure technologies and best practices and incorporating them into projects and operation.; Maintains awareness of industry trends on regulatory compliance, emerging threats and technologies in order to understand the risk and better safeguard the company.; Manage product lifecycle, from requirement, design, engineering, testing, acceptance, training, and documentation.; Fostering the culture of continuous learning and improvement within team member; ; Job Requirement; Degree from any recognized University preferably with major in computer science\/engineering \/Information Technology; Azure Cloud Certified; Min. 5 years of experience in cloud computing with focus on Azure Cloud infrastructure with proven track record in managing and maintaining secure cloud infrastructure environments.; Min. 12 years of experience in an operational, or service delivery role; In-depth knowledge of Azure Cloud infrastructure services and solutions; Good understanding of Azure cloud infrastructure security, compliance, and governance; Experience with infrastructure management, including provisioning, monitoring and scaling.; Proficiency in Infrastructure as code (IaC) using tools like ARM templates, Terraform.; Expertise in networking and connectivity within Azure Cloud; Skilled in scripting (e.g. PowerShell, Phyton) for infrastructure automation tasks; Familiarity with monitoring and logging tools (e.g. Azure monitor, Log Analytics, Application Insights); Experience in DevOps practices and tools, including CI\/CD pipelines; Excellent leadership and collaboration skills, with the ability to influence and drive consensus across diverse teams and stakeholders; Good delivery experience; Excellent problem-solving and analytical abilities; Effective communications and interpersonal skills; Ability to work effectively in fast-paced environment.; Adaptability and a willingness to learn and grow together with the team; Good organizational and time management skill; Certification in Project Management or Cyber Security related would be a plus; Knowledge in Banking or Financial Institution Domain is highly desirable.; Knowledge with MS Intune is desirable; Aftab Ahmed Saghana Sithara EA License No.: 02C3423 Personnel Registration No.: R1550224; ; Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and\/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit https:\/\/www.manpower.com.sg\/privacy-policy","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85608183","Role":"Backend Engineer Intern, Data Infra - OLAP (Aug - Dec 2025)","Company":"SHOPEE SINGAPORE PRIVATE LIMITED","Location":"Singapore","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85608183","job_desc":"The Engineering and Technology team is at the core of the Shopee platform development. The team is made up of a group of passionate engineers from all over the world, striving to build the best systems with the most suitable technologies. Our engineers do not merely solve problems at hand; We build foundations for a long-lasting future. We don't limit ourselves on what we can or can't do; we take matters into our own hands even if it means drilling down to the bottom layer of the computing platform. Shopee's hyper-growing business scale has transformed most \"innocent\" problems into huge technical challenges, and there is no better place to experience it first-hand if you love technologies as much as we do.; About the Team:; Shopee will be prioritizing applicants who have a current right to work in Singapore, and do not require Shopee sponsorship of a visa.; Kindly note that you can only be considered in one recruitment process at a time within Sea Group and will be considered for jobs in the order that you have applied.; Our team builds and maintains the company\u2019s big data infrastructure and platforms, ensuring they are stable, efficient, secure, and easy to use. We provide core data capabilities\u2014including storage, batch and real-time computing, querying, and analytics\u2014to support business teams, analysts, and machine learning applications. Our platforms cover the full data lifecycle, from ingestion to processing and monitoring, enabling teams to build reports, dashboards, real-time pipelines, and data-driven insights efficiently.; Job Description:; Participate in the system optimization, and maintenance of Big Data engines and platform; Engage in system performance tuning and troubleshooting, ensuring service stability and high availability; Collaborate with the product team to develop and optimize features based on business requirements; Write and maintain related technical documentation in English, ensuring knowledge consolidation; Analyze and solve user problems combining user scenarios; Requirements:; Currently enrolled in or a recent graduate of a Bachelor\u2019s program in computer science or a related field; Basic understanding of Big Data Related Components and it\u2019s internal mechanisms; Proficient in Java, HDFS, Presto, ClickHouse, Druid, and other relevant technologies; Excellent team collaboration and communication skills, able to respond and resolve issues promptly; Good English reading and writing abilities, capable of reading technical documentation in English|; Good to have:; Previous exposure to or coursework related to the Big Data domain; An interest in cloud-native technologies, including Kubernetes; A solid foundation in algorithms and a keen interest in problem-solving; Interest in open-source contributions and eagerness to learn from the open-source community; Interest in use AI to solve complex issues","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84400150","Role":"DevOps Platform Engineer APAC (F\/M\/D)","Company":"Flowdesk","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84400150","job_desc":"Flowdesk mission is to build a global financial institution for digital assets, one designed from the ground up for market integrity and efficiency.; To achieve this in a rapidly evolving market, we apply a disciplined, first-principles approach to everything we do. This approach is embedded in our core services, from institutional liquidity provision, trading solutions, OTC execution to our comprehensive treasury management offerings. This is how we cut through the noise and build robust and scalable systems across all our business lines.; Therefore, we seek individuals who are driven by this systematic approach. Joining Flowdesk means you will be a key contributor in building and scaling a more transparent and efficient financial markets infrastructure.; You will be part of the infrastructure team. Reporting to Flowdesk's Lead of Infrastructure and in permanent interaction with the Engineering\/Trading\/Data teams, your mission is to improve, scale, and maintain Flowdesk's infrastructures.; Your mission will be to; Improve and add new features to our CI\/CD systems (FluxCD, Github actions, python scripting ...).; Work on the Kubernetes operators to make them more efficient, and more integrated with other systems and put in place update processes such as Blue\/Green or Canary.; Work on an in-house workload orchestrator solution built using Rust language.; Develop internal tooling for our platform; You will also work on developing DevOps practices, application-level reliability, observability, performance tuning, FinOps, incident management, supporting development processes, and non-core systems.; Participate in the day-to-day operational activities.; Discuss needs with Flowdesk's teams and answer those needs.; Propose improvements and bring new ideas to the table.; Our tech stack: Kubernetes, GCP, Terraform, Ansible, NATS, Rust, Golang, Python, FluxCD, Github actions, Prometheus, Grafana, Vault, Kong.; Requirements; Background and experience; English is mandatory ; Experience with Kubernetes Operators and Kubernetes globally.; Strong backend engineering experience (python, node, golang, rust); Experience using Ansible, Terraform Google Cloud, or AWS.; Experience working with CI\/CD pipelines, fluxCD, and Github actions would be a plus.; Excellent communication skills and ability to explain technical concepts to non-technical people; Good organizational and time management skills with the ability to prioritize tasks and meet deadlines; Basic knowledge of monitoring solutions (Prometheus, Grafana, etc ...) and development (python, node); Strong interest in technology and eagerness to learn new technologies and concepts; Benefits; International environment (English is the main language); An allowance of 400 SGD \/ per month \/ per person in the household; Top-of-the-range equipment Macbook, keyboard, laptop stand, 4K monitor & headphones; Team events and offsites; Are you interested in this job but feel you haven't ticked all the boxes? Don't hesitate to apply and tell us in the cover letter section why we should meet!; Here's what you can expect if you apply; HR Call with the Tech Talent Acquisition (30'); Technical round with the Lead of the Infrastructure team (45\u2019); Technical interview with the Head of the Infrastructure department (60\u2019); Culture fit with the Lead Talent Acquisition (30'); We focus on conversations, not trick questions. These discussions will help you understand how Flowdesk operates and allow you to share your journey and what you\u2019re looking for in your next role.; So... Ready to Join Us?; If you\u2019re excited by the opportunity to shape crypto's future and directly impact our cutting-edge infrastructure, we\u2019d love to hear from you! Apply today and let\u2019s explore how we can build great things together.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85717868","Role":"VP, Strategic Planning, Transformation and Data, Group COO","Company":"DBS Bank Limited","Location":"Central Region","Publish_Time":"2025-07-14 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85717868","job_desc":"Business Function\\:; Here at the DBS Transformation & Data, Group COO, we focus on nurturing the culture of the \u201cWorld\u2019s Best Digital Bank&rdquor; (Euromoney, 2016 & 2018) and Best Bank in the World (Euromoney 2019). Our approach is a combination of both science and art; we immerse our stakeholders in the world of design thinking and experimentation, drive rigorous creativity along our pipeline, and build connections between corporate entrepreneurs and start-ups. We are a cross-disciplinary team focused on the invention of solutions that will radically improve the way people live, work and play. We are passionate and committed to make banking joyful (while having lots of fun)!; Responsibilities; Work with internal and external stakeholders on the strategy development and planning of Transformation and Data Group; Track, measure, and manage performance to meet unit goals. Identify potential risks to ensure timely action is taken to bridge gaps.; Support management by preparing presentations and reports with analytical and strategic information gathered from various data sources or from stakeholders; Support strategic projects\/initiatives to address unit\u2019s needs and opportunities; Manage employee experience initiatives for the unit to cultivate a positive team culture; Craft communication to support senior leadership and management team to convey key messages to the organisation; Support the unit\u2019s external speaking engagements\/visits in alignment with DBS brand messaging; Support leadership team in organising meetings, conferences, townhalls to support and drive unit\u2019s agenda; Keep proper files and archives of performance data, reports, budgeting, and meeting notes; Requirements\\:; Bachelor\u2019s degree with more than 8 years of working experience in banking, data\/technology companies or management consulting; Strong follow-up skills; responsive and proactive; Self-starter with strong experience indeveloping and implementing new ideas; Excellent in crafting decks, memos, speaking engagement notes for senior management; A problem solver who is able to work with ambiguity and possess strong business acumen; Excellent communication skills - verbal and written; Data-driven and detailed; Proven experience in managing multiple stakeholders and teams, in areas of responsibilities; Timely delivery and excellent quality on KPIs and projects \u2013 ability to demonstrate thinking out of the box, not accepting status quo, consistently looking for opportunities to improve\/enhance areas of focus; Possess excellent Microsoft office skills, especially PowerPoint and excel","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84894159","Role":"Java\/Scala Data Engineer, Vice President","Company":"Morgan Stanley","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84894159","job_desc":"We are seeking someone to join our team as a Data Engineer as part of the Fixed Income Federal Risk Applications department.; In the Technology division, we leverage innovation to build the connections and capabilities that power our Firm, enabling our clients and colleagues to redefine markets and shape the future of our communities.; The Fixed Income Federal Risk Applications department has a strong presence in Singapore. Our focus is developing systems serving as a data integration and feeding platform, ensuring that calculation results and other data initiated in our Division reaches our downstream clients and meeting all their requirements. The main challenges in this area are the volume of the data (feeding hundreds of gigabytes daily), interfacing with multiple other systems, being exposed to different financial products to a certain extent and being resilient to errors while keeping our SLA-s. The data we feed is critical in fulfilling the regulatory requirements set by the FED, PRA or BAFIN. Our team is also involved in developing calculations of regulatory scenarios requested by our Market Risk Department. The main technical challenge for this team is computational complexity.; This is a Software Engineer II position at Associate Level, which is part of the job family responsible for developing and maintaining software solutions that support business needs.; ; Since 1935, Morgan Stanley is known as a global leader in financial services, continuously evolving and innovating to better serve our clients and our communities in more than 40 countries around the world.; ; What you'll do in the role:; - Work for the firm that attracts some of the brightest talents like Bjarne Stroustrup, the inventor of the C++ language; - A supportive and vibrant multinational environment, which is leveraging technology to its highest potential. We accept individual differences and believe in teamwork; - An open door to have continuous dialogue with our senior leaders - an environment where you are truly listened to; - Professional development opportunities including access to Morgan Stanley's world-class internal trainings; - A competitive compensation and benefits package including eligibility for an annual bonus and flexible working arrangements (core hours \/ work-time cycle and opportunity to work from home); What you'll bring to the role:; -At least 2 years' relevant experience would generally be expected to find the skills required for this role.; - Develop IT systems covering various aspects of the business run by our Fixed Income division; - Have the opportunity to work in close collaboration with our business user and to learn business concepts like how certain financial products and financial markets work; - Participate in every stage of the lifecycle of an IT system ranging from gathering the requirement and refining user stories, designing solutions, and writing code to help our support organization to answer the most interesting user questions; - Work on a diverse technology landscape involving various programming languages (Java, Scala, Python), data management systems, CI\/CD pipeline (Jenkins); - Our team has a wide coverage on technical and business problems to solve ranging from developing data integration and feeding solutions having extreme throughput and resiliency requirements to calculating regulatory scenarios requested by our Market Risk Department. The choice will primarily depend on skillset, personal interest and team fit You have:; - Strong analytical and problem-solving skills; - A good command of English and in general good communication skills; - Prior experience in developing data or computation intensive (e.g. grid based) backend applications is an advantage; - OOP design skills with an understanding or at least personal interest towards the concepts of Functional Programming; - Willingness to understand and enhance other people's code, being able to work in an environment where developers will oversee and work on wider components also dealing with older legacy code; - Strong Java or Scala skills with the willingness to pick up the other language if not already mastered at a sufficient level is important; - Spring knowledge is an advantage, but in general willingness to learn, work with and even enhance in-house developed frameworks is a must; - Prior experience in working with Git, Bitbucket, Jenkins, working with PR-s, using JIRA, following the Scrum Agile methodology is an advantage; - Prior knowledge of financial products is an advantage; - BSc or MSc in any relevant field of IT\/Engineering area is an advantage; What you can expect from Morgan Stanley; We have a track record of innovation and passion for unlocking new opportunities, we help our clients raise, manage and allocate capital. We do this by offering a wide range of investment banking, securities, wealth management and asset management services. All that we do at Morgan Stanley is driven by our five core values: do the right thing, put clients first, lead with exceptional ideas, commit to diversity and inclusion, and give back. These aren\u2019t just beliefs, they guide the decisions we make every day, ensuring we do what's best for our clients, communities and more than 80,000 employees around the world. And at the core of our success are the people who drive it - relentless collaborators and creative thinkers who are fueled by diverse thinking and experiences. Wherever you are in our 1,200 global offices, you\u2019ll have the opportunity to work alongside the best and the brightest in an environment where you are empowered to achieve your full potential. We are proud to support our employees and their families at every point along their work-life journey, offering some of the most attractive and comprehensive employee benefits and perks in the industry. To learn more about our offices across the globe, please copy and paste https:\/\/www.morganstanley.com\/about-us\/global-offices into your browser.; Morgan Stanley is an equal opportunities employer. We work to provide a supportive and inclusive environment where all individuals can maximize their full potential. Our skilled and creative workforce is comprised of individuals drawn from a broad cross section of the global communities in which we operate and who reflect a variety of backgrounds, talents, perspectives, and experiences. Our strong commitment to a culture of inclusion is evident through our constant focus on recruiting, developing, and advancing individuals based on their skills and talents.; WHAT YOU CAN EXPECT FROM MORGAN STANLEY:; We are committed to maintaining the first-class service and high standard of excellence that have defined Morgan Stanley for over 89 years. Our values - putting clients first, doing the right thing, leading with exceptional ideas, committing to diversity and inclusion, and giving back - aren\u2019t just beliefs, they guide the decisions we make every day to do what's best for our clients, communities and more than 80,000 employees in 1,200 offices across 42 countries. At Morgan Stanley, you\u2019ll find an opportunity to work alongside the best and the brightest, in an environment where you are supported and empowered. Our teams are relentless collaborators and creative thinkers, fueled by their diverse backgrounds and experiences. We are proud to support our employees and their families at every point along their work-life journey, offering some of the most attractive and comprehensive employee benefits and perks in the industry. There\u2019s also ample opportunity to move about the business for those who show passion and grit in their work.; Morgan Stanley is an equal opportunities employer. We work to provide a supportive and inclusive environment where all individuals can maximize their full potential. Our skilled and creative workforce is comprised of individuals drawn from a broad cross section of the global communities in which we operate and who reflect a variety of backgrounds, talents, perspectives, and experiences. Our strong commitment to a culture of inclusion is evident through our constant focus on recruiting, developing, and advancing individuals based on their skills and talents.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84871596","Role":"AWS & Azure Infrastructure Engineer (L2\/L3)","Company":"NTT Communications","Location":"East Region","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84871596","job_desc":"Make an impact with NTT DATA; Join a company that is pushing the boundaries of what is possible. We are renowned for our technical excellence and leading innovations, and for making a difference to our clients and society. Our workplace embraces diversity and inclusion \u2013 it\u2019s a place where you can grow, belong and thrive.; Job Description Summary; We are seeking a highly capable Infrastructure Engineer (L2\/L3) experienced in managing hybrid and multi-cloud environments on AWS and Azure. The ideal candidate will have proven expertise in infrastructure management, cloud migrations, and DevSecOps practices, along with a strong understanding of automation, security, and operational excellence.; Location: [Remote\/On-site\/Hybrid \u2013 specify]; Job Type: Full-Time; Experience Level: Mid to Senior (Minimum 5 Years); Key Responsibilities:; Infrastructure Management (L2\/L3):; Provide Level 2 and 3 operational support across AWS and Azure environments.; Monitor and optimize infrastructure performance, availability, and cost.; Configure and manage compute, storage, networking, and identity services across both platforms.; Cloud Migration:; Lead and support cloud migration projects from on-prem to AWS\/Azure or between clouds.; Use tools like AWS Migration Hub, Azure Migrate, CloudEndure, DMS, ASR.; Conduct workload discovery, assessment, planning, testing, and execution.; DevSecOps & Automation:; Design and implement CI\/CD pipelines using Azure DevOps, GitHub Actions, Jenkins, or AWS CodePipeline.; Automate infrastructure using Terraform, ARM Templates, Bicep, CloudFormation, or AWS CDK.; Integrate security testing (SAST\/DAST), policy-as-code, and compliance into pipelines.; Security and Compliance:; Apply cloud security best practices using IAM, Key Vault\/KMS, Defender for Cloud, Security Hub, GuardDuty.; Ensure infrastructure meets security frameworks (NIST, ISO, SOC 2, HIPAA).; Conduct regular security audits, patching, and risk remediation.; ; Monitoring and Incident Management:; Set up and manage observability stacks (e.g., CloudWatch, Azure Monitor, Prometheus, ELK, Datadog).; Create runbooks, alerts, and dashboards for proactive infrastructure management.; Participate in on-call rotation and incident response.; Collaboration & Documentation:; Collaborate with development, architecture, security, and operations teams.; Maintain detailed architecture diagrams, process documents, and knowledge base articles.; Mentor junior engineers and contribute to continuous improvement.; Academic Qualifications and Certifications:; Experience in multi-cloud and hybrid environments (on-prem + cloud).; Familiarity with Zero Trust architecture and cloud governance frameworks.; Exposure to serverless technologies and event-driven architectures.; ITIL or SRE practices knowledge is a plus.; Certifications Required:; AWS Certified Solutions Architect \u2013 Associate\/Professional; Microsoft Certified: Azure Administrator Associate \/ Solutions Architect Expert; One security-focused certification (e.g., AWS Security Specialty, Microsoft SC-200, CISSP, CompTIA Security+); DevOps\/Containerization: CKA or equivalent preferred; Required Skills and Experience:; Minimum 5 years of hands-on experience with cloud infrastructure and DevOps in AWS and Azure.; Strong command of infrastructure automation, scripting (PowerShell, Python, Bash), and CI\/CD tools.; Deep understanding of networking, DNS, VPN, load balancing, and firewalls in cloud environments.; Practical experience with container platforms (Docker, Kubernetes, AKS, EKS).; Strong problem-solving skills and ability to troubleshoot complex issues independently.; Workplace type:; About NTT DATA; NTT DATA is a $30+ billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long-term success. We invest over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure, and connectivity. We are also one of the leading providers of digital and AI infrastructure in the world. NTT DATA is part of NTT Group and headquartered in Tokyo.; Equal Opportunity Employer; NTT DATA is proud to be an Equal Opportunity Employer with a global culture that embraces diversity. We are committed to providing an environment free of unfair discrimination and harassment. We do not discriminate based on age, race, colour, gender, sexual orientation, religion, nationality, disability, pregnancy, marital status, veteran status, or any other protected category. Join our growing global team and accelerate your career with us. Apply today.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85136113","Role":"Research Associate (Data Engineer)","Company":"National University of Singapore","Location":"National University Of Singapore","Publish_Time":"2025-06-24 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85136113","job_desc":"Company description:; ; The National University of Singapore is the national research university of Singapore. Founded in 1905 as the Straits Settlements and the Federated Malay States Government Medical School, NUS is the oldest higher education institution in Singapore; ; ; Job description:; ; Job Description; The National University of Singapore invites applications for Research Associate (Data Engineer) in the Department of Biochemistry, Yong Loo Lin School of Medicine. Specifically, utilising data science approaches involving machine learning and artificial intelligence, A\/Prof Gruber's team focuses on the development and validation of biological ageing clocks for clinical translation and application. Appointments will be made on a two-year contract basis, in the first instance, with the possibility of extension.; Purpose of the post; The successful candidate should have a strong background in database administration, management and warehousing, as well as advanced machine learning, artificial intelligence, and bioinformatics techniques. Specifically, he or she will be responsible for curating and organising existing clinical databases, assist with the deployment and validation of algorithms using these databases, and related data analysis. The ideal candidate will have a strong understanding of SQL and expertise in programming languages such as Python and\/or R.; Main Duties and Responsibilities; The Research Associate will be mainly responsible for the organisation and management of clinical databases, work with other team members to deploy biological ageing clock algorithms, and support the implementation of data systems and analytics pipelines for longitudinal trials in these databases. He or she will be accountable to the Principal Investigator (PI). The Research Associate will be able to:; Organise and manage clinical databases (in SQL), as well as liaise with external collaborators to maintain data operability and regulatory compliance;; Build data systems to reduce manual data processing and integrate warehousing;; Develop and apply computational models, algorithms, and tools to analyse and interpret large-scale clinical datasets; Collaborate with data scientists to design and analyse experiments, and interpret results;; Stay up-to-date on new computational methods and tools, and apply them to ongoing research projects;; Communicate research findings through publications, presentations, and reports.; Qualifications; The ideal applicant should:; Have a Master's degree or equivalent in Data Science, Computer Science, or Biomedical Informatics;; Professional certification or equivalent in Data Engineering; Strong programming skills in SQL, Python and\/or R;; Experience with clinical data analysis and interpretation;; Excellent communication and collaboration skills;; Strong problem-solving skills and ability to work independently;; Prior experience with biomedical and clinical data, especially in the context of age-dependent diseases and ageing would be advantageous.; Remuneration will be commensurate with the candidate's qualifications and experience. Informal enquiries are welcome and should be made to A\/Prof Jan Gruber at bchjg@nus.edu.sg.; Formal application: Please submit your application, indicating current\/expected salary, supported by a detailed CV (including personal particulars, academic and employment history, complete list of publications\/oral presentations and full contacts of three (3) referees to this job portal.; We regret that only shortlisted candidates will be notified.; More Information; Location: Kent Ridge Campus; Organization: Yong Loo Lin School of Medicine; Department : Biochemistry; Employee Referral Eligible: No; Job requisition ID : 29413","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84124393","Role":"Data Engineer - Global E-Commerce (Governance Service - Security Platform)","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84124393","job_desc":"Responsibilities; Global E-Commerce is a content e-commerce business with international short video product as the carrier. It is committed to becoming the first choice for users to discover and purchase good products with affordable prices. Global E-Commerce business team hopes to provide users with more tailored and efficient consumption experience, enabling merchants to receive reliable platform services in different scenarios such as live e-commerce, short video content e-commerce, thereby making more affordable and high-quality products easily accessible and improving lives.; The Global E-Commerce's Governance and Experience is a global team responsible for ensuring a safe and trustworthy marketplace not only for our buyers but also for our sellers and creators. We continually work on areas such as risk detection abilities, fairness, and sustainability of the E-Commerce ecosystem, content and commodity quality, and friction-free experiences to drive improvement. Responsibilities:; Responsible for the offline data warehouse construction of global e-commerce security, including data layering, model design, ETL process, etc.; Establish data warehouse standards for global e-commerce security to ensure data accuracy and consistency.; Collaborate with the security team in optimising their offline tasks to ensure system stability and improving resource efficiency.; Assist in identifying risk indicators through data analysis to support the development of key security projects.; Support real-time data processing pipelines, including tagging systems and real-time ETL infrastructure.; Visualise, interpret, and report data findings and may create dynamic data reports as well.; Qualifications; Minimum Qualifications:; Bachelor's or higher degree in Computer Science, Information Technology, Programming & System Analysis, Science (Computer Studies) or related discipline.; Candidates should have at least 5 years of experience in big data ecosystem development, familiar with technologies such as Spark, Flink, Clickhouse, Hadoop, and practical experience with Lambda\/Kappa architectures.; Proficient in data warehouse implementation methodologies, with a deep understanding of data warehouse systems, and experience supporting real-world business scenarios.; Experience in SQL performance tuning, with an understanding of Hive SQL development.; Preferred Qualifications:; Candidates with deep experience in real-time data warehouse construction.; Data-sensitive with strong business understanding, excellent logical reasoning skills, and some data analysis capabilities.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85680065","Role":"Senior Solution Architect \/ Solution Architect (Contract)","Company":"Monetary Authority of Singapore (MAS)","Location":"Central Region","Publish_Time":"2025-07-11 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85680065","job_desc":"What the role is; The Monetary Authority of Singapore (MAS) is Singapore\u2019s central bank and integrated financial regulator.; ; As central bank, MAS promotes sustained, non-inflationary economic growth through the conduct of monetary policy and close macroeconomic surveillance and analysis. It manages Singapore\u2019s exchange rate, official foreign reserves, and liquidity in the banking sector.; ; As an integrated financial supervisor, MAS fosters a sound financial services sector through its prudential oversight of all financial institutions in Singapore \u2013 banks, insurers, capital market intermediaries, financial advisors, and stock exchanges. It is also responsible for well-functioning financial markets, sound conduct, and investor education.; ; MAS also works with the financial industry to promote Singapore as a dynamic international financial centre. It facilitates the development of infrastructure, adoption of technology, and upgrading of skills in the financial industry.; ; Join us now, if you have a genuine interest in making an impact to help shape Singapore\u2019s economic and financial landscape.; What you will be working on; You will be part of a dynamic team within Supervision Platforms Division under Information Technology Department. In this role, the officer is expected to undertake the following areas of work:; Application Architecture; Design the system\u2019s application architecture based on requirements.; Manage non-functional requirements like scalability, reliability, and security.; Decompose monolithic applications into microservices.; Design services that can be independently deployed and scaled.; Design scalable UI components and architecture.; Data Architecture; Define Data model strategies (Structured vs semi-structured).; Define Data storage strategies (e.g., relational, NoSQL, GraphQL).; Ensure data consistency, security, and accessibility.; Security Architecture; Define security architecture for application based on system classification.; Design security controls, such as encryption, authentication, and authorization.; Ensure compliance with regulatory standards (e.g., IM8).; Stakeholder management; Work with business teams and product owners to ideate Solution Architecture and Design.; Coordinate and work with other technical teams (e.g. Infrastructure, Enterprise, Applications, Security) to set up infrastructure, CI\/CD pipelines, application integrations and resolve deployment and integration issue.; Engineering and Operations; Design scalable and resilient infrastructure.; Support development teams by providing advice and guiding the engineers in solving technical problems, code review.; Improve software quality using cloud-native and Agile development practices such as TDD, automated CI\/CD.; Work with application teams to understand RCA for issues, incidents, provide interim and long term solution.; Define logging, tracing, and observability practices to quickly identify issues and bottlenecks.; Reusable components; Advocate and build reusable components and libraries to be shared across different application development teams.; Create and govern guidelines for design, coding, database and best practices.; You will be working in a fast-paced environment that would require the ability to manage multiple priorities and needs of stakeholders, as well as the agility to respond to changes and developments.; What we are looking for; Bachelor Degree or Master Degree with minimally 8 years of relevant working experience in application development and design, and business analysis; Strong knowledge of solution architectures and integration patterns; Ability to design and develop large scale applications to solve complex business problems; Proficient in .Net, Java, React.js, Node.js, MYSQL and MongoDB; Familiar with multi-paradigm programming languages; Experience in software development lifecycle in an Agile Scrum context; Experience in OAuth2\/OpenID connect; Experience in containers, microservices and DevSecOps technologies; Familiar with cloud-native technology; Experience in designing and developing applications in AWS cloud environment; Certification on AWS cloud technology is preferred; Good understanding of SRE\/Service\/Security \/Compliance Management process including change, incident, problem on cloud platform; Good analytical skills, and able to multi-task and deliver results in a timely manner; Ability to resolve complex problems creatively; Self-driven, creative and team-oriented person with good interpersonal and organizational skills; As part of the shortlisting process for this role, you may be required to complete a medical declaration and\/or undergo further assessment.; This contract ends in Dec 2029. All applicants will be notified on whether they are shortlisted or not within 4 weeks of the closing date of this job posting.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155082","Role":"Backend Software Engineer - (Data Management Suite)","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155082","job_desc":"Responsibilities; About Tiktok TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo. Why Join Us Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy; a mission we all believe in and aim towards achieving every day.; To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact; for ourselves, our company, and the communities we serve.; Join us. About the Team The Data Management Suite team is building products that cover the whole lifecycle of data pipeline, including data ingestion and Integration, data development, data catalog, data security and data governance.; These products support various businesses, so data engineers and data scientists could greatly boost their productivity. As a software engineer in the data management suite team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on core systems in the data platform ecosystem.; Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users. Responsibilities:; Design and implement a unified data development platform that improves the efficiency of globalization data producers, which includes intelligence IDE, workflow management, multiple engine integration etc.; Figure out efficient ways to manage distributed states, and sync metadata between centralized place and regions globally;; Design and develop a high-performance and distributed scheduling system that manages large-scale tasks across different business lines in whole ByteDance;; Work closely with partner teams across the company and all over the world;; Responsible for the design and development of integration with other systems in the big data area; Qualifications; Minimum Qualifications:; Bachelor's degree in Computer Science or equivalent practical experience; 5+ years of experience in software development, and with data structures\/algorithms; 3+ years of experience with design and architecture, and testing and launching software products; 2+ years of experience in data management systems, have experience of building big data development platforms, data catalog platforms, or data transfer platforms;; Preferred Qualifications:; 5+ years of experience building and developing large-scale infrastructure, distributed systems or networks, and\/or experience with compute technologies, storage, and\/or hardware architecture; 3+ years of experience working in a complex, matrixed organization involving cross-functional, and\/or cross-business projects; Experiences in data platform related product development or big data technologies (such as Hadoop, Clickhouse, Flink etc.); TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"83469272","Role":"Senior integration architect","Company":"NTT Communications","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83469272","job_desc":"enior Integration Architect; Job Overview:; We are seeking a highly experienced Senior integration architect who has expertise in designing, developing, and maintaining enterprise level application interations between ERP, COTS and Custom applications. The ideal candidate will possess a deep understanding of various technologies and frameworks with strong focus on integration solutions (APIs, microservices, cloud platforms, and third-party systems. The developer will work closely with cross-functional teams to deliver enterprise-level applications, provide leadership in solution architecture, and mentor junior developers.; Key Responsibilities:; Lead the architectural design and development of scalable and maintainable web solutions.; Develop and maintain RESTful APIs, microservices, and system integration components.; Collaborate with teams across various departments to define, design, and ship new features, ensuring integration with external systems and services.; Implement robust, efficient, and secure integration solutions across diverse platforms and services (cloud, on-premise).; Work on database design and optimization using SQL Server, NoSQL, or other relevant databases.; Perform code reviews to ensure code quality, maintainability, and adherence to best practices.; Troubleshoot and resolve complex technical issues across front-end and back-end components.; Collaborate in Agile\/Scrum teams, providing technical leadership and mentoring junior developers.; Ensure the highest level of software quality through automated testing frameworks, unit testing, and performance tuning.; Provide ongoing support for web applications, continuously improving performance, security, and scalability.; Required Skills and Qualifications:; 12+ years of hands-on experience in various technologies (.NET, Java 8, Camel, Spring Boot, Spring Framework, Microservices, Rest API, Infor ION); Extensive experience with various technology and frameworks Java, C#, .NET Core, ASP.NET MVC, Web API, Entity Framework.; Strong front-end development skills using modern JavaScript frameworks such as Angular, React, or Vue.js.; Proficiency in HTML5, CSS3, SASS\/LESS, JavaScript (ES6+).; Expertise in integration technologies, including RESTful APIs, SOAP, microservices, and message queues (e.g., RabbitMQ, Kafka).; Experience with Azure, AWS, or Google Cloud Platform for cloud-based application development and deployment.; Proficient in working with databases, including SQL Server, MySQL, PostgreSQL, and NoSQL databases.; Strong knowledge of design patterns, SOLID principles, and best practices in software architecture.; Experience in CI\/CD pipelines (e.g., Jenkins, Azure DevOps, GitHub Actions) and version control systems such as Git.; Ability to develop and maintain unit and integration tests using testing frameworks like NUnit or similar.; Knowledge of containerization technologies (Docker, Kubernetes) and experience deploying to cloud or on-premise environments.; Familiarity with DevOps practices and a collaborative approach to working with operations teams.; Strong problem-solving skills and the ability to troubleshoot complex issues effectively.; Excellent communication skills and the ability to work both independently and in a team environment.; Preferred Qualifications:; Experience with enterprise-level integrations, including ERP, CRM, and financial systems.; Familiarity with OAuth, OpenID Connect, and JWT for securing web services.; Leadership experience in technical project management or mentoring teams; Senior Integration Architect; Job Overview:; We are seeking a highly experienced Senior integration architect who has expertise in designing, developing, and maintaining enterprise level application interations between ERP, COTS and Custom applications. The ideal candidate will possess a deep understanding of various technologies and frameworks with strong focus on integration solutions (APIs, microservices, cloud platforms, and third-party systems. The developer will work closely with cross-functional teams to deliver enterprise-level applications, provide leadership in solution architecture, and mentor junior developers.; Key Responsibilities:; Lead the architectural design and development of scalable and maintainable web solutions.; Develop and maintain RESTful APIs, microservices, and system integration components.; Collaborate with teams across various departments to define, design, and ship new features, ensuring integration with external systems and services.; Implement robust, efficient, and secure integration solutions across diverse platforms and services (cloud, on-premise).; Work on database design and optimization using SQL Server, NoSQL, or other relevant databases.; Perform code reviews to ensure code quality, maintainability, and adherence to best practices.; Troubleshoot and resolve complex technical issues across front-end and back-end components.; Collaborate in Agile\/Scrum teams, providing technical leadership and mentoring junior developers.; Ensure the highest level of software quality through automated testing frameworks, unit testing, and performance tuning.; Provide ongoing support for web applications, continuously improving performance, security, and scalability.; Required Skills and Qualifications:; 12+ years of hands-on experience in various technologies (.NET, Java 8, Camel, Spring Boot, Spring Framework, Microservices, Rest API, Infor ION); Extensive experience with various technology and frameworks Java, C#, .NET Core, ASP.NET MVC, Web API, Entity Framework.; Strong front-end development skills using modern JavaScript frameworks such as Angular, React, or Vue.js.; Proficiency in HTML5, CSS3, SASS\/LESS, JavaScript (ES6+).; Expertise in integration technologies, including RESTful APIs, SOAP, microservices, and message queues (e.g., RabbitMQ, Kafka).; Experience with Azure, AWS, or Google Cloud Platform for cloud-based application development and deployment.; Proficient in working with databases, including SQL Server, MySQL, PostgreSQL, and NoSQL databases.; Strong knowledge of design patterns, SOLID principles, and best practices in software architecture.; Experience in CI\/CD pipelines (e.g., Jenkins, Azure DevOps, GitHub Actions) and version control systems such as Git.; Ability to develop and maintain unit and integration tests using testing frameworks like NUnit or similar.; Knowledge of containerization technologies (Docker, Kubernetes) and experience deploying to cloud or on-premise environments.; Familiarity with DevOps practices and a collaborative approach to working with operations teams.; Strong problem-solving skills and the ability to troubleshoot complex issues effectively.; Excellent communication skills and the ability to work both independently and in a team environment.; Preferred Qualifications:; Experience with enterprise-level integrations, including ERP, CRM, and financial systems.; Familiarity with OAuth, OpenID Connect, and JWT for securing web services.; Leadership experience in technical project management or mentoring teams; #LI-APJ; About NTT DATA; NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com; NTT DATA endeavors to make https:\/\/us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https:\/\/us.nttdata.com\/en\/contact-us. ; This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here. If you'd like more information on your EEO rights under the law, please click here. For Pay Transparency information, please click here.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85786142","Role":"Tencent Cloud Architect (Manager\/Senior Manager), Technology Consulting","Company":"Ernst & Young Solutions LLP","Location":"Singapore","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85786142","job_desc":"Job Description: Tencent Cloud Architect,  AI Data, Technology Consulting; At EY, we develop you with future-focused skills and equip you with world-class experiences. We empower you in a flexible environment, and fuel you and your extraordinary talents in a diverse and inclusive culture of globally connected teams.; We work together across our full spectrum of services and skills powered by technology and AI, so that business, people and the planet can thrive together. ; We\u2019re all in, are you?; Join EY and shape your future with confidence.; About the opportunity; EY AI & Data is the data and advanced analytics capability within EY Asia-Pacific, with over 500 specialist employees working across multiple industry sectors. We implement information-driven strategies, data platforms and advanced data analytics solution systems that help grow, optimize and protect client organizations. We go beyond strategy and provide end to end design, build and implementation of real-life data environments and have some of the best architects, project managers, business analysts, data scientists, big data engineers, developers and consultants in the region. ; We are looking for an experienced Tencent Cloud Architect at the Manager\/Senior Manager level to join our Technology Consulting practice. The ideal candidate will bring deep technical expertise in Tencent Cloud architecture, with proven experience in delivering cloud transformation and digital innovation projects for enterprise clients. As a leader in the team, you will help shape strategy, manage delivery, and guide clients through their cloud adoption journeys.; Your key responsibilities:; Lead end-to-end architecture design and implementation of solutions on Tencent Cloud for large-scale enterprise and public sector clients.; Translate client business requirements into scalable, secure, and cost-effective cloud solutions.; Drive client workshops, technical assessments, and solution presentations.; Provide architectural guidance and governance across all project phases (discovery, design, delivery, and operations).; Design cloud-native architectures including microservices, containers (Kubernetes), serverless, and hybrid cloud models.; Develop cloud migration strategies (lift-and-shift, re-platforming, re-architecting).; Ensure alignment with best practices for cloud security, performance, and compliance.; Stay abreast of Tencent Cloud\u2019s evolving services and capabilities; identify how these can benefit client use cases; Manage cross-functional project teams across multiple geographies and time zones.; Oversee project timelines, deliverables, and resource planning; Engage senior stakeholders and act as the technical point of contact for cloud-related engagements.; Provide mentorship and technical leadership to junior architects and engineers.; Support business development by contributing to proposals, RFPs, and solution demonstrations.; Build and expand strategic partnerships with Tencent Cloud and related ecosystem vendors.; Drive internal capability development, knowledge sharing, and thought leadership in cloud computing and digital transformation.; Skills & attributes for success:; Bachelor\u2019s degree in Computer Science, Engineering, or related field; Master\u2019s preferred.; 8\u201312 years of experience in IT consulting or enterprise architecture roles.; At least 3\u20135 years of hands-on architecture experience with Tencent Cloud, including services like CVM, COS, TKE, SCF, and VPC.; Tencent Cloud certification (e.g., Tencent Cloud Solutions Architect) or equivalent is a strong advantage.; Experience with other cloud platforms (e.g., AWS, Azure, GCP) for multi-cloud or migration scenarios.; Familiarity with DevSecOps, CI\/CD pipelines, and Infrastructure as Code (Terraform, Ansible).; Deep understanding of cloud governance, cost optimization, and security frameworks.; Consulting or client-facing experience in government, finance, or telecom industries in Asia, especially China\/Southeast Asia.; To qualify for the role, you must have; Experience working with Singapore public sector clients.; Strong communication and stakeholder engagement skills.; What we look for; Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you\u2019ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.; What working at EY offers; EY offers a competitive remuneration package where you\u2019ll be rewarded for your individual and team performance. We are committed to being an inclusive employer and are happy to consider flexible working arrangements. Plus, we offer:; Continuous learning: You\u2019ll develop the mindset and skills to navigate whatever comes next.; Success as defined by you: We\u2019ll provide the tools and flexibility, so you can make a meaningful impact, your way.; Transformative leadership: We\u2019ll give you the insights, coaching and confidence to be the leader the world needs.; Diverse and inclusive culture: You\u2019ll be embraced for who you are and empowered to use your voice to help others find theirs.; Company description; EY is building a better working world by creating new value for clients, people, society and the planet, while building trust in capital markets.; Enabled by data, AI and advanced technology, EY teams help clients shape the future with confidence and develop answers for the most pressing issues of today and tomorrow.; EY teams work across a full spectrum of services in assurance, consulting, tax, strategy and transactions. Fueled by sector insights, a globally connected, multi-disciplinary network and diverse ecosystem partners, EY teams can provide services in more than 150 countries and territories.; All in to shape the future with confidence.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84484732","Role":"Machine Learning Engineer (Data Mining) - Global E-Commerce","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84484732","job_desc":"Responsibilities; About The Team The e-commerce industry has seen tremendous growth in recent years and has become a hotly contested space amongst leading Internet companies, and its future growth cannot be underestimated.; With millions of loyal users globally, we believe TikTok is an ideal platform to deliver a brand new and better e-commerce experience to our users. Our product engineering team is responsible for building an e-commerce ecosystem that is innovative, secure and intuitive for our users. We are looking for passionate and talented people to join us as we drive the future of e-commerce here at TikTok.; Responsibilities; Responsible for development of data-empowered capabilities for e-commerce platform, enable different e-commerce verticals to extract and apply key insights from oceans of data to meet their business needs.; Data mining for e-commerce, building tagging system based on massive data, analysing user, traffic, e-commerce and other data, combining with business to improve GMV.; Data analysis, mining, model specific productization; understanding of e-commerce business, able to work with PM to continuously optimize data products based on data-driven.; Develop data mining pipelines to extract data assets (eg. entity labels) from aggregated data and enable the extraction of actionable insights from large volumes of domain data.; Design and development of various strategies, algorithms and machine learning techniques to improve the accuracy and coverage of extracted data assets.; Analyze e-commerce data-related business problems and abstract them into data-related requirements that are then implemented to help resolve key business problems.; Qualifications; Minimum Qualifications; B. Sc or higher degree in Computer Science or related fields from accredited and reputable institutions.; 5 years experience in data structures and algorithms, familiar with one or more: machine learning, natural language processing, data mining.; Familiar with one of the Python\/Java\/Go\/C++ programming languages.; Familiar with common data processing technologies (Hadoop, Spark, Hive, Storm, Flink), with demonstrable coding skills.; Familiar with common data mining techniques and machine learning algorithms (GBDT, Xgboost, FM, DFM, etc.), and familiar with their principles and scope of application.; Proficiency in data mining, machine learning tools and common frameworks (TensorFlow, Pytorch).; Preferred Qualifications; Continuous learning, keeping up with the latest research directions and results in the field of machine learning, for the exploration of big data applications in various vertical areas.; In-depth research experience in analysis and mining of user behaviour data and construction of user portraits.; Data mining experience in vertical industries (e-commerce, finance, games, travel, real estate, etc.).; Development and optimisation of advertising and recommendation algorithms.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84571807","Role":"Staff Software Engineer, Developer Experience","Company":"Airwallex","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84571807","job_desc":"About Airwallex; Airwallex is the only unified payments and financial platform for global businesses. Powered by our unique combination of proprietary infrastructure and software, we empower over 150,000 businesses worldwide \u2013 including Brex, Rippling, Navan, Qantas, SHEIN and many more \u2013 with fully integrated solutions to manage everything from business accounts, payments, spend management and treasury, to embedded finance at a global scale.; Proudly founded in Melbourne, we have a team of over 1,700 of the brightest and most innovative people in tech across 26 offices around the globe. Valued at US$6.2 billion and backed by world-leading investors including Visa, Airtree, Blackbird, Sequoia, DST Global, Greenoaks, Salesforce Ventures, Lone Pine, and Square Peg, Airwallex is leading the charge in building the global payments and financial platform of the future. If you\u2019re ready to do the most ambitious work of your career, join us.; About the team; The Developer Experience (DevX) team oversees our customer\u2019s developer journey from discovery to building at scale. We aim to provide an onboarding experience so intuitive and well-organized that developers can discover product details, learn implementation specifics, and develop independently. During build and scale, our customers have developer affordances that are comprehensive, ergonomic and delightful.; We achieve this by providing structured channels to collect feedback and use data analytics informing us on how we can provide the best experience.; What you\u2019ll do; Responsibilities:; Lead and develop next-in-class user and data analytics pipeline.; Ensure our APIs meet the highest standards and conventions.; Build world-class developer portal and docs with AI as a core feature.; Contribute to open source and fostering a developer community; Incorporate the latest technologies and up-leveling our tech stack.; Develop external tools and services that get released to our customers.; Collaborate with product, engineering, customer-success, and technical support teams to refine & streamline the developer experience for our customers; Who you are; We\u2019re looking for people who meet the minimum qualifications for this role. The preferred qualifications are great to have, but are not mandatory.; Minimum qualifications:; 10+ years of software engineering experience, with a focus on API development.; Bachelor degree or above in computer science or engineering related majors.; Strong communication and collaboration skills.; Solid understanding of RESTful API design principles and patterns.; Experience with backend technologies is essential. While we do not mind what language you have most recently been using we are using Java or Kotlin, Spring \/ Spring Boot.; Experience developing and maintaining automated tests and quality control processes.; Evidence of working on high volume distributed systems.; Strong cloud experience GCP (preferred) or AWS (EC2, RDS, ELB, CloudFront etc) with docker and Kubernetes.; Experience integrating with observability tooling such as Splunk, NewRelic, Prometheus, Grafana.; Preferred qualifications:; Released and maintained well-known APIs or have API design experience.; Basic experience with frontend technologies such as React and Angular are preferred.; Some experience working within a financial domain is a highly desirable.; Worked in developer experience or other customer-facing engineering roles.; Equal opportunity; Airwallex is proud to be an equal opportunity employer. We value diversity and anyone seeking employment at Airwallex is considered based on merit, qualifications, competence and talent. We don\u2019t regard color, religion, race, national origin, sexual orientation, ancestry, citizenship, sex, marital or family status, disability, gender, or any other legally protected status when making our hiring decisions. If you have a disability or special need that requires accommodation, please let us know.; Airwallex does not accept unsolicited resumes from search firms\/recruiters.  Airwallex will not pay any fees to search firms\/recruiters if a candidate is submitted by a search firm\/recruiter unless an agreement has been entered into with respect to specific open position(s).  Search firms\/recruiters submitting resumes to Airwallex on an unsolicited basis shall be deemed to accept this condition, regardless of any other provision to the contrary.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85627283","Role":"Solution Architect, AI \/ Cloudflare Developer Platform","Company":"Area 1 Security","Location":"Singapore","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85627283","job_desc":"Available Location: Singapore; As a Solution Architect,  AI \/ Cloudflare Developer Platform and a member of the sales team you will help customers understand the technical details and business value proposition of the Cloudflare AI \/ Developer Platform and demonstrate the path and advantages of building applications with our products. ; In this role, you will serve as the Regional Lead for Cloudflare AI \/ Developer Platform sales. You will advise sales leadership on programs to grow Developer revenue and support strategic opportunities. You will collaborate closely with technical sales teams to design innovative solutions, develop proof of concept demonstrations, and showcase the technical capabilities of these designs to meet customer needs and expectations.; Serving as a trusted technical advisor you will help guide and enable clients, partners and teams within Cloudflare on product capabilities, positioning and competitive intelligence. You will form a tight feedback loop with product, product marketing, and technical pre-sales to refine and evolve our product. ; The ideal candidate possesses a consultative mindset, strong selling skills, along with a deep understanding of modern Web Technologies, Cloud Architecture , and the advantages of a Distributed Serverless Platform. No matter your background, you have natural curiosity and desire to solve problems, achieve goals, and design the most elegant and efficient solutions to address client needs.; Responsibilities; You will partner with the sales organization to drive revenue, new customers and pipeline of AI and Developer Platform solutions. ; Collaborate with cross-functional teams including product management, sales, and marketing to drive developer platform revenue and customer adoption; Present to strategic customers as an expert of our Developer platform solutions; Develop programs to drive the overall sales and pipeline strategy for the Cloudflare Developer Platform in partnership with regional and country sales leaders; Align Director and C-Level perceived business and technical value with Cloudflare developer solutions; Prepare and give regular business reviews to the management team highlighting attainment progress and challenges to closing business; Generate a succinct feedback loop with cross-functional teams to deliver relevant Developer content, use cases, customer stories, and data driven value propositions.; In order to be successful, you will need to become a thought leader, trusted advisor, and spokesperson for the Cloudflare AI and Developer platform.; Skill Requirements; 3+ years of experience selling or supporting the technical sales of cloud computing and storage, full-stack Engineering, or Cloud Developer; Technical expertise in cloud infrastructure, web technologies and AI\/MLas a solutions engineer, entrepreneur, or solution architect.; Knowledge and experience of Systems Design; You\u2019ve built a web application, either professionally or as a hobbyist, and will be able to explain your design choices clearly during the interview process; Able to hear a clear, non-technical description of an Application (\u201cIt is a chat room, for our 150 most important users\u201d) and quickly determine which Compute, Data, and Security components are needed to build this application; Software development experience delivering full-stack applications, preferably using modern JavaScript frameworks and a variety of databases; In-depth knowledge of at least one major public cloud provider (AWS, GCP, Azure, etc.); Have a good understanding of systems design theory and practice for distributed, full-stack applications (frontend, backend, databases, related services); ideally in a serverless paradigm; Have a strong understanding of developer workflows (branching, release, versioning, CI\/CD practices, system integrations); Act as an AI and Developer product expert, educating internal teams and external stakeholders on the value and capabilities of the Cloudflare Developer platform; Knowledge of key market players\/competitors in the cloud computing, AI and storage spaces; 30% travel; Other desirable skills areas include:; You\u2019ve built something on Cloudflare Workers; AWS Solutions Architect or GCP Cloud Architect certifications; Prioritize and manage the product roadmap, making strategic trade-offs to ensure the product meets customer needs and business goals; Participate in product launch activities, including developing messaging and positioning, coordinating with marketing and sales teams; Stay up-to-date with industry trends and advancements in cloud computing to inform product strategy and roadmap; What Makes Cloudflare Special?; We\u2019re not just a highly ambitious, large-scale technology company. We\u2019re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.; Project Galileo: Since 2014, we've equipped more than 2,400 journalism and civil society organizations in 111 countries with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare\u2019s enterprise customers--at no cost.; Athenian Project: In 2017, we created the Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration. Since the project, we've provided services to more than 425 local government election websites in 33 states.; 1.1.1.1: We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here\u2019s the deal - we don\u2019t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.; Sound like something you\u2019d like to be a part of? We\u2019d love to hear from you!; This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.; Cloudflare is proud to be an equal opportunity employer.  We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness.  All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA\/Veterans\/Disabled Employer.; Cloudflare provides reasonable accommodations to qualified individuals with disabilities.  Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.  If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"83696114","Role":"Manager Data Platform Engineering Lead","Company":"National Healthcare Group Corporate Office (HQ)","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83696114","job_desc":"Data Platform Engineering Lead; Technical Leadership & Architecture; Lead and oversee technical direction across data engineering, backend, frontend, MLOps domains; Provide oversight of DevOps practices and infrastructure management; Review and approve system architecture, design patterns, and technical decisions; Establish coding standards, best practices, and technical documentation requirements; Evaluate and recommend new technologies and tools to improve development efficiency; Team & Project Management; Lead sprint planning, backlog grooming, and agile ceremonies; Manage resource allocation and project prioritisation across multiple workstreams; Coordinate with stakeholders to gather and refine requirements; Serve as primary technical point of contact for clinicians and business users; Ensure project deliverables and milestones are met on schedule; Engineering Operations; Oversee code review processes across all engineering domains; Review and approve production deployments and changes; Ensure robust testing practices including unit, integration, and end-to-end testing; Manage application monitoring and maintain service level agreements (SLAs); Lead incident response and troubleshooting for critical issues; Infrastructure & DevOps Oversight; Review and approve CI\/CD pipeline designs and automation strategies; Oversee infrastructure architecture decisions and cloud resource planning; Guide security and compliance implementation in infrastructure; Review disaster recovery and backup strategies; Ensure proper monitoring and alerting systems are in place; Validate environment configuration management practices; Data & ML Operations; Guide data pipeline architecture and implementation; Oversee ML model development, deployment, and monitoring; Ensure data quality, security, and compliance standards are met; Direct the implementation of MLOps practices and tools; Team Development; Mentor and guide technical growth of team members across all domains; Conduct technical interviews and participate in hiring decisions; Plan and oversee onboarding of new team members; Identify training needs and facilitate knowledge sharing; Process & Documentation; Maintain technical documentation and system architecture diagrams; Establish and refine development workflows and processes; Oversee JIRA ticket management and workflow; Ensure proper documentation of incidents, changes, and solutions; Review and approve operational runbooks","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85549468","Role":"Data Scientist Project Intern (Trust and Safety-Monetization Integrity-Data...","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-07-07 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85549468","job_desc":"Responsibilities; About the Team The success of TikTok's data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. The Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management. We are looking for a motivated Data Science Intern to join our Data Acquisition function. As an intern, you will take ownership of a high-impact, scoped project designed to improve operational efficiency in TikTok's data labeling workflows. This internship offers exposure to real-world applications of data science in large-scale operational systems and a chance to work with a cross-functional team of data scientists, engineers, and business stakeholders. Applications will be reviewed on a rolling basis - we encourage you to apply early. Successful candidates must be able to commit to at least 3 months long internship period. Successful candidates must be able to commit to the following internship cycles below: - Off Cycle \/ Credit Bearing Internship - Starting from Aug 2025 (latest) We will prioritize candidates who are able to commit to the above internship period. Please state your availability clearly in your resume (Start date, End date). Responsibilities 1. Algorithm Development & Optimization: Design and implement matching algorithms and probabilistic models for task allocation and confidence scoring, focusing on multi-objective optimization that balances quality, cost, and efficiency constraints. 2. Feature Engineering & Data Pipeline Development: Extract meaningful signals from labeler performance data, task characteristics, and system logs to build robust features that power allocation decisions and confidence assessments. 3. Experimentation & Model Validation: Design and execute A\/B tests, simulations, and validation experiments to measure algorithm performance, iterate on model improvements, and ensure real-world effectiveness. 4. Data Analysis & Insights Generation: Conduct exploratory analysis on platform data to identify patterns, build predictive models for operational forecasting, and generate actionable insights for product and business decisions. 5. Cross-functional Collaboration: Present findings and recommendations to engineering, product, and business teams, contributing to implementation planning and strategic decision-making processes. Qualifications; Minimum Qualifications: 1. Penultimate or final year pursuing a Bachelor's or Master's degree in Computer Science, Data Science, Operations Research, Statistics, or a related field. 2. Proficiency in Python and core data science libraries (pandas, numpy, scikit-learn), with experience in machine learning algorithms, optimization techniques, statistical modeling, and SQL for data extraction. 3. Strong analytical and problem-solving abilities with experience breaking down complex optimization problems Preferred Qualifications: 1. Excellent communication skills for presenting technical findings to diverse stakeholders 2. Self-motivated with ability to manage multiple projects in a collaborative, fast-paced environment By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https:\/\/careers.tiktok.com\/legal\/privacy. If you have any questions, please reach out to us at apac-earlycareers@tiktok.com","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155218","Role":"Data Engineer intern - User Growth- 2025 Start","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155218","job_desc":"Responsibilities; The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth. Typical Growth projects including creative generating, attribution, ads bot, etc. As a project intern, you will have the opportunity to engage in impactful short-term projects that provide you with a glimpse of professional real-world experience. You will gain practical skills through on-the-job learning in a fast-paced work environment and develop a deeper understanding of your career interests. Responsibilities: - Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; - Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for \u201cPackaged Business Capability\u201d such as user-growth, gaming and searching; - Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications; Minimum Qualifications -Undergraduate or Postgraduate currently pursuing a Degree\/Master in Software Development, Computer Science, Computer Engineering, or a related technical discipline Preferred Qualifications - Developers with strong self-drive and sense of responsibility, with internship experience in back-end development, and who have participated in complete projects will be given priority; By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https:\/\/careers.tiktok.com\/legal\/privacy. If you have any questions, please reach out to us at apac-earlycareers@tiktok.com","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85452525","Role":"Senior Engineer, Smart City Platform","Company":"ST Engineering Urban Solutions","Location":"Jurong East","Publish_Time":"2025-07-04 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85452525","job_desc":"ST Engineering is a global technology, defence and engineering group with a diverse portfolio of businesses across the aerospace, smart city, defence and public security segments. The Group harnesses technology and innovation to solve real-world problems, enabling a more secure and sustainable world. Headquartered in Singapore, we employ about 25,000 people across our network of subsidiaries and associated companies in Asia, Europe, the Middle East and the U.S., serving customers in more than 100 countries. We rank among the largest companies listed on the Singapore Exchange and are a component stock of the FTSE Straits Times Index, Dow Jones Sustainability Asia Pacific Index, iEdge SG ESG Transparency Index and iEdge SG ESG Leaders Index.;  Introduction to URS Business Area; We prepare cities for a smarter future, creating connected, resilient and sustainable cities. We have helped to make cities around the world a better place to live in, delivering urban efficiencies while keeping them safe and secure.; Our technologies address the connectivity, mobility, security, infrastructure and environmental needs of cities and provide IoT solutions for lighting, water and waste management.; Backed by a track record of 700 smart city projects in over 130 cities worldwide, we are well-equipped to help global cities address challenges from road congestion to physical and cybersecurity threats, as well as energy inefficiency and utility wastage.; Find out more: https:\/\/www.stengg.com\/urban-solutions; Job Description Summary;  We\u2019re looking for a Senior Engineer with a sharp and flexible mind, excellent technical skills, and strong leadership qualities. You\u2019ll drive both product innovation and technical project delivery across scalable, secure, and high-performance systems.; Key Job Accountabilities; Lead end-to-end design, development, customization, and deployment of smart city modules.; Oversee both front-end and back-end development using modern tech stacks.; Guide and manage local and offshore development teams, including code reviews and technical mentoring.; Collaborate with architects, BAs, QA, UI\/UX, DevOps, and security teams to deliver robust solutions.; Ensure scalable, secure applications with proper documentation and testing.; Provide short- to mid-term support for overseas deployments as required.; May be deployed for short (less than a week) or mid-term (less than 3 months) overseas projects.; Required Tech Stack & Tools; Languages & Frameworks: NodeJS, Java\/C#\/C++, JavaScript, HTML, CSS, AngularJS, ReactJS; Databases: MSSQL, PostgreSQL, Oracle, MongoDB, GAIA; Cloud & DevOps: Docker, Kubernetes, CI\/CD pipelines, AWS\/GCP\/Azure; Middleware & Protocols: Kafka, RabbitMQ, REST APIs, Keycloak, HTTP\/FTP; Architecture: Microservices, SOA, Event-driven systems; Testing & QA: Selenium, Postman, JMeter, Jest; Bonus: GIS (GeoServer, ArcGIS), AI\/ML, 3D modeling, Data & Video Analytics, Security tools (VAPT, code scanning);  Required Qualifications & Experience; 4+ years in full-stack development; 2+ years as Technical Lead; Strong leadership, problem-solving, and communication skills; Fluent in English and Mandarin (Vietnamese\/Arabic is a plus) to effectively communicate with Mandarin, Vietnamese, Arabic-speaking clients.; Able to work independently in a fast-paced, collaborative environment; Excellent problem-solving skills and attention to details.;  Reporting Relationship; The incumbent reports to Technical Director, Digital Platform;  Work Location; ST Engineering Ltd, 100 Jurong East Street 21, Singapore 609602","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85696908","Role":"Architect \/ developer","Company":"Cloudflare","Location":"Singapore","Publish_Time":"2025-07-12 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85696908","job_desc":"About UsAt Cloudflare, we are on a mission to help build a better Internet. Today the company runs one of the world\u2019s largest networks that powers millions of websites and other Internet properties for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine\u2019s Top Company Cultures list and ranked among the World\u2019s Most Innovative Companies by Fast Company.; We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!; Available Location: Singapore; As a Solution Architect, AI \/ Cloudflare Developer Platform and a member of the sales team you will help customers understand the technical details and business value proposition of the Cloudflare AI \/ Developer Platform and demonstrate the path and advantages of building applications with our products.; In this role, you will serve as the Regional Lead for Cloudflare AI \/ Developer Platform sales. You will advise sales leadership on programs to grow Developer revenue and support strategic opportunities. You will collaborate closely with technical sales teams to design innovative solutions, develop proof of concept demonstrations, and showcase the technical capabilities of these designs to meet customer needs and expectations.; Serving as a trusted technical advisor you will help guide and enable clients, partners and teams within Cloudflare on product capabilities, positioning and competitive intelligence. You will form a tight feedback loop with product, product marketing, and technical pre-sales to refine and evolve our product.; The ideal candidate possesses a consultative mindset, strong selling skills, along with a deep understanding of modern Web Technologies, Cloud Architecture , and the advantages of a Distributed Serverless Platform. No matter your background, you have natural curiosity and desire to solve problems, achieve goals, and design the most elegant and efficient solutions to address client needs.; Responsibilities; You will partner with the sales organization to drive revenue, new customers and pipeline of AI and Developer Platform solutions.; Collaborate with cross-functional teams including product management, sales, and marketing to drive developer platform revenue and customer adoption; Present to strategic customers as an expert of our Developer platform solutions; Develop programs to drive the overall sales and pipeline strategy for the Cloudflare Developer Platform in partnership with regional and country sales leaders; Align Director and C-Level perceived business and technical value with Cloudflare developer solutions; Prepare and give regular business reviews to the management team highlighting attainment progress and challenges to closing business; Generate a succinct feedback loop with cross-functional teams to deliver relevant Developer content, use cases, customer stories, and data driven value propositions.; In order to be successful, you will need to become a thought leader, trusted advisor, and spokesperson for the Cloudflare AI and Developer platform.; Skill Requirements; 3+ years of experience selling or supporting the technical sales of cloud computing and storage, full-stack Engineering, or Cloud Developer; Technical expertise in cloud infrastructure, web technologies and AI\/MLas a solutions engineer, entrepreneur, or solution architect.; Knowledge and experience of Systems Design; You\u2019ve built a web application, either professionally or as a hobbyist, and will be able to explain your design choices clearly during the interview process; Able to hear a clear, non-technical description of an Application (\u201cIt is a chat room, for our 150 most important users\u201d) and quickly determine which Compute, Data, and Security components are needed to build this application; Software development experience delivering full-stack applications, preferably using modern JavaScript frameworks and a variety of databases; In-depth knowledge of at least one major public cloud provider (AWS, GCP, Azure, etc.); Have a good understanding of systems design theory and practice for distributed, full-stack applications (frontend, backend, databases, related services); ideally in a serverless paradigm; Have a strong understanding of developer workflows (branching, release, versioning, CI\/CD practices, system integrations); Act as an AI and Developer product expert, educating internal teams and external stakeholders on the value and capabilities of the Cloudflare Developer platform; Knowledge of key market players\/competitors in the cloud computing, AI and storage spaces; 30% travel; Other desirable skills areas include:; You\u2019ve built something on Cloudflare Workers; AWS Solutions Architect or GCP Cloud Architect certifications; Prioritize and manage the product roadmap, making strategic trade-offs to ensure the product meets customer needs and business goals; Participate in product launch activities, including developing messaging and positioning, coordinating with marketing and sales teams; Stay up-to-date with industry trends and advancements in cloud computing to inform product strategy and roadmap; What Makes Cloudflare Special?We\u2019re not just a highly ambitious, large-scale technology company. We\u2019re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.; Project Galileo: Since 2014, we've equipped more than 2,400 journalism and civil society organizations in 111 countries with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare\u2019s enterprise customers--at no cost.; Athenian Project: In 2017, we created the Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration. Since the project, we've provided services to more than 425 local government election websites in 33 states.; 1.1.1.1: We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here\u2019s the deal - we don\u2019t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.; Sound like something you\u2019d like to be a part of? We\u2019d love to hear from you!; This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.; Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA\/Veterans\/Disabled Employer.; Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85225192","Role":"DevOps Engineer - Cloud Platforms (AWS)","Company":"ScienTec Consulting Pte Ltd","Location":"Downtown Tanjong Pagar","Publish_Time":"2025-06-27 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85225192","job_desc":"Spearhead digital transformation by building and maintaining modern cloud platforms using Infrastructure as Code (IaC). Join a passionate team working on impactful cloud migration and CI\/CD projects across hybrid environments.; Competitive salary up to $7,500\/month + AWS + Performance Bonus; Central office location with 5-day work week; Exposure to hybrid cloud infrastructure & cutting-edge automation tools; Collaborative, Agile environment with passionate colleagues; Key Responsibilities:; Develop and maintain CI\/CD pipelines and automated testing using Jenkins Pipeline\/Library.; Write scripts for system monitoring and health checks.; Automate scalable cloud infrastructure with Kubernetes, Terraform, and GitOps.; Implement security hardening across testing, deployment, and production environments.; Provide technical insights on solution design and implementation.; Foster a DevOps culture by collaborating with Development and Operations teams.; Drive continuous enhancements to the release and deployment process.; Requirements:; Degree in Computer Science, IT, or related discipline; Passion for automation, standardization, and best practices; Experience deploying and securing cloud apps, especially AWS; Hands-on skills with Terraform, Jenkins, Jira, Confluence, Bitbucket, Bamboo, Docker, Ansible, Puppet, CloudStack, vSphere, OpenStack, etc.; Agile environment experience and strong Linux OS knowledge; Familiar with Java technologies; Be a driving force in cloud innovation and automation. Submit your updated resume today!; By submitting your resume, you consent to the collection, use, and disclosure of your personal information per ScienTec\u2019s Privacy Policy (scientecconsulting.com\/privacy-policy).; ; This authorizes us to:; Contact you about potential opportunities.; Delete personal data as it is not required at this application stage.  ; ; All applications will be processed with strict confidence. Only shortlisted candidates will be contacted.; ; Ng Kee Hung (Vickus) - R2091423; ScienTec Consulting Pte Ltd - 11C5781","salary":"SGD 5500 - 7500 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85235321","Role":"DevOps Engineer (AWS \/ Kubernetes \/ Docker \/ IAC)","Company":"ScienTec Consulting Pte Ltd","Location":"Central Region","Publish_Time":"2025-06-27 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85235321","job_desc":"We\u2019re seeking a skilled DevOps Engineer to join our growing tech team. You will play a critical role in automating infrastructure, ensuring scalable deployments, and improving the overall developer experience.; Working Hours: Mon-Fri; Working Location: Central; Salary up to $7500 (basic) + bonus; \ud83d\udd27 Responsibilities:; Design, implement, and manage CI\/CD pipelines and automated infrastructure using Terraform or CloudFormation; Maintain and optimize containerized environments with Docker and Kubernetes; Manage and scale cloud infrastructure on AWS; Collaborate with development teams to enhance system reliability, security, and performance; Monitor, troubleshoot, and support production systems and environments; \ud83e\udde0 Requirements:; Strong hands-on experience with AWS services (EC2, ECS\/EKS, S3, IAM, etc.); Proficient in Docker and Kubernetes (deployment, scaling, and orchestration); Experience with IaC tools like Terraform, CloudFormation, or Pulumi; Knowledge of CI\/CD tools (e.g., Jenkins, GitLab CI, GitHub Actions); Scripting skills (e.g., Bash, Python); \ud83d\udca1 Nice to Have:; Experience with observability tools (e.g., Prometheus, Grafana, ELK stack); Familiarity with security best practices in cloud environments; Certification (e.g., AWS DevOps Engineer, CKA); By submitting your resume, you consent to the collection, use, and disclosure of your personal information per ScienTec\u2019s Privacy Policy (scientecconsulting.com\/privacy-policy).   This authorizes us to:; Contact you about potential opportunities.; Delete personal data as it is not required at this application stage.; All applications will be processed with strict confidence. Only shortlisted candidates will be contacted.  ; ; Elane Yap Theng Yu- R1989397; ScienTec Consulting Pte Ltd - 11C5781","salary":"SGD 5500 - 7500 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85488968","Role":"System Engineer (AWS)","Company":"Talent Trader Group Pte Ltd","Location":"Bendemeer","Publish_Time":"2025-07-05 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85488968","job_desc":"Responsibilities:; Design, deploy, and configure scalable and highly available AWS infrastructure including EC2, VPC, IAM, S3, and other core AWS services; Automate infrastructure provisioning and configuration using tools like CloudFormation, Terraform, and AWS CLI; Monitor and maintain the health and performance of AWS resources, troubleshooting issues and implementing proactive measures to ensure system reliability; Collaborate with development teams to integrate cloud infrastructure with application code and ensure seamless deployments; Implement security best practices to protect AWS environments, including identity and access management, network security, and data encryption; Document infrastructure architecture, processes, and procedures to support knowledge sharing and continuity; Stay up-to-date with the latest AWS services, features, and best practices, and make recommendations to continually optimise the cloud environment; Requirements:; Minimum 2 years of hands-on experience as a System Engineer or DevOps Engineer, with a strong focus on AWS cloud technologies; Proficiency in designing, deploying, and managing highly scalable and secure AWS infrastructure using services like EC2, VPC, IAM, S3, and CloudFormation; Excellent understanding of cloud architecture patterns, networking, security, and best practices; Familiarity with infrastructure as code tools like Terraform and CloudFormation, and experience with automation and CI\/CD pipelines; Strong troubleshooting and problem-solving skills, with the ability to quickly identify and resolve issues in a dynamic cloud environment; Excellent communication and collaboration skills to work effectively with cross-functional teams; Familiarity with containerisation technologies like Docker and Kubernetes is a plus; Interested candidates who wish to apply for the advertised position, please email us an updated copy of your resume.; Email Address: it@talenttradersg.com;  EA License No.: 13C6305; Reg No: R1770654 (HIEW CHAI SYIN);  For candidate who applied for the advertised position is deemed to have consented to us that we may collect, use or disclose your personal information for purpose in connection with the services provided by us.","salary":"$5,000 \u2013 $6,500 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85041168","Role":"Senior AI Software Engineer - AI Integration","Company":"Razer Inc.","Location":"Singapore","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85041168","job_desc":"Joining Razer will place you on a global mission to revolutionize the way the world games. Razer is a place to do great work, offering you the opportunity to make an impact globally while working across a global team located across 5 continents. Razer is also a great place to work, providing you the unique, gamer-centric #LifeAtRazer experience that will put you in an accelerated growth, both personally and professionally.; Job Responsibilities :; We are seeking a highly skilled AI Software Engineer to design, develop, and deploy AI-powered solutions. This role involves building scalable AI systems, integrating AI \/ Machine Learning (ML) models into applications, and optimizing AI workflows for production. You will collaborate closely with data scientists, software engineers, and DevOps teams to bring cutting-edge AI capabilities to life.; Implement and optimize AI \/ ML models in production, via containerization (Docker, Kubernetes), for speed, accuracy and cost-effectiveness; Deploy AI models using RESTful APIs, gRPC, or edge computing solutions.; Implement monitoring, logging, and error-handling mechanisms to track AI performance.; Design APIs and microservices to integrate AI capabilities into software systems to ensure that they are secure, performant and well-documented; Monitor and optimize model performance in production environments, ensuring API latency and availability meet the required SLAs (Service Level Agreements).; Build scalable, high-performance AI pipelines for real-time and batch processing.; Implement MLOps best practices, including CI\/CD for machine learning workflows on both local machines and cloud platforms; Work closely with data scientists to turn research models into deployable solutions.; Collaborate with DevOps and cloud engineers to ensure seamless AI model deployment.; Stay up to date with the latest AI\/ML frameworks, tools, and industry trends in API, plugins development to continuously improve and enhance API solutions.; Identify opportunities to improve existing AI API \/ plugins architectures and suggest new features or services to add value to AI products.; Pre-Requisites :; 3+ years of experience in AI\/ML software development.; Proven track record of deploying AI solutions in production environments.; Strong experience in deploying AI models and API development using RESTful APIs, gRPC, or edge computing solutions.; Strong programming skills in Python, Java, or C++.; Hands-on experience with AI\/ML frameworks (TensorFlow, PyTorch, Scikit-learn).; In depth understanding of containerization (Docker, Kubernetes) and DevOps practices.; Experience in developing and deploying AI applications running both edge deployment (TensorRT, ONNX, TFLite) and on cloud infrastructure (AWS, Azure or Google Cloud Platform) using Infrastructure as code tools such as Terraform and also cloud AI services (AWS SageMaker, Google Vertex AI, Azure ML).; Experience with database management (SQL, NoSQL, and vector databases).; Knowledge of distributed computing (Spark, Dask) and parallel processing.; Ability and willingness to learn any new technologies and apply them at work in order to stay ahead, in a fast paced, high pressure, agile environment; Excellent written and verbal communication skills for coordinating across teams.; Education & Experience; Has a Bachelor\u2019s or Master\u2019s degree in computer science, AI or similar discipline from an accredited institution; Are you game?","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85608182","Role":"Backend Engineer Intern, Data Infra - Platform (Aug - Dec 2025)","Company":"SHOPEE SINGAPORE PRIVATE LIMITED","Location":"Singapore","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85608182","job_desc":"The Engineering and Technology team is at the core of the Shopee platform development. The team is made up of a group of passionate engineers from all over the world, striving to build the best systems with the most suitable technologies. Our engineers do not merely solve problems at hand; We build foundations for a long-lasting future. We don't limit ourselves on what we can or can't do; we take matters into our own hands even if it means drilling down to the bottom layer of the computing platform. Shopee's hyper-growing business scale has transformed most \"innocent\" problems into huge technical challenges, and there is no better place to experience it first-hand if you love technologies as much as we do.; About the Team:; Shopee will be prioritizing applicants who have a current right to work in Singapore, and do not require Shopee sponsorship of a visa.; Kindly note that you can only be considered in one recruitment process at a time within Sea Group and will be considered for jobs in the order that you have applied.; Our team builds and maintains the company\u2019s big data infrastructure and platforms, ensuring they are stable, efficient, secure, and easy to use. We provide core data capabilities\u2014including storage, batch and real-time computing, querying, and analytics\u2014to support business teams, analysts, and machine learning applications. Our platforms cover the full data lifecycle, from ingestion to processing and monitoring, enabling teams to build reports, dashboards, real-time pipelines, and data-driven insights efficiently.; Job Description:; Responsible for the development of company level big data platform; Communicate effectively with product managers, designing and implementing product features; Writing high-quality, clean and maintainable code using engineering best practices; Requirements:; Bachelor's degree and above in Computer Science or related fields; Relevant experience in Backend Development; Familiar with commonly used languages and framework, such as Java, SpringBoot; In-depth understanding of Data Structures and Algorithms, Networking, OS and other Computer Science fundamentals; Familiar with commonly used Databases, such as MySQL; Familiar with commonly used Middlewares, such as Redis and Kafka; Familiar with HTTP protocols; Familiar with Distributed Systems; Full-time interns preferred; Part-time interns who can commit at least 4 working days a week are also welcome to apply; Familiar with big data technologies is a plus, such as Hadoop, Spark, Presto, etc","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85646745","Role":"Principal Integration Engineer Senior Manager","Company":"StarHub Ltd","Location":"Singapore","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85646745","job_desc":"Strategic Leadership and Coordination; \u2022    Lead Integration Strategy: Define and manage the integration strategy for enterprise and consumer solutions at StarHub, ensuring all components are integrated effectively to meet business needs.; \u2022    Coordinate Across Squads: Oversee the delivery of six squads (Mobile, Entertainment, Broadband, T2, SuperApp, eShop, and Enterprise Solutions) ensuring alignment with organizational objectives and promoting cross-functional collaboration.; \u2022    Stakeholder Management: Serve as the primary point of contact for key stakeholders, including business owners, squad leads, and OEM vendors, ensuring they are well-informed on integration progress and issues.; Technical Oversight; \u2022    End-to-End Integration: Ensure end-to-end system integration across multiple platforms (enterprise and consumer), including CRM, billing systems, digital front-ends, and third-party applications.; \u2022    Technical Architecture: Work closely with the Integration Design Specialists to establish integration standards, design reusable components, and ensure consistency in integration practices across different squads.; \u2022    API and Middleware Management: Oversee the development, implementation, and management of APIs, middleware solutions, and network protocols that facilitate integration among systems.; Delivery Management; \u2022    Sprint Planning and Delivery Oversight: Collaborate with Scrum Masters and Squad Leads to plan and manage delivery timelines for integration-related features and capabilities, ensuring they align with the overall product roadmap.; \u2022    Risk Management: Identify risks related to integration projects, create mitigation plans, and manage escalation processes for any challenges during integration.; \u2022    Performance Monitoring: Track and monitor the progress of all integration projects, using KPIs to evaluate performance and ensure that deadlines and quality standards are met.; Vendor Management; \u2022    OEM Coordination: Engage and manage relationships with OEM vendors to facilitate integration activities, including contract negotiations, managing SLAs, and monitoring vendor performance.; \u2022    Quality Assurance: Work with vendors to ensure all integration solutions comply with StarHub\u2019s security standards, quality requirements, and industry best practices.; Integration Testing and Quality Assurance; \u2022    Test Strategy Development: Define the integration testing strategy to ensure that all integrated components work seamlessly together.; \u2022    Coordinate Testing Efforts: Work with QA Leads and Network Integration Dev to plan and execute integration tests across systems, ensuring that all APIs, data flows, and interactions are functioning correctly.; \u2022    Defect Management: Oversee defect resolution during testing phases, especially during UAT and post-deployment hypercare; DevOps Integration and Automation; \u2022    DevOps Practices: Lead the integration team to follow DevOps principles, ensuring that integration services are delivered through automated CI\/CD pipelines.; \u2022    Infrastructure as Code (IaC): Work with the DevOps Tech Lead to establish infrastructure deployment using IaC principles to ensure consistency and repeatability in environment setup.; Tertiary Education in Engineering, Computer Science or equivalent; At least 8-10 years of relevant experience; Technical Expertise: Strong background in integration platforms, middleware, API management, and telecom systems.; Leadership: Ability to lead multiple cross-functional teams and manage external vendors effectively.; Agile and DevOps: Deep understanding of agile delivery, DevOps practices, and how to integrate them effectively within a telecommunications environment.; Problem Solving and Decision Making: Ability to navigate complex integration challenges, with a strong focus on problem resolution and risk mitigation.; Team Leadership and Development; \u2022    Lead Integration Team: Directly lead and mentor a team that includes:; \u2022    Integration Tech Lead: Responsible for driving technical integration across squads.; \u2022    Integration Design Specialists: Oversee the architecture and ensure alignment with StarHub\u2019s design principles and guidelines.; \u2022    Network Integration Developers: Develop and execute integration code to connect various systems and services.; \u2022    RPA Tech Lead: Oversee automation initiatives across the integration layers to reduce manual intervention and streamline workflows.; \u2022    DevOps Tech Lead: Ensure that integration processes are aligned with DevOps principles, facilitating smooth CI\/CD pipelines.; \u2022    OEM Vendors: Manage engagements with external vendors, ensuring they deliver as per the contract and meet integration standards.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"80159441","Role":"Cloud Architect - Technology Transformation - Technology Consulting","Company":"Ernst & Young Solutions LLP","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/80159441","job_desc":"Whole industries have been disrupted and transformed in recent years by digital technology.; As a Technology Consulting professional, you\u2019ll help businesses realize the value they can gain from their IT investments \u2014 supporting strategy and being a key growth driver. As part of a high-performing team, you\u2019ll deliver exceptional client service \u2014 providing advice on how technology enablement, digital transformation and enterprise intelligence contribute to performance improvement, as well as how IT can act as multiplying effect during major program transformations.; As organizations look to leverage the advantage IT offers, we\u2019ll work with you to develop the consultancy and analytical skills that you\u2019ll need in today\u2019s environment. Working on projects that cross borders and sectors, the experiences you gain here will be more valuable than anywhere else. So whenever you join, however long you stay, the exceptional EY experience lasts a lifetime.; The opportunity; We are seeking a self-driven Cloud Architect to plan and design the technology solution for client engagements.; Your Key Responsibilities; ; You will enable, drive and lead initiatives focusing on establishing and embedding cloud architecture & design governance across the organization.; Key functions include:; Lead initiatives for setting up cloud architecture & technology strategies, standards, governance and best practices for the whole organization.; Lead the initiatives to identify right set of cloud technologies to be used for specific type of solutions and drive the effort to templatize and automate those technologies to be used at scale in all products and applications across organization.; Architect & Design solutions for cloud (e.g. AWS, Azure) which are optimal, secure, efficient, scalable, resilient and reliable, and at the same time. are compliant with EY cloud standards and policies.   ; Design strategies and tools to deploy, monitor, and administer Cloud applications and the underlying services for Cloud (e.g. Azure, AWS, private cloud); Architect and implement DevSecOps processes and CI\/CD pipelines using tools like VSTS, Jira, Ansible, Jenkins, Chef.; Build quick POCs and write some code for exploring new technology solutions.; Skills and Attributes for Success; Deep understanding of cloud computing and data technologies, business drivers, emerging computing trends, and deployment options (preferably in Microsoft Azure and AWS).; Expert in defining, designing and developing distributed and scalable products and services, including reusable domain-specific microservices on multi-platform\/hybrid clouds (such as Microsoft Azure, AWS, Google Cloud Rackspace, VMware, or OpenStack).; Deep understanding of Application, Infrastructure and security architecture and non-functional aspects like Performance, Scalability, Reliability, Availability etc.; Deep experience in IAAS (with good fundamentals in network and security) as well as PAAS. Good understanding of all Azure services and ability to choose the right service for a workload among multiple Azure services preferred.; Strategic business acumen and understanding of organizational strategy and ability to design information systems to deliver that strategy.; Strong expertise in DevOps, Agile methodologies, containers, CI\/CD and tools like VSTS, Jira.; Experience with software and product development lifecycle (incl. coding, coding standards and reviews, source control, testing, debugging, build, deployment and operations).; Strong understanding of one or more development platform .Net technologies (C#), Java \/ JavaScript.; Familiarity in the following areas, but not limited to:; Front end \/ UI technologies including frameworks such as React\/Angular.js; REST \/ Webservices (with high performance, multi-tenancy, global, scalable elements); SQL, XML, JSON, Linux, ELK stack, Splunk, Solr, GIT, Ant\/Maven, Jenkins; Familiarity with Data Ingestion, Analytics, AI technologies  ;   To Qualify for the role, you must have; At least 6-10 years of deep technology experience at very large enterprises or web scale product companies.; At least 6-10 years of architecture, design, implementation, and\/or support of highly distributed applications (i.e. having an architectural sense for ensuring availability, reliability, etc.) on cloud.; Experience in presenting ideas, papers, patents to varied audiences.; Certificates requirements:; Microsoft Azure related certifications; Other cloud providers like AWS and Google Cloud are accepted; What we look for; Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you\u2019ll be a confident leader equipped with strong people management skills and a genuine passion to make things happen in a dynamic organization.; What working at EY offers; EY offers a competitive remuneration package where you\u2019ll be rewarded for your individual and team performance. We are committed to being an inclusive employer and are happy to consider flexible working arrangements. Plus, we offer:; Continuous learning: You\u2019ll develop the mindset and skills to navigate whatever comes next.; Success as defined by you: We\u2019ll provide the tools and flexibility, so you can make a meaningful impact, your way.; Transformative leadership: We\u2019ll give you the insights, coaching and confidence to be the leader the world needs.; Diverse and inclusive culture: You\u2019ll be embraced for who you are and empowered to use your voice to help others find theirs.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85044271","Role":"RVP, Agentforce & Data Cloud, ASEAN","Company":"Salesforce.com","Location":"Singapore","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85044271","job_desc":"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.; Job Category; Sales; Job Details; About Salesforce; We\u2019re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too \u2014 driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good \u2013 you\u2019ve come to the right place.; The Regional Vice President - Sales will be responsible for driving sales growth for the Salesforce Agentforce & Data Cloud portfolio in ASEAN. Agentforce & Data Cloud, our flagship innovation, harness the power of real-time data to reimagine the Customer 360, enabling businesses to create agentic first awe-inspiring customer interactions at scale.  This manager will be a leader of a growing sales organisation of Account Executives to help drive complex, strategic transactions. Your mission will be to develop a Sales Team distinguished by its supportive and inclusive culture, operational excellence, teamwork, commitment to professional development and consistent performance.; Your Impact:; Development of a thriving and diverse team across ASEAN who are seen as trusted advisors to our customer(s) and with internal team members; Supporting Account Executives by participating and leading in client meetings and engaging other corporate resources as required; Development of a winning team, including recruiting, hiring and training; Build strong team unity and collaboration; Leading weekly forecast meetings; Driving pipeline generation initiatives to maximise revenue generating opportunities for the customer account(s); Coach and professionally develop Account Executives regarding strategies to ensure a high level of closure rates and opportunity identification; Engaging at the C-level in customer organisations; Develop the Go-To-Market strategy for the account(s); Accurate reporting on sales activity and forecasting to Area Sales Management; Consistently monitoring and enhancing the sales activities of the team; To be an enabler of an inclusive and winning team spirit; Required Skills:; Relevant people management experience leading a team of experienced individual contributors; Consistent overachievement of quota and revenue goals.; Proven track record of building satisfied and loyal customers .; Proven success working within a highly matrixed organisation.; Experience leading comprehensive pipeline generation strategy and execution.; Strong operational and analytical abilities.; Sales experience and revenue achievement selling complex software offerings primarily at the C-level.; Strong track record of recruiting, developing and retaining a high performing sales organisation.; Experience selling one or more of the following: modern enterprise cloud data platforms (e.g., Snowflake, Databricks, Big Query), data analytics tools (e.g., Tableau), CRM applications and consumption selling strongly preferred.; Accommodations; If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.; Posting Statement; Salesforce is an equal opportunity employer and maintains a policy of non-discrimination with all employees and applicants for employment. What does that mean exactly? It means that at Salesforce, we believe in equality for all. And we believe we can lead the path to equality in part by creating a workplace that\u2019s inclusive, and free from discrimination. Know your rights: workplace discrimination is illegal. Any employee or potential employee will be assessed on the basis of merit, competence and qualifications \u2013 without regard to race, religion, color, national origin, sex, sexual orientation, gender expression or identity, transgender status, age, disability, veteran or marital status, political viewpoint, or other classifications protected by law. This policy applies to current and prospective employees, no matter where they are in their Salesforce employment journey. It also applies to recruiting, hiring, job assignment, compensation, promotion, benefits, training, assessment of job performance, discipline, termination, and everything in between. Recruiting, hiring, and promotion decisions at Salesforce are fair and based on merit. The same goes for compensation, benefits, promotions, transfers, reduction in workforce, recall, training, and education.","salary":"","work_type":"","country":"singapore"}
{"Job_ID":"84725789","Role":"Backend software engineer - Privacy and Security (Data Protection...","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84725789","job_desc":"Responsibilities; Team introduction: Build a first-class privacy compliance R & D team, create a high-security, high-stability, and high-efficiency globalization multi-data center data transmission platform , and provide strong technical support for TikTok to become the best privacy protection and most trustworthy product for users. Responsibilities:; 1. Design, develop, and maintain CI\/CD release pipelines leveraging Kubernetes (K8s) to ensure seamless deployment and delivery processes. 2. Develop and enhance Kubernetes cluster management capabilities, including cluster upgrades, resource pool management, and lifecycle automation. 3. Build and maintain tools for Kubernetes operations and maintenance, such as web-based shells, container log access, and debugging utilities.; 4. Lead the development of observability features, including system monitoring, centralized logging, and automated alerting to ensure high platform reliability. 5. Develop and implement Kubernetes security features, such as cluster certificate management and related compliance capabilities. 6. Support the day-to-day operations and maintenance of the platform to ensure stability, performance, and availability.; Qualifications; Minimum Qualifications:; BS\/MS Degree in Computer Science or equivalent majors; Proficiency in at least one of the following languages: Go, Java;; Deep understanding of computer architectures, data structures and algorithms;; Solid communication and teamwork skills, with the ability to work effectively with cross-functional teams;; Preferred Qualification:; Experience in high-traffic & high-concurrency server systems is preferred","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84484337","Role":"Senior Platform R&D Engineer - Recommendation System","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84484337","job_desc":"Responsibilities; About The Team The Recommendation Architecture Team is responsible for designing and developing recommendation system architectures for various products under the company. We ensure system stability and high availability, optimize performance for online services and offline data pipelines, address system bottlenecks, and reduce operational costs. We also abstract reusable system components and services to build recommendation and data middleware platforms, supporting rapid incubation of new products and empowering enterprise clients (ToB). Responsibilities 1. Design intelligent development toolkits for large-scale recommendation systems, providing tooling and productized solutions to enhance R&D efficiency. 2. Develop business metrics-driven gray release systems to ensure safe, stable, and efficient release strategies and workflows. 3. Enhance observability of recommendation systems in complex global environments (multi-region, multi-data center, multi-language), establish end-to-end tracing systems, and optimize issue attribution mechanisms. 4. Build algorithm engineering toolchains to accelerate the end-to-end process from experimental algorithm\/model development to deployment, improving iteration efficiency. 5. Overhaul platform ecosystem architectures and develop data intelligence assistants. Qualifications; Minimum Qualifications 1. Bachelor's degree or above, majoring in Computer Science, or related fields, with 3+ years of experience in designing and developing large-scale systems. 2. Proficiency in at least one programming language (Go\/Python\/C++) and solid understanding of data structures and algorithms. 3. Ability to independently lead the technical design and implementation of complex systems and components. 4. Strong product sense, with the ability to balance priorities across requirements, technical solutions, timelines, and delivery quality. Preferred Qualifications 1. Deep understanding of large language models (LLMs), familiarity with LLM principles and applications, and hands-on experience in Agent system design. 2. Experience in recommendation\/advertising\/search systems, or privacy compliance frameworks (GDPR, CCPA).","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85617459","Role":"VP\/AVP, Cloud Security Engineer, Information Security Services, Group Technology","Company":"DBS Bank Limited","Location":"Singapore","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85617459","job_desc":"Business Function; Group Technology enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group Tech, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.; Responsibilities; This candidate will be responsible for the implementation and governance of cloud and container security controls and tooling across platforms, while driving risk assessments, incident response, and compliance in cloud-native and containerized environments.; Lead the evaluation, implementation, and operationalization of security controls for public clouds and container platforms such as (AWS, GCP, Azure, OpenShift, PCF, VIC).; Define and enforce security baselines, architecture patterns, and hardening standards for cloud workloads and container platforms.; Participate, perform threat modelling and risk assessments for cloud projects, identifying security gaps and defining effective controls aligned with regulatory and industry frameworks.; Review and assess cloud implementations, defined through Infrastructure as Code (IaC) and CI\/CD pipelines, to identify security gaps and ensure alignment with access control best practices and compliance requirements.; Serve as a trusted security advisor to stakeholders and senior management, translating technical risks into actionable strategies for secure cloud adoption.; Continuously evaluate emerging threats and technologies, driving the adoption of new technologies and processes to enhance the bank\u2019s cloud security posture without compromising performance or usability.; Develop and manage monitoring and alerting systems, perform incident triage, vulnerability scans, and execute root-cause analysis.; Design and implement automated detection, alerting, and remediation workflows using scripting, IaC, and SOAR platforms.; Requirements; Bachelor\u2019s or Master\u2019s degree in Computer Science or equivalent; Working experience developing applications or managing infrastructure services for public cloud such as AWS, GCP or Azure; Programming skills in at least one programming language\\: Python, Javascript, Java, C\/C; Working experience in the information technology domain (computer\/mobile application, APIs, container technology such as Dockers, public cloud, data science etc) and preferably in the information security (public cloud) domain; Experience performing system analysis and design requirements gathering.; Professional certification such as CISSP, GIAC GISP will be an added advantage; Public cloud certifications; Possess good technical knowledge in various security tools (end-point, network, authentication etc); Good understanding of regulatory requirements (e.g. MAS Technology Risk Management Guidelines, PCI DSS, Personal Data Protection Act); Knowledge of tactics, techniques, and procedures associated with malicious insider activity, organized crime\/fraud groups and both state and non-state sponsored threat actors.; Able to perform coding on need-to basis to build or enhance existing security solution; Knowledge and working experience of financial security standards such as EMV, PCI DSS, is advantageous.; Good networking with other security professionals in the financial industry; Apply Now; We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155045","Role":"Big Data Engineer Intern, Ads Data - 2025 Start","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155045","job_desc":"Responsibilities; Monetization data SG team aims to empower TikTok monetization business through acquiring, building and managing all kinds of ad data as our data foundation, and further provide scalable solutions including dashboards, pipelines, data products and data services. We are partnership with business through a better understanding of business strategy and aligning OKRs with business to drive business growth as a stakeholder. At the same time, our team continues to explore the development of data engines, data warehouse methodology, BI tools, ML data technology to efficiently improve the efficiency of data development, and deeply mine data value to improve business growth.; We are looking for talented individuals to join us for an internship in 2025. Internships at TikTok aim to offer students industry exposure and hands-on experience. Watch your ambitions become reality as your inspiration brings infinite opportunities at TikTok.; Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early.; Successful candidates must be able to commit to the following Internship: We will prioritize candidates who are able to commit to a minimum of 4 months and above, ideally for a minimum of 3 days a week. Responsibilities; - Responsible for developing and operating our internal BI platform to support various business of advertising and analytics. - Process data processing requests and execute data model design, implementation and maintenance;; Qualifications; Minimum Qualifications; Undergraduate, or Postgraduate who is currently pursuing a degree\/master in Computer Science, Computer Engineering, Information Systems or a related technical major;; Strong interest in computer science and internet technology;; Know relevant technologies of the Hadoop ecosystem, such as the principles of MapReduce, Spark, Hive, and Flink;; Familiar with SQL, be able to use SQL to perform data analysis, or proficient in Java, Python and Shell and other programming languages for data processing;; Good at communication, proactive in work, a strong sense of responsibility, and good teamwork ability.; By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https:\/\/careers.tiktok.com\/legal\/privacy. If you have any questions, please reach out to us at apac-earlycareers@tiktok.com","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85033956","Role":"Tencent Cloud - CLS Storage Product Solution Architect (Singapore)","Company":"Tencent International Service Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85033956","job_desc":"Business Unit; Cloud & Smart Industries Group (CSIG) is responsible for promoting the company's cloud and industry Internet strategy. CSIG explores the interactions between users and industries to create innovative solutions for smart industries via technological advancements such as cloud, AI, and network security. While driving the digitalization of retail, medical, education, transportation and other industries, CSIG helps companies serve users in smarter ways, building a new ecosystem of intelligent industries that connect users and businesses. What the Role Entails; Position Overview; Tencent Cloud is seeking a highly capable Storage Product Solution Architect to support the growth of our Cloud Log Service (CLS) and broader storage portfolio in Southeast Asia. In this role, you will serve as a technical expert in storage, logging, and observability domains\u2014working closely with sales and solution teams to design and deliver tailored architecture for enterprise customers. You will translate complex business requirements into scalable, cloud-native solutions, while contributing to product innovation through feedback to our R&D team. If you are passionate about distributed systems, storage technologies, and driving business impact through technical leadership, this is your opportunity to grow with one of Asia\u2019s leading cloud providers.; Responsibilities; Collaborate with industry sales and presales teams to understand client needs and propose appropriate solutions across file storage, block storage, CLS logging, and observability services.; Design robust, scalable, and cost-effective technical architectures tailored to customer requirements. Deliver migration strategies and implementation roadmaps for smooth solution rollout.; Monitor market dynamics, customer demands, and competitor offerings to provide actionable feedback to R&D and help guide product roadmap development.; Act as an internal evangelist for CLS and related storage products\u2014supporting enablement initiatives for sales and partner teams. Represent Tencent Cloud at events or workshops to strengthen our positioning in the region.; Contribute to technical documentation, whitepapers, and solution playbooks that support adoption of CLS and observability offerings.; Who We Look For; Bachelor\u2019s degree or above in Computer Science, Software Engineering, or related field; Master\u2019s degree is a plus.; At least 5 years of experience in cloud computing or storage architecture.; Experience supporting public cloud pre-sales or solution architecture, with strong customer-facing exposure.; Proficient in technical domains such as: cloud-native storage solutions, object\/file\/block storage, log ingestion pipelines, observability frameworks, and data retention\/compliance strategies.; Excellent communication and stakeholder engagement skills in both English and Chinese Mandarin in order to coordinate with global product teams and HQ stakeholders.; Self-motivated with strong analytical thinking, and ability to solve complex technical challenges in dynamic, fast-paced environments.; #LI-JY1; Equal Employment Opportunity at Tencent; As an equal opportunity employer, we firmly believe that diverse voices fuel our innovation and allow us to better serve our users and the community. We foster an environment where every employee of Tencent feels supported and inspired to achieve individual and common goals.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85225762","Role":"Microsoft Cloud (Azure), Data and Apps Business Development Director -...","Company":"SoftwareONE Deutschland GmbH","Location":"Singapore","Publish_Time":"2025-06-26 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85225762","job_desc":"Why SoftwareOne?; Discover the heartbeat of SoftwareOne! Our 7 core values aren't just words \u2013 they're the beating heart of our company culture. Join us in a journey that unveils the essence of how we work, connect, and succeed. Watch the video to feel the values shaping our everyday interactions, customer relations, and team spirit.; Please note that SoftwareOne does not accept unsolicited resumes from recruiters or employment agencies. In the absence of a signed Services Agreement (Job-Specific per our global standard) with the agency\/recruiter, SoftwareOne will not consider or agree to payment of any referral compensation or recruiter fee.; The role; Our Hiring Leader:; Hi, My name is Alex Tay and I am the Business Development Director (Cloud, Apps and data) at SoftwareOne Southeast Asia.; \"We at SoftwareOne are looking for Sales Professionals that model a positive mindset and remain curious in all activities that they are involved in. Professionals that seek to maintain a joint-venture relationship with our customers, partners and internal support teams. Professionals who have a curious mindset and a hunger for knowledge for both our customers and our own business. Finally, they need to know how to have fun and recognise our customers' and team members' contributions.\"; Eager to meet our Dynamic leader? Feel free to check out his LinkedIn Profile:; Alex Tay | linkedin; A BDD (Individual Contributor) is a sales expert against customer problems\/ business needs. The BDD is responsible for accelerating time to value for our customers and supporting them in their cloud and digital transformation by aligning our solutions. Good technical understanding and the ability to transform our customers challenges into commercial solutions. The BDD identifies, develops, and lands opportunities for defined portfolio elements in cooperation with Account Management team. A highly motivated collaborator to hunt and win deals.; Key Responsibilities: Cloud (Azure), Data, Application and AI Services business growth in the Singapore.; Location : Singapore; Accountable for growing new Cloud (Azure), Data, Application and AI Services Opportunities along with Field Sales ensuring that the customers\u2019 needs are met or exceeded. Drive the entire Sales Cycle from initial Customer Engagement till Contract Closing for new & existing customers.; Establish relationships with new and existing customers and secure new business in the assigned portfolio element(s).; Work with Account Managers to ensure that the overall account strategy and goals are followed and achieved.; Maintain a very detailed level of relevant knowledge on the assigned portfolio element(s) in order to have meaningful and relevant conversations with customers and prospects; Work with Technical Architects \/ Practice Leaders to ensure that we design the right solutions for our customers.; Work with Partners, i.e. Microsoft, to grow the services around Microsoft technology.; Provide feedback to Account Management on ways to decrease the Sales Cycle, enhance Sales, and improve company brand and reputation.; Provide feedback to the service delivery team to ensure that the service delivered meets or overachieve the satisfaction level of the client.; Construct service contracts and associated commercials\/cost model based on scope and customer\u2019s desired outcome.; What we need to see from you; Existing Full-Time Work Rights in Singapore; Ability to commute to our Singapore office and visit clients in Singapore; Technical Qualifications:; 10+ years enterprise technology strategic sales\/pre-sales experience with a good knowledge on selling cloud and digital transformation solutions, specifically around Microsoft Azure.; Able to articulate use cases of cloud transformation specific to the customers industry and size and understand where the customer is on their journey.; Engage with stakeholders from IT all the way to C-level, understand the Customers business requirement & challenges, create an IT transformation roadmap covering (not limited to) Cloud, Data, Application and AI Services and position the right support model and articulate the business value of the offering.; Position Cloud. Data, Application and AI Services advisory and\/or professional services to customer depending on their requirements.; Understanding of the Microsoft Azure Cloud, Data, Application and AI Services technologies and Funding program, drive SoftwareOne services.; Have strategic sales\/pre-sales experience with a good knowledge on selling Data or Application transformation solutions, specifically around Microsoft Azure.; Have experience around selling professional services, managed services and consulting services and structuring go to market product services.; Functional understanding of key technologies and trends in the cloud domain, Application Modernization, Data & Analytics, containerization, cloud operating models, Cloud economics, Finops.; Experience preparing, presenting formal proposals to customers. Leading negotiations, coordinating complex decision-making process, and overcoming objections to closure.; Strong knowledge in public cloud market in Asia and strong understanding of cloud consumption economics.; Strong Knowledge on domain arounds Data and Application development using Microsoft technology.; Expertise in enterprise solution selling techniques and selling cloud-based solutions.; Effective territory\/account management and leading sales teams: planning, opportunity qualification and creation, stakeholder and executive communication, needs analysis, value engineering, services\/partner engagement, opportunity management and proposal response, pipeline management, large dollar licensing and deal negotiation required.; Experience and expertise selling to c-suite and executive business decision makers by aligning & reinforcing the value of Cloud transformation to the customer's overall business and\/or strategic opportunities and decision criteria.; Experience leading large cloud engagements, especially those involving infrastructure modernization and migration.; executive level speaking and presentation skills, and good written communication skills, exceptional demonstrated decision-making, conflict resolution, problem solving and negotiation skills.; Have a strong collaboration skill to engage internal and external.; Job Function; Sales #J-18808-Ljbffr","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155396","Role":"Machine Learning Engineer (Data Compass) Intern, TikTok Global E-Commerce -...","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155396","job_desc":"Responsibilities; TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok's sponsorship of a visa. TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy.; TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo. Why Join; Us Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.; Together, we inspire creativity and bring joy; a mission we all believe in and aim towards achieving every day.; To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact; for ourselves, our company, and the communities we serve.; Join us. About the Team The E-Commerce Business Growth; Data Compass team aims to cater to merchants and creators on the e-commerce platform and improve their operational efficiency.; Our focus is to optimize various aspects such as merchandise strategy, user operation, and marketing, leveraging algorithm-driven solutions. We are looking for talented individuals to join us for an internship in from August 2024 onwards. Internships at TikTok aim to offer students industry exposure and hands-on experience.; Watch your ambitions become reality as your inspiration brings infinite opportunities at TikTok. Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to TikTok and its affiliates' jobs globally.; Applications will be reviewed on a rolling basis; we encourage you to apply early.; Successful candidates must be able to commit to at least 3 months long internship period. Responsibilities; Improve the working efficiency of e-commerce merchants, influencers, and account managers to boost the growth of sellers' products, customers, and revenue.; Participate in the optimization of sellers' operations, such as marketing insights, assortment planning, customer relationship management (CRM), anomaly detection, and diagnostic attribution.; Participate in the optimization of merchandise operations, such as seasonal and trend analysis, supply and demand analysis, new product and product growth analysis, and improving the alignment of products and associated traffic.; Participate in the optimization of the marketing strategies and Return on Investment (ROI) of sellers and influencers in TikTok e-commerce live streaming, short video, and ShopTab.; Analyze and conduct feature engineering for massive data such as customer profiling, e-commerce transactions, relationships between products, business opportunities, and deploy the model pipeline.; Use techniques such as representation learning, graph modelling, causal inference, and time series forecasting to assist merchants and influencers in problem-solving and discovering growth opportunities.; Run experiments to test the performance of deployed models, and identifies and resolves bugs that arise in the process.; Work in a team setting and apply knowledge in statistics, scripting and programming languages required by the firm.; Qualifications; Minimum Qualifications; Undergraduate, or Postgraduate who is currently pursuing a degree\/master in Software Development, Computer Science, Computer Engineering, or a related technical discipline.; Experienced with feature engineering from massive raw data, such as customer\/seller\/influencer profiling and e-commerce transactions.; Proficiency in coding skills using Python, Spark, Tensorflow\/PyTorch, and other deep learning tools.; Hands-on experience with data structure algorithms, machine learning models such as sales forecasting, classification task, deep learning etc.; Proven experience of implementing business projects and launching product features.; Preferred Qualifications; Experienced in deep learning, time series forecasting, causal inference or relevant fields.; Solid understanding of search and recommendation systems, with an emphasis on AIGC field, is a plus.; A strong desire to learn and discover new things, result-oriented, customer-oriented, team player, and self-driven.; TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy.; To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https:\/\/careers.tiktok.com\/legal\/privacy.; If you have any questions, please reach out to us at apac-earlycareers@tiktok.com.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155490","Role":"Backend Engineer Intern, Ads Data - 2025 Start","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155490","job_desc":"Responsibilities; Team Introduction Monetization data SG team aims to empower TikTok monetization business through acquiring, building and managing all kinds of ad data as our data foundation, and further provide scalable solutions including dashboards, pipelines, data products and data services. We are partnership with business through a better understanding of business strategy and aligning OKRs with business to drive business growth as a stakeholder.; At the same time, our team continues to explore the development of data engines, data warehouse methodology, BI tools, ML data technology to efficiently improve the efficiency of data development, and deeply mine data value to improve business growth. We are looking for talented individuals to join us for an internship in 2025. Internships at TikTok aim to offer students industry exposure and hands-on experience.; Watch your ambitions become reality as your inspiration brings infinite opportunities at TikTok. Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to TikTok and its affiliates' jobs globally.; Applications will be reviewed on a rolling basis - we encourage you to apply early. Successful candidates must be able to commit to the following Internship: We will prioritize candidates who are able to commit to a minimum of 4 months and above, ideally for a minimum of 3 days a week.; Responsibilities: - Responsible for developing and operating our internal BI platform to support various business of advertising and analytics. - Process data processing requests and execute data model design, implementation and maintenance; Qualifications; Minimum Qualifications; Undergraduate, or Postgraduate who is currently pursuing a degree\/master in Computer Science, Computer Engineering, Information Systems or a related technical major;; Familiar with SQL, be able to use SQL to perform data analysis; Familiar with Java, Python or other programming languages for data processing and software development;; Preferred Qualification; Excellent English written and verbal communication skills, proactive in work, a strong sense of responsibility, and good teamwork ability.; Strong interest in computer science and internet technology; By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https:\/\/careers.tiktok.com\/legal\/privacy. If you have any questions, please reach out to us at apac-earlycareers@tiktok.com","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85483383","Role":"Cloud Security Engineer (AWS|VA|IAM)","Company":"ScienTec Consulting Pte Ltd","Location":"Central Region","Publish_Time":"2025-07-04 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85483383","job_desc":"Working Hours: Monday \u2013 Friday (10am \u2013 7pm); Location: Tanjong Pagar; Salary: Up to $8,500 (VB + AWS); ; Responsibilities               ; Develop and manage cloud security controls, access privileges, and policies across cloud services.; Perform regular audits and assessments to identify and remediate security vulnerabilities.; Investigate security incidents by analyzing logs, network data, and pentest results.; Safeguard data, applications, endpoints, and SaaS platforms from internal and external threats.; Collaborate with solution architects and engineering teams to embed security within DevOps pipelines and cloud architecture.; Lead or contribute to root cause analysis of penetration test findings and drive remediations.; Implement security tools such as GuardDuty, AWS Security Hub, Inspector, IDS\/IPS, and SIEM platforms.; Guide internal teams on secure development practices and cloud configurations.; Support incident response efforts and provide after-hours\/weekend assistance as required.; Stay updated on the latest security threats, vulnerabilities, and cloud hardening techniques.; Requirements; Minimum 3 years of experience in AWS Cloud Security (e.g., GuardDuty, Security Hub, Inspector).; Solid understanding of SSDLC, OWASP, and cloud security best practices.; Hands-on experience with vulnerability assessment, pentesting, and SIEM\/IDS tools.; Proficient in IAM, secrets management, and container security (e.g., Kubernetes). Comfortable with Linux, scripting, and open-source security tools.; Relevant certifications (e.g., OSCP, CISSP, or AWS Security).;  ; ; By submitting your resume, you consent to the collection, use, and disclosure of your personal information per ScienTec\u2019s Privacy Policy (scientecconsulting.com\/privacy-policy).; This authorizes us to:; Contact you about potential opportunities.; Delete personal data as it is not required at this application stage.; All applications will be processed with strict confidence. Only shortlisted candidates will be contacted.; Wong Siew Ting (Maeve) - R25127375; ScienTec Consulting Pte Ltd - 11C5781","salary":"SGD 7000 - 8500 per month, AWS + VB (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"83897037","Role":"Tencent Cloud - Senior Cloud Architect (R&D & Solution Design)","Company":"Tencent International Service Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83897037","job_desc":"Business Unit; Cloud & Smart Industries Group (CSIG) is responsible for promoting the company's cloud and industry Internet strategy. CSIG explores the interactions between users and industries to create innovative solutions for smart industries via technological advancements such as cloud, AI, and network security. While driving the digitalization of retail, medical, education, transportation and other industries, CSIG helps companies serve users in smarter ways, building a new ecosystem of intelligent industries that connect users and businesses. What the Role Entails; Position Overview:; As a Senior Cloud Architect at Tencent Cloud, you will be responsible for designing and implementing advanced cloud architectures, collaborating with internal product and R&D teams, and delivering tailored cloud solutions for our customers. This role requires deep technical expertise in cloud infrastructure and a passion for innovation, as you will also be leading R&D efforts to enhance our cloud platform.; This position requires travel to Indonesia, potentially on a frequent basis.; Responsibilities:; Design and architect scalable, secure, and reliable cloud infrastructure to support Tencent Cloud's expanding portfolio of products and services.; Lead the technical development and integration of cloud solutions, ensuring they meet business objectives and customer requirements.; Drive cloud R&D initiatives by exploring new technologies and developing innovative solutions to optimize our cloud platform.; Collaborate with cross-functional teams, including product development and external partners, to deliver end-to-end cloud solutions.; Provide technical leadership and guidance to teams on cloud architecture best practices, ensuring high availability, performance, and security.; Ensure the alignment of cloud architectures with industry standards and compliance requirements.; Support the achievement of revenue objectives through the adoption and migration of applications, software, and services onto the TencentCloud platform, in partnership with the sales team.; Troubleshoot and resolve complex issues related to cloud infrastructure, performance, and scalability.; Support the achievement of revenue objectives through the adoption and migration of applications, software, and services onto the Tencent Cloud platform, in partnership with the sales team.; Who We Look For; Bachelor's or Master's degree in Computer Science, Engineering, or a related field.; 5+ years of experience in cloud architecture design, with hands-on experience in cloud infrastructure, cloud-native technologies, and R&D.; Expertise in Tencent Cloud or similar platforms (e.g., AWS, Azure) with a deep understanding of IaaS, PaaS, and SaaS models.; Proven experience in designing and deploying cloud solutions, including microservices architecture, containers (Docker, Kubernetes), and CI\/CD pipelines.; Strong problem-solving skills with the ability to lead technical initiatives and propose innovative cloud solutions.; Excellent communication skills, with fluency in both English and Chinese (spoken and written) in order to manage internal and external stakeholders and craft technical documents in both languages effectively.; Preferred Skills:; Experience with cloud R&D projects, particularly in exploring emerging technologies like AI, big data, or edge computing.; Strong understanding of cloud security, monitoring, and compliance practices.; Familiarity with DevOps practices and automation tools for continuous integration and deployment.; Equal Employment Opportunity at Tencent; As an equal opportunity employer, we firmly believe that diverse voices fuel our innovation and allow us to better serve our users and the community. We foster an environment where every employee of Tencent feels supported and inspired to achieve individual and common goals.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85155160","Role":"Backend Engineer Intern (TikTok Recommendation Developer Infrastructure) -...","Company":"TikTok Pte. Ltd.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85155160","job_desc":"Responsibilities; About the Team E-commerce is a new and fast growing business that aims at connecting all customers to excellent sellers and quality products on TikTok Shop, through E-commerce live-streaming, E-commerce short videos, and commodity recommendation. Our E-ecommerce Recommendation Infra team is responsible for building up and optimizing the infrastructure for such recommendation systems, so as to provide the best experience for our users. We work closely with applied machine learning engineers and build scalable systems to support all kinds of innovative algorithms and techniques.; We are looking for talented individuals to join us for an internship in 2025. Internships at TikTok aim to offer students industry exposure and hands-on experience. Watch your ambitions become reality as your inspiration brings infinite opportunities at TikTok.; Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis; we encourage you to apply early.; Successful candidates must be able to commit to at least 3 months long internship period. Responsibilities; Build and maintain high performance online services for TikTok recommendation system\uff1b; Build extremely efficient and reliable data pipelines for candidates generation, profile generation, training examples generation, realtime online training, etc;; Build globalized large-scale recommendation system;; Design and develop high performance computing frameworks and storage systems.; Qualifications; Qualifications: Minimum Qualifications: - Undergraduate, or Postgraduate who is currently pursuing a degree\/master in Computer Science, Computer Engineering, Information Systems or a related technical major;; - Experience programming in at least one of the following programming languages: C, C++, Java or Golang; - Effective communication skills and a sense of ownership and drive; Preferred Qualifications:; - Experienced in at least one area of the following areas: personalized recommendations, search engine, machine learning, distributed storage system, big data frameworks is a plus. By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https:\/\/careers.tiktok.com\/legal\/privacy. If you have any questions, please reach out to us at apac-earlycareers@tiktok.com","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"83648111","Role":"Head of SAP Business Data Cloud (BDC) Sales, APAC","Company":"SAP Asia Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83648111","job_desc":"We help the world run better; At SAP, we enable you to bring out your best. Our company culture is focused on collaboration and a shared passion to help the world run better. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from.; Position Overview; The primary purpose of the SAP Business Data Cloud (BDC) Solution Sales Manager is to lead, drive, manage, coach, and develop a team of Business Data Cloud Solution Sales Executives to consistently attain targeted revenue and profitability goals and set the vision and strategy for the sales team. To accomplish these goals, the Solution Sales Manager must develop specific territory plans to ensure growth in all revenue streams, formulate objectives, performance standards and priorities for the sales team and ensure that the selling models facilitate market penetration.; What you\u2019ll do\/ Key Responsibilities; \u25aa Recruit a team of high caliber sales talent, introduce strong sales processes, support the development of a full pipeline of sales prospects, engage customers and Partners at the executive level, motivate the sales team, resolve conflicts, remove barriers, and provide recognition in the pursuit and achievement of sales revenue and profitability.; \u25aa Define a vision and create a winning strategy that draws upon the strengths of SAP and responds to specific market needs, generates competitive advantage on existing markets, and develops consistent new revenue streams that will guarantee short and long term achievements.; \u25aa Develop and apply an in-depth understanding of SAP's processes\/ procedures and sales tools\/systems as well as enterprise market, including industry, marketplace, strategies and trends, competitors, and competitive tactics to develop an effective long-term sales strategy and plan.; \u25aa Demonstrate an outstanding execution track along sales cycles, ensuring SAP's sales methodologies and common processes are in place and define clear territory engagement guidelines.; \u25aa Monitor and take necessary measures to ensure adequate pipeline of opportunities and demand generation for sustainable growth.; \u25aa Utilize a disciplined approach for successful solution selling (value Centric Sales Approach), establish, and maintain accurate, timely and documented sales revenue forecasting procedures, provide required updates to SAP executive management.; \u25aa Ensure there is a proper business case with clear and attractive ROI impact, on each proposal SAP presents.; \u25aa Build a network of executive relationships across industry, community, and business groups, and with key partners and customers to stay current on issues impacting business and sales, provide meaningful strategic advice to retain and grow their business through integrated solutions.; \u25aa Stay current and informed on all new campaigns, understand their objectives and relevance, communicate to the Sales team, and ensure all involved know the roles the play in making campaigns successful.; \u25aa Work collaboratively with other internal teams within SAP, Industry Sales teams, Marketing, Development, Center of Excellence, Solution Advisory, etc.; What you bring\/ Qualifications; \u25aa Experience leading\/managing in a team selling environment.; \u25aa 10+ years of experience in sales of complex technology\/cloud solutions.; \u25aa Proven track record in business application software sales.; \u25aa Demonstrated success with complex, long-cycle sales campaigns in a fast-paced, consultative, and competitive market.; \u25aa Demonstrate success negotiating complex contracts.; \u25aa Demonstrated knowledge on consultative selling methodologies; \u25aa Proven abilities on managing highly complex organizations and applying risk-mitigation strategies to the customer.; \u25aa Bachelor\u2019s degree in business, Information Technology, or a related field.; Preferred:; \u25aa Understanding of SAP technologies including SAP Datasphere, SAP Analytics Cloud, SAP BW and SAP Business AI. Generic knowledge about SAP Business Technology Platform is useful.; \u25aa Proficient in cloud platforms (AWS, Azure, Google Cloud) and data engineering tools.; \u25aa Experience in enterprise solution sales management focused on data management and AI integration.; \u25aa Extensive industry network for business development.; \u25aa Knowledge of data engineering, machine learning, AI, and their ecosystem.; Bring out your best; SAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, you can bring out your best.; We win with inclusion; SAP\u2019s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone \u2013 regardless of background \u2013 feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.; SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and\/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com; For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.; EOE AA M\/F\/Vet\/Disability:; Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability.; Successful candidates might be required to undergo a background verification with an external vendor.; Requisition ID: 417900  | Work Area: Sales  | Expected Travel: 0 - 10%  | Career Status: Management  | Employment Type: Regular Full Time   | Additional Locations: Virtual - Asia-Pacific #LI-Hybrid.; Job Segment: Cloud, SAP, ERP, Software Sales, Database, Technology, Sales","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85813512","Role":"Data Engineer","Company":"Singapore Telecommunications Limited","Location":"Singapore","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85813512","job_desc":"An empowering career at Singtel begins with a Hello. Our purpose, to Empower Every Generation, connects people to the possibilities they need to excel. Every \"hello\" at Singtel opens doors to new initiatives, growth, and BIG possibilities that takes your career to new heights. So, when you say hello to us, you are really empowered to say\u2026\u201cHello BIG Possibilities\u201d.; Be a Part of Something BIG!  ; Responsible for building and supporting data ingestion and transformation pipelines in a modern hybrid cloud platform; Independently develop basic batch and streaming pipelines, working with cloud tools such as Databricks and Kafka under the guidance of senior engineers; Contribute to the delivery of reliable, secure, and high-quality data for analytics, reporting, and machine learning use cases; Gain exposure to enterprise-scale data architecture, while growing into more advanced engineering responsibilities over time.; Make An Impact By; Build and maintain data ingestion pipelines for batch and streaming data sources using tools like Databricks and Kafka; Perform data transformation and cleansing using PySpark or SQL based on business and technical requirements; Monitor and troubleshoot data workflows to ensure data quality and pipeline reliability; Work closely with senior data engineers to understand platform architecture and apply best practices in pipeline design; Assist in integrating data from diverse source systems (files, APIs, databases, streaming); Help maintain metadata and pipeline documentation for transparency and traceability; Participate in integrating pipelines with tools such as Microsoft Fabric, Databricks, Delta Lake, and other platform components; Contribute to automation efforts using version control and CI\/CD workflows; Apply basic data governance and access control policies during implementatio; Skills to Succeed; Bachelor\u2019s degree in Computer Science, Engineering, or a related field; 1\u20133 years of experience in data engineering or data platform development; Proven ability to independently build basic batch or streaming data pipelines; Hands-on experience with Python and SQL for data transformation and validation; Familiarity with Apache Spark (especially PySpark) and large-scale data processing concepts; Self-starter with strong problem-solving skills and a keen attention to detail; Able to work independently while collaborating effectively with senior engineers and other stakeholders; Strong documentation and communication skills.; Rewards that Go Beyond; Full suite of health and wellness benefits  ; Ongoing training and development programs  ; Internal mobility opportunities; Your Career Growth Starts Here. Apply Now!; We are committed to a safe and healthy environment for our employees & customers and will require all prospective employees to be fully vaccinated.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85815135","Role":"Cloud Engineer","Company":"Virtusa Singapore Private Limited","Location":"Downtown Tanjong Pagar","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85815135","job_desc":"Roles & responsibilities:; Work as the go to person inside Data & Analytics organization in HSBC Wealth and Personal Banking for any banking data request from Data Scientist team and senior business stakeholders.; Work as DataOps transformation to enable self-serve, high performing data ETL.; Hands-on development for data ETL pipeline, data quality check and be responsible for peer coding review.; Participate in regular stands-up to share and speak up the progress and key blocker to ensure project is going smooth; Skills & Qualifications:; 2-5 years of data related working experience in Financial Institute with special preference in banking.; High proficiency in SQL, Python, PostgreSQL and Cloud native data pipeline automation tooling, e.g. BigQuery; Knowledge of SAS coding will be an advantages; Proven working experience in delivering large scale data projects\/data products.; Project experience in designing & developing high-performance solution for handling extremely large volume data processing, storage and wrangling in real-time manner.; Good understanding of DevOps, DataOps or MLOps.; Experience in RPA (Robotic Process Automation) is an advantages; Experience in Business visualization tool Looker, including LookML; Cloud-native data ETL development in GCP is preferred; Technology stack provisioned in the team include:; DataProc plus Python on Google Cloud; Airflow DAG for scheduling; Multiple databases including PostgreSQL, BigQuery, graph databases, etc.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85818027","Role":"Staff Data Engineer","Company":"Network Guard","Location":"North Region","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85818027","job_desc":"We are seeking a highly skilled and hands-on Staff Data Engineer to architect and maintain modern data infrastructure and pipelines. This is an individual contributor role focused on building scalable data platforms that power analytics, insights, and data-driven decisions across the company. You will work closely with analysts, data scientists, product, and engineering teams to design end-to-end data solutions using tools like AWS Redshift, Athena, Snowflake, and other leading cloud platforms.; ; ; What You\u2019ll Do; Design and build scalable data pipelines to ingest, process, and store large volumes of structured and unstructured data from diverse sources.; Develop and maintain robust data warehouse architectures leveraging tools such as AWS Redshift, Athena, and Snowflake.; Optimize data models, queries, and storage strategies for performance, scalability, and cost-effectiveness.; Collaborate with cross-functional stakeholders (analytics, product, ML) to gather requirements and deliver data solutions that support business goals.; Ensure data quality, security, and privacy through best practices in governance, testing, and monitoring.; Own and operate production data workflows, resolving incidents and ensuring reliability.; Stay up-to-date with the latest trends and advancements in data engineering and analytics.; ; ; Tech Stack; Languages & Tools: Python, SQL; Data Warehousing & Query Engines: Snowflake, AWS Redshift, Athena; Pipeline & Orchestration: Apache Airflow, AWS Glue, dbt; Cloud & DevOps: AWS (Lambda, S3, IAM), Docker, Terraform; Streaming : Kafka, Kinesis; BI & Analytics: Tableau, Power BI; ; ; What You\u2019ll Need To Succeed; Bachelor's or Master\u2019s degree in Computer Science, Engineering, or related field.; 5+ years of experience as a Data Engineer, with a strong focus on data pipeline development and data warehousing.; Deep proficiency in AWS Redshift, Athena, Snowflake, and experience working with large-scale data systems.; Strong programming and scripting skills in Python, SQL, and Shell.; Experience with pipeline orchestration tools (e.g., Airflow, Glue, dbt).; Solid understanding of data modeling, schema design, and ETL processes.; Familiarity with cloud infrastructure and DevOps practices (especially AWS).; Experience with BI platforms like Tableau or Power BI.; Excellent analytical and problem-solving skills.; Strong communication and the ability to work across functions and mentor others.; ; ; Nice to Have; Knowledge of data privacy and security best practices (e.g., GDPR, SOC2).; Exposure to MLOps and ML data pipelines.; Experience in high-growth, product-led or SaaS environments.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85043745","Role":"Data Engineer","Company":"Tabernacle Pte Ltd","Location":"Central Region","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85043745","job_desc":"We are seeking a hands-on Fabric Onsite Data Engineer to support our data modernization initiatives by leveraging Microsoft Fabric. This role is critical in transitioning legacy ADF pipelines to Fabric Pipelines and Dataflows Gen2 while ensuring high data quality, robust metadata management, and effective collaboration with business and technical stakeholders.; Key Responsibilities:; Rebuild and optimize existing Azure Data Factory (ADF) ingestion processes using Microsoft Fabric Pipelines and Dataflows Gen2.; Coordinate with SL10\/EQS source system owners to align data schemas, field mappings, and ingestion specifications.; Perform onsite data validation and integrity checks across ingestion workflows to ensure accuracy and completeness.; Capture and log file-level and field-level metadata (e.g., file name, source system, ingestion timestamp) to enhance traceability and auditability.; Support User Acceptance Testing (UAT), triage user-reported issues, and provide technical support to business users during validation phases.; Train and guide end users on accessing and using Power BI reports, data glossary resources, and Baobao Q&A tools for self-service analytics.; Proactively respond to data queries from business users, ensuring data understanding and alignment with operational needs.; Qualifications:; Diploma or Degree in Information Technology, Computer Science, or related field.; Proven experience with Microsoft Fabric, including Pipelines and Dataflows Gen2.; Strong knowledge of Azure Data Factory, data ingestion strategies, and ETL\/ELT best practices.; Familiarity with data modeling, schema design, and metadata logging.; Experience working with business users and system owners to align technical data structures with business requirements.; Solid understanding of data quality assurance, validation techniques, and troubleshooting in production environments.; Excellent communication skills to support user training and documentation.; Ability to work onsite and collaborate across cross-functional teams in a dynamic environment.","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85823545","Role":"Data Engineer","Company":"Innowave Tech Pte Ltd","Location":"Paya Lebar East","Publish_Time":"2025-07-17 01:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85823545","job_desc":"About Innowave Tech Singapore ; Innowave Tech is an Artificial Intelligence (AI) company offering solutions for the Semiconductor and Advanced Manufacturing industry. Utilizing deep industrial domain knowledge, proven experience, and innovation, we provide expert AI solutions and systems to address various industry pain points. ;  Roles & Responsibilities ; We are seeking Data Engineer to establish and lead our data infrastructure. The successful candidate will be responsible for building our data engineering practice from the ground up, implementing robust data systems for industrial AI applications, and establishing best practices that will power our semiconductor manufacturing AI solutions. ;  Your Role and Impact ; As our first Data Engineer, you will have a foundational role in building robust data infrastructure to handle manufacturing data and LLM applications, while establishing secure data practices that power our AI solutions for advanced manufacturing operations. ;  What You\u2019ll Do ; Select and manage on-premises technologies suitable for secure and efficient operations. ; Build robust pipelines to collect, clean, and transform diverse datasets including process data, sensor data, image data, and human annotations. ; Ensure secure, maintainable, and scalable deployment of data infrastructure. ; Define and enforce best practices in data governance, privacy, and access control. ; Collaboration & Deployment. ;  What We\u2019re Looking For ; Educational Background: ; Minimum Poly or Bachelor Degree in Computer Science, Engineering, or a related field. ; * We welcome applications from Singapore Citizens, Permanent Residents (PRs), Malaysians, and local graduates bonded for local employment, in accordance with MoM regulations.;  Technical Expertise: ; 3+ years of experience in data engineering roles, ideally with on-premises or hybrid infrastructure. ; Proven track record of building scalable data systems from ground up in a startup environment. ; Proficiency in Python and\/or Java for data pipeline development. ; Solid experience with ETL frameworks (e.g., Apache Airflow, Dagster) and streaming systems (e.g., Kafka). ; Experience designing and maintaining SQL and NoSQL databases. ; Experience building and operating data lakes and data catalog. ; Familiarity with containerization (Docker), version control (Git), and CI\/CD practices. ;  Soft Skills: ; Excellent communication skills and ability to collaborate with cross-functional technical and non-technical teams. ; Excellent problem-solving and debugging abilities. ; Ability to balance engineering tradeoffs. ;  Bonus Skills: ; Experience with manufacturing data systems, especially SPC, SCADA, and industrial sensor protocols (e.g., OPC UA, MQTT, Modbus). ; Familiarity with AI\/ML pipelines and tools (e.g., MLflow). ; Knowledge in vector databases and LLM data infrastructure. ; Prior experience working in or with regulated industries (e.g., semiconductor, automotive, aerospace). ; What we Offer ; \u2022 A leading role in cutting-edge AI projects within the semiconductor industry. ; \u2022 The opportunity to work with an learn from experts in the field of AI and data science. ; \u2022 A dynamic, innovative, and supportive work environment. ; \u2022 Competitive salary and benefits package. ; \u2022 Career growth opportunities in a fast-paces technology company.","salary":"$5,333 \u2013 $8,000 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85817337","Role":"Data Engineer","Company":"SMRT Trains Ltd","Location":"Katong","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85817337","job_desc":"Job Purpose; The Data Engineer will be part of the team to develop operation & maintenance decision-support tools to enhance train reliability and maintenance efficiency. This position involves designing, developing, and maintaining data pipelines, APIs, and cloud infrastructure for various rail-oriented applications. The ideal candidate will have expertise in data analysis, transformation, ingestion, database design, API development, and preferably, cloud infrastructure setup. Collaborating closely with software engineers, data scientists, and frontend developers, the Data Engineer will contribute to building efficient, scalable, and reliable systems.; Responsibilities; The duties and responsibilities for Data Engineer, are as listed below. The list is not comprehensive and related duties and responsibilities may be assigned from time to time.; Data Engineering & Processing:; Develop and maintain data pipelines for efficient data ingestion and transformation.; Work with structured and unstructured data to ensure optimal storage and retrieval.; Perform data analysis and report on results.; Database Design & Management:; Design and implement relational and NoSQL database schemas for scalability.; Optimize database performance through indexing, partitioning, and query tuning.; Implement data security and compliance best practices.; API Development & Backend Engineering:; Design and develop APIs for data access and application integration.; Implement authentication, authorization, and API security best practices.; Cloud Infrastructure & Deployment (Supporting Role):; Assist in design Azure cloud architectures; Work with IT infrastructure team to set up cloud infrastructure for application hosting, data storage and processing.; Collaboration & Best Practices:; Collaborate with internal stakeholders to understand their business needs.; Work with software engineers, data scientist, frontend developer to understand the data requirement and design architecture of the data platform.; Implement CI\/CD pipelines for automated testing, deployment and monitoring.; Write testable and maintainable code and documentation to deploy to production.; Engage continuously with end-user for feedback and improvements.; Qualifications & Work Experience; Degree in Science, Technology, Engineering or Mathematics (STEM); Previous experience as a data engineer or in a similar role; Data engineering certification is a plus; Knowledge of security best practices in cloud and database management is a plus; Skills; Technical skills include:; Programming and Data processing: MATLAB, Python, SQL, or similar languages.; Databases: My SQL, SQL Server, MongoDB or similar.; Cloud Platforms: Azure; DevOps & CI\/CD: Git Lab CI\/CD, Docker; Generic skills include:; Strong inclination and eager for continual learning and development; Strong team player; Critical thinking and problem-solving skills; Ability to understand and explain complex data and effective interactions with the stakeholders; Ability to think independently and actively propose solutions to the team.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85043774","Role":"Data Engineer","Company":"Tabernacle Pte Ltd","Location":"Central Region","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85043774","job_desc":"Role Overview:; We are looking for a skilled Remote Fabric Data Engineer to support our ongoing data platform migration and transformation efforts. This role focuses on migrating existing Databricks workloads into Microsoft Fabric, implementing efficient transformation logic, and ensuring complete lineage documentation and performance optimization.; Key Responsibilities:; Migrate existing Databricks Silver\/Gold layer SQL transformations into Microsoft Fabric SQL and Dataflows.; Design and implement transformation logic, including deduplication, joins, field mappings, and business rules in Fabric Dataflows.; Develop dimensional data models with surrogate key generation, row-level security (RLS) attributes, and role-based filtering.; Build and maintain metadata lineage pipelines to track data flow across the lifecycle \u2014 from source systems through transformation to target layers.; Tune performance of Fabric solutions by applying partitioning strategies, indexing, and aggregations where applicable.; Produce clear, concise documentation including:; Dataflow structures and logic; Dimensional model definitions; End-to-end lineage path summaries for audit and traceability; Qualifications:; Diploma or Degree in Information Technology, Computer Science, or related field.; Any other related certifications;  Experience and Skills:; Strong experience in Microsoft Fabric (Dataflows, Pipelines, Fabric SQL, and Lakehouses).; Prior hands-on experience migrating Databricks SQL logic or similar workloads into Microsoft environments.; Solid understanding of data modeling, data warehousing, and ETL\/ELT transformations.; Proficiency in performance tuning and working with large-scale data systems using partitioning and indexing.; Experience with metadata management, data lineage, and documentation practices.; Comfortable working in a fully remote setting with distributed teams.; Excellent written communication skills to produce technical documentation and collaborate asynchronously.","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85578684","Role":"DATA ENGINEER","Company":"Continental Technology Solutions Pte Ltd","Location":"Kampong Ubi","Publish_Time":"2025-07-07 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85578684","job_desc":"Roles&Responsibilities:; Design, build, and maintain scalable ETL\/ELT pipelines and data workflows.; Develop and manage job schedules using Control-M to automate complex data workflows.; Collaborate with data analysts, data scientists, and business users to understand data requirements.; Ensure reliable data ingestion from internal and external sources into data lakes and data warehouses.; Monitor job execution, troubleshoot failures, and optimize system performance.; Ensure data quality, consistency, and security across systems.; Document data flows, Control-M job configurations, and operational procedures.; Participate in on-call rotations and incident response as needed.; Requirements:; Bachelor\u2019s degree in Computer Science, Engineering, Information Systems, or related field.; 3+ years of experience in a data engineering or data integration role.; Strong hands-on experience with Control-M (job scheduling, development, troubleshooting, and automation).; Proficiency in SQL and scripting languages (Python, Shell, or PowerShell).; Solid understanding of ETL processes, data pipelines, and workflow orchestration.; Experience with relational databases (e.g., Oracle, SQL Server, PostgreSQL).; Familiarity with data warehouse platforms (e.g., Snowflake, Redshift, BigQuery).; Experience with cloud platforms (AWS, GCP, or Azure) and their data services.; Knowledge of CI\/CD practices and version control systems (Git).","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85653083","Role":"Data Engineer (DSAD)","Company":"SkillsFuture Singapore Agency","Location":"Paya Lebar Air Base","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85653083","job_desc":"SSG is a dynamic and forward-thinking organization dedicated to empowering individuals and shaping the future of Singapore's workforce. As a statutory board under the Ministry of Education, SSG leads the charge in driving the SkillsFuture movement, a national initiative that promotes lifelong learning and skills development. With a strong focus on innovation and collaboration, SSG works closely with employers, training providers, and individuals to create a vibrant ecosystem of learning and growth. By offering a wide range of initiatives, programs, and funding schemes, SSG enables individuals to unlock their full potential, acquire new competencies, and stay ahead in a rapidly changing job market.; Join the Data Strategy & Analytics Division (DSAD) team to grow SSG into a data-mature organization where we use data pervasively and securely to deliver on our business missions:; ; \u2022 Develop and drive SSG\u2019s data strategy, including LOIs, data competency, and maintaining strong links with CIO Office; \u2022 Develop, implement and maintain comprehensive data governance and management framework that complies with WOG requirements Implement Lines of Inquiries; \u2022 Support data management and exploitation; \u2022 Develop MLOps and instil best practices; What you will be working on; As a Data Engineer within DSAD, you will play a pivotal role in managing and optimizing data pipelines, ensuring the seamless flow and integrity of data across our organization. Your expertise in data pipeline management, automation, MLOps, data governance, and infrastructure architecture will contribute significantly to our mission of leveraging data to drive innovation and operational excellence. We are looking for a candidate who embodies our core values of integrity, collaboration, and continuous improvement, and who is passionate about harnessing the power of data to achieve our strategic objectives.; Data Pipeline Management, Automation, and MLOps Proficiency; - Manage and optimize multi-stage data pipelines for various use cases, from data acquisition to consumption; - Automate data preparation and integration tasks using innovative tools and techniques; - Apply MLOps principles to integrate machine learning models efficiently with data pipelines and infrastructure; Data Governance, Cataloging, and Collaboration; - Work closely with data governance teams to ensure data is accurately cataloged and available for governed reuse; - Collaborate with AI engineers to optimize data solutions for machine learning projects, focusing on data flow and accessibility; Infrastructure Architecture and Data Modeling; - Design and manage scalable data infrastructure using cloud services like AWS; - Develop efficient data models and pipelines for large-scale data sets, ensuring data quality and availability; Data Quality Assurance, Documentation, and Continuous Improvement; - Lead initiatives to establish standards for data accuracy and reliability; - Maintain comprehensive documentation on data architectures and management practices; - Stay updated on data engineering advancements, advocating for and implementing improvements; - Facilitate knowledge sharing and technical training sessions to enhance organizational data competency; What we are looking for; Possess the required competencies to execute the job duties proficiently; A minimum of six years of experience in data management disciplines, including data integration, modeling, optimization, and data quality; At least three years of experience in cross-functional team collaboration and supporting data management\/analytics initiatives; Demonstrated ability to work creatively and collaboratively with both business and IT teams; Strong interpersonal skills with the ability to engage and earn the respect of stakeholders at all levels; Confident, energetic self-starter with a commitment to ethics, regulatory compliance, customer service, and business integrity; Highly adaptable and committed to excellence in a dynamic business environment; Successful candidates will be offered a 2-year contract in the first instance and may be considered for an extension or be placed on a permanent tenure.; Candidates are encouraged to sign up for a Careers & Skills Passport (CSP) account and include your CSP public profile in your resume. Please check out www.myskillsfuture.gov.sg for details on the CSP.","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85578382","Role":"DATA ENGINEER","Company":"Continental Technology Solutions Pte Ltd","Location":"Kampong Ubi","Publish_Time":"2025-07-07 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85578382","job_desc":"Responsibilities:; Design, implement, and maintain scalable and reliable data pipelines.; Build and optimize data architectures (data lakes, data warehouses, ETL\/ELT processes).; Collaborate with data scientists, analysts, and other stakeholders to understand data needs.; Develop data models and structures for reporting and analytics.; Ensure data quality, integrity, security, and compliance with governance policies.; Monitor and troubleshoot performance issues with data systems.; Automate data workflows using modern orchestration tools.; Document processes, systems, and data flows.; Requirements:; Bachelor's degree in Computer Science, Engineering, or a related field.; 2+ years of experience in a data engineering or similar role.; Strong SQL skills and experience with relational databases (e.g., PostgreSQL, MySQL).; Proficiency in Python, Scala, or Java for data manipulation and pipeline development.; Experience with ETL\/ELT tools (e.g., Apache Airflow, dbt, Talend).; Familiarity with data warehouse solutions (e.g., Snowflake, Redshift, BigQuery).; Experience with cloud platforms (AWS, GCP, or Azure) and their data services.; Understanding of data modeling, data governance, and best practices.","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85437508","Role":"Data Engineer for URA with 4 years experience (Contract)","Company":"Websparks Pte Ltd","Location":"East Region","Publish_Time":"2025-07-03 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85437508","job_desc":"About Design and Planning Lab (DPLab); Be part of URA\u2019s DPLab, which spearheads URBEX efforts in the experimentation and development of smart planning technologies through Policy-Ops-Tech collaborations. Our teams leverage on their capabilities in data policy, governance, strategy, and engineering, product strategy, business analysis, software engineering, cloud engineering, urban design technologies, data science, AI\/ML, and modelling and simulation to collaborate with planners, architects, and policymakers to create insights and digital solutions for Singapore\u2019s urban planning challenges.; Data Engineering Work:; Support data engineering tasks, including the implementation and enhancement of data pipelines, as well as the rectification of broken pipelines.; Manage the data platform and perform regular software version upgrades across all environments, ensuring thorough testing and detailed documentation.; Support daily operational needs by handling application configuration changes, managing user access request to application, addressing general function queries, and troubleshooting on issues.; Perform source code review and configuration review periodically to ensure code quality and verify that sensitive information, such as secrets, is not hardcoded or embedded in source codes or configuration files.; Periodic patching of Azure Cloud Servers; Develop business processes by engaging stakeholders to understand use cases for building data pipelines, performing data modeling, completing data collection forms, documenting use cases, defining data attributes within various data quality zones, and establishing naming conventions for datasets.; Requirements:; Degree in Computer Science, Engineering, or related disciplines; Experienced in data engineering, including the implementation of data pipelines, development of data models and schemas, and pipeline monitoring and management.; Experienced in architecting, designing, and developing data platform.; Experience with:; \u25cb Python, PySpark, or similar programming languages; \u25cb Python packages for data manipulation and analysis (e.g. Pandas, GeoPandas, Shapely); \u25cb Database design and management (e.g. PostgreSQL, MS SQL, Oracle, Geodatabase); \u25cb SQL programming (e.g. writing complex queries, optimizing performance, data manipulation); \u25cb Scripting and version control (e.g. Bash, PowerShell, Git); \u25cb ETL (Extract, Transform, Load) processes; \u25cb Technologies such as JupyterHub, RStudio, PowerBI; \u25cb CI\/CD tools such as Jenkins, GitLab, YAML; \u25cb GIS technology (e.g. ArcGIS Server, PostGIS); \u25cb API development and SFTP for secure data transfer; \u25cb Cloud Platforms (e.g. Microsoft Azure, AWS); \u25cb Cloud Technologies (e.g. Azure Data Factory, Databricks, Azure Functions, Azure Key Vault, AWS Lambda); \u25cb Containerization technologies (e.g. Docker, Kubernetes); Able to work well with a team and be willing to learn.; Effective presentation, communication and writing skills.; Added advantage with the following:; Infrastructure-as-code Tools \u2013 Terraform, CloudFormation; Log Management tools (e.g. Azure Monitor, AWS CloudWatch, Splunk); Agile Management Tools \u2013 Confluence, Jira, Kanban board","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85172239","Role":"Lead Big Data Engineer","Company":"PLOY ASIA PTE. LTD.","Location":"Singapore","Publish_Time":"2025-06-25 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85172239","job_desc":"What's on offer:; Location: Singapore; Client: End client user environment; ; Job Summary:; We are seeking a highly skilled and motivated Lead Big Data Engineer to join our data team. The ideal candidate will play a key role in designing, developing, and maintaining scalable big data solutions while providing technical leadership. This role will also support strategic Data Governance initiatives, ensuring data integrity, privacy, and accessibility across the organization.; Key Responsibilities:; Design, implement, and optimize robust data pipelines and ETL\/ELT workflows using SQL and Python.; Lead architecture discussions, including the creation and review of Entity Relationship Diagrams (ERDs) and overall system design.; Collaborate closely with Data Engineers, Analysts, and cross-functional engineering teams to meet evolving data needs.; Deploy and manage infrastructure using Terraform and other Infrastructure-as-Code (IaC) tools.; Develop and maintain CI\/CD pipelines for deploying data applications and services.; Leverage strong experience in AWS services (e.g., S3, Glue, Lambda, RDS, Lake Formation) to support scalable and secure cloud-based data platforms.; Handle both batch and real-time data processing effectively.; Apply best practices in data modeling and support data privacy and data protection initiatives.; Implement and manage data encryption and hashing techniques to secure sensitive information.; Ensure adherence to software engineering best practices including version control, automated testing, and deployment standards.; Lead performance tuning and troubleshooting for data applications and platforms.; ; Required Skills & Qualifications:; Strong proficiency in SQL for data modeling, querying, and transformation.; Advanced Python development skills with an emphasis on data engineering use cases.; Hands-on experience with Terraform for cloud infrastructure provisioning.; Proficiency with CI\/CD tools, particularly GitHub Actions.; Deep expertise in AWS cloud architecture and services.; Demonstrated ability to create and evaluate ERDs and contribute to architectural decisions.; Strong communication and leadership skills with experience mentoring engineering teams.; ; Preferred Skills:; Familiar AI\/ML RAG (Retrieval-Augmented Generation) MCP (Multi-Channel Processing) concepts; Understanding of data processing libraries (Pandas, NumPy); Familiarity with cloud platforms (AWS, GCP, or Azure); Knowledge of containerisation (Docker) and orchestration tools; Experience with CI\/CD pipelines; Basic understanding of data structures and algorithms","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85702523","Role":"Senior Data Engineer","Company":"Singapore Telecommunications Limited","Location":"Singapore","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85702523","job_desc":"An empowering career at Singtel begins with a Hello. Our purpose, to Empower Every Generation, connects people to the possibilities they need to excel. Every \"hello\" at Singtel opens doors to new initiatives, growth, and BIG possibilities that takes your career to new heights. So, when you say hello to us, you are really empowered to say\u2026\u201cHello BIG Possibilities\u201d.; Be a Part of Something BIG!  ; Design, build, and maintain scalable data pipelines and processing systems that power analytics and AI use cases across a hybrid data platform; Contribute to design conversation of AIDA\u2019s new data and AI platform; Collaborate with platform, analytics, and governance teams to deliver high-quality, secure, and well-documented data assets; Lead team of data engineers to ensure timely availability of accurate, well-documented data for use in AI use case; Make An Impact By; Design and implement batch and streaming data ingestion pipelines from diverse sources (e.g., files, APIs, Kafka, databases); Develop real-time and near-real-time data workflows using tools like Apache Flink, Kafka Streams; Optimize performance for high-volume and high-velocity datasets; Implement data quality checks and automatic monitoring system to ensure consistently accurate and available data; Design and manage storage solutions such as Microsoft Fabric, Delta Lake, and Databricks; Apply best practices for schema design, partitioning, and data lifecycle management; Support data discovery and cataloguing in coordination with governance tools; Work with data scientists, analysts, and business users to understand data needs and translate them into technical solutions; Partner with DevSecOps and platform engineers to automate deployment and orchestration of data pipelines; Document data flows, transformations, and quality checks in accordance with governance standard; Skills to Succeed; Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, or a related field; 5 years of experience in data engineering; 1 year in a senior technical role delivering data engineering projects; Deep expertise in Spark, Databricks, and data processing frameworks; Strong knowledge of streaming technologies such as Apache Kafka, Apache Flink, or Azure Event Hub; Experience working with data lake and\/or lakehouse architectures such as Hadoop, Delta Lake, Iceberg and Microsoft OneLake; Proficient in Python and SQL; Familiar with workflow orchestration (e.g., Apache Airflow) and CI\/CD principles; Analytical mindset with a focus on data quality, performance, and maintainability; Able to work independently and collaboratively in a dynamic environment; Strong communication and documentation skills to support cross-functional collaboration; Knowledge of data types across network and IT in telco environment; Rewards that Go Beyond; Full suite of health and wellness benefits  ; Ongoing training and development programs  ; Internal mobility opportunities; Your Career Growth Starts Here. Apply Now!; We are committed to a safe and healthy environment for our employees & customers and will require all prospective employees to be fully vaccinated.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85783909","Role":"Data Engineer (Python\/OpenSearch)","Company":"ASTEK Singapore Innovation Technology Pte. Ltd.","Location":"Central Region","Publish_Time":"2025-07-15 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85783909","job_desc":"Job Title: Data Engineer; Location: Singapore, CBD; Employment Type: Full-time Permanent; We are looking for a Data Engineer to join our team and support the development of a standardized Data Toolkit. This platform will streamline data ingestion and observability efforts across the organization. You will also assist in migrating data and systems from legacy tools to this new framework.; Key Responsibilities; Design, build, and test components of the Data Toolkit.; Integrate data systems to ensure consistency and efficiency in data workflows.; Support the migration of existing data and processes from legacy systems.; Collaborate with engineering and product teams to ensure seamless adoption.; Requirements; Minimum 3 years of full time working experience.; Proficiency in Python.; Experience with search platforms such as OpenSearch, Elasticsearch, or Solr.; Strong software development, analytical, and problem-solving skills.; Knowledge of SQL, ETL\/ELT, and data pipeline architecture will be advantageous.; Experience with CI\/CD, Terraform, and AWS cloud services is a plus.; Good communication skills and the ability to work well in a team.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85167337","Role":"Contract Data Engineer (2-year contract)","Company":"Public Service Division","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85167337","job_desc":"[What the role is]; [What the role is]; The role of the Data Engineer is to collaborate with the existing team of data scientists, data engineers and analysts to create data tools, develop data ingestion and processing pipelines, ensuring optimized data processing, and ensuring that data systems meet STB's business requirements. The role requires working closely with the data science team to set up and deploying data pipelines to support machine learning models and analytics scripts, developing data integrations, assembling complex datasets and implementing process improvements. The Data Engineer plays a key role in enhancing data reliability and quality while ensuring scalable business processes and supporting the team's data-related initiatives.; [What you will be working on]; [What you will be working on]; 1. Project Management; a) Project manage and work closely with vendors and internal stakeholders to deliver on data engineering related implementations ensuring that deliverables and objectives are met within agreed scope and timelines.; b) Collaborate with cross-functional teams, including data scientists, data engineers, DevOps engineers, product managers, business analysts and business stakeholders, to integrate and deploy models into current analytics platforms and production systems.; c) Plan, execute and monitor project milestones and ensure timely update to management on project progress and issues.;   2. Application of Engineering Disciplines in Support of Strategic Business Objectives; a) Prepare, process, cleanse and verify the integrity of data collected for analysis.; b) Design, develop and implement self-managed data processing and compilation pipelines related to key enterprise data domains so that data compilation business logic can be managed and maintained in-house to retain agility in responding to changing operational needs.; c) To review the design and implementation of data pipelines developed by the vendor to ensure that they meet the operational requirements of STB\u2019s business and are integrated back to the self-managed data compilation pipelines for a seamless data processing and compilation process.; d) Work closely with vendors and internal stakeholders to project manage and coordinate Data Science & Analytics's (DS&A) data ingestion and data processing pipelines across platforms which can include mobile apps, SaaS platforms, on-premise and partner systems; e) Help architect DS&A\u2019s data integrations and data processing flows between external \/ 3rd party data sources, AWS Cloud datawarehouses (e.g. Redshift, RDS) and internal on-premise systems for workloads at scale; f) Provide guidance to internal teams on best practices for Cloud data integrations; g) Identify, design and implement internal process improvements: automating manual processes, optimising data delivery, re-designing infrastructure for greater scalability, etc.; h) Develop monitoring toolkits to ensure that integration is executed successfully and alerts where integrations have failed; i) Implement best practice DataOps processes to ensure continuous integration, deployment and governance of our data pipelines across the entire data lifecycle from data preparation to reporting.;   3. Data Integration and Data Management; a) Collaborate with current team to review the existing data integration processes and make improvements to the current data processing pipelines.; b) Work with data and agency partners to assemble large, complex datasets that meet functional and non-functional business requirements.; c) Provide inputs to the design and development of an integrated data model to allow analysis across multiple structured and unstructured datasets.; d) Recommend different ways to constantly improve data reliability and quality, including helping review and enhance the existing data collection procedures to include data for building analytics models relevant for industry transformation; e) Analyse and assess the effectiveness and accuracy of data sources (e.g., datasets received from stakeholders) and ensure that they meet STB's Data Quality standards.; [What we are looking for]; Strong project management, planning, time management and organisational skills.; Experience supporting and working with cross-functional teams in a dynamic environment.; Experienced data pipeline builder and data wrangler who enjoys optimising data systems and building them from ground up.; Experience in using Qlik Sense and AWS services (e.g., SageMaker, Athena, RDS, ECR, ECS, EMR, Lambda, Redis) will be advantageous.; The following certifications would be advantageous:; Certified AWS Cloud Architect \/ Data Engineer \/ DevOps Engineer; Certified Qlik Sense Data Architect; Degree from a recognised university in a quantitative or engineering discipline: Computer Science, Computer Engineering, Informatics \/ Information Systems, Applied Mathematics or Statistics.; At least 5 years of work experience in a related field with demonstrable skills in developing, deploying and maintaining data workflows.; Proven track record in managing internal and external stakeholders and delivering on objectives according to project timelines and successfully deploying at least 1 medium to large scale analytics system.; Good command of written and spoken English with good presentation and communication skills with ability to express complex ideas, data \/ concepts and outcomes of analysis clearly to business audiences.; Strong analytical skills with a good eye for detail and possess an aptitude\/experience in solving engineering problems to produce quality deliverables.; Ability to integrate and synthesise research and data across multiple sources to derive meaningful conclusions.; Experience working with structured and unstructured datasets is essential.; Proficient in statistical programming tools (e.g., R, Python), and database scripting languages (e.g., SQL - DQL, DML, DDL); Experience with DataOps and deploying models and data workflows through DevOps process will be advantageous; [What we are looking for]","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85783762","Role":"Collibra Platform & Metadata Engineer","Company":"Goldtech Resources Pte Ltd","Location":"Singapore","Publish_Time":"2025-07-15 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85783762","job_desc":"We are seeking a highly skilled and detail-oriented Collibra Platform & Metadata Engineer to lead the design, configuration and integration of metadata governance capabilities within our enterprise data environment. This role will be responsible for administering the Collibra platform, managing metadata lifecycle processes, supporting regulatory reporting initiatives and enabling advanced lineage and data quality linkages.; Key Responsibilities:; Metadata Governance & Lifecycle; Manage the full lifecycle of Metadata assets in Collibra, including definitions, certifications, ownership and stewardship.; Oversee and maintain the enterprise business glossary, ensuring alignment with data standards and compliance frameworks.; Data Lineage & KDE Traceability; Build and maintain comprehensive business and technical lineage in Collibra.; Enable traceability of Key Data Elements (KDEs) across data systems and reports, supporting regulatory needs.; Collibra Administration & Configuration; Configure Collibra assets, domains, user roles, responsibilities and workflows.; Administer platform integrations and ensure optimal performance and availability.; Manage access control, asset lifecycles and approval workflows.; Metadata Integration & Automation; Develop metadata ingestion pipelines using APIs and data connectors.; Integrate metadata from tools such as ETL platforms, data warehouses, BI tools (Power BI, Tableau) and DQ tools (Alteryx, Informatica).; Workflow Development & Advanced Capabilities; Design and implement custom workflows for glossary, lineage, and KDE processes.; Automate metadata processes and enhance Collibra usability through term linking, data quality rule associations and embedded metadata strategies.; Stakeholder Engagement & Enablement; Work closely with data stewards, business users, and compliance teams to align metadata governance with enterprise policies.; Provide user onboarding, training and technical documentation to support adoption.; Requirements:; Bachelor\u2019s degree in Computer Science, Data Management or related field.; Certified in Collibra Ranger (mandatory).; 4\u20138 years of experience in data governance or metadata management roles.; Minimum 2\u20133 years of hands-on experience with Collibra, including platform configuration and API-based integration.; Strong knowledge of metadata, business glossary, data lineage, and data governance principles.; Proficiency with scripting and integration tools (e.g., Python, SQL, REST APIs).; Familiar with regulatory requirements (e.g., BCBS 239, MAS, GDPR) and data quality frameworks.; Preferred Qualifications:; Collibra Solution Architect certification is a plus.; Experience in financial services, regulatory reporting or enterprise data governance programs.; Familiarity with cloud platforms (Azure, AWS) and data modeling.; Excellent communication and stakeholder engagement skills.; Please send your updated resume in MS Word format to resume@goldtechrs.com along with:; Education Level; Working experiences; Each employment background; Reason for leaving each employment; Last drawn salary; Expected salary; Date of availability","salary":"","work_type":"Kontrak\/Temporer, Full time","country":"singapore"}
{"Job_ID":"85293565","Role":"BIG DATA PLATFORM ENGINEER","Company":"Matrix Process Automation Pte Ltd","Location":"Central Region","Publish_Time":"2025-07-01 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85293565","job_desc":"Operating Global Data Platform components (VM Servers, Kubernetes, Kafka) and applications (Apache stack, Collibra, Dataiku and similar).; Implement automation of infrastructure, security components, and Continuous Integration & Continuous Delivery for optimal execution of data pipelines (ELT\/ETL).; You have 5+ years of experience in building or designing large-scale, fault-tolerant, distributed systems, (for example: data lakes, delta lakes, data meshes, data lake houses, data platforms, data streaming solutions\u2026); In-depth knowledge and experience in one or more large scale distributed technologies including but not limited to: Hadoop ecosystem, Kafka, Kubernetes, Spark; Migration experience of storage technologies (e.g. HDFS to S3 Object Storage); Integration of streaming and file based data ingestion \/ consumption (Kafka, Control M, AWA); Experience in DevOps, data pipeline development, and automation using Jenkins and Octopus (optional: Ansible, Chef, XL Release, and XL Deploy); Expert in Python and Java or another static language like Scala\/R, Linux\/Unix scripting, Jinja templates, puppet scripts, firewall config rules setup; VM setup and scaling (pods), K8S scaling, managing Docker with Harbor, pushing Images through CI\/CD","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85617821","Role":"Data Platform Engineer","Company":"International Baccalaureate Organization","Location":"Singapore","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85617821","job_desc":"The Data Platform Engineer will be responsible for the design, build, maintenance, security and performance of the data analytics platform, serving both Digital Office stakeholders and lines of business.  The work will range from larger technology delivery initiatives, working on a shared Digital Office Data Analytics product backlog, providing maintenance support, and ensuring the smooth operation of live applications and platforms. This role requires hands-on development experience implementing new features and functionalities within the platform.; The International Baccalaureate provides world-class educational services to over 5500 schools across 159 countries. A career at IB is not just a job; it\u2019s an opportunity to work with an innovative world leader of education services and contribute to our 50-year mission of creating a better and more peaceful world. Apply now to join our global organization where we empower our employees to thrive and make a difference.; About the Job; Technical Design ; Analyze business requirements, understand underlying data sources, transformation requirements, data mapping, data modelling and metadata for reporting solutions.; Translate these business needs to a simple, scalable and secure technical design.; Design EDW, data mart layers with appropriate enterprise considerations like architectural fit, performance, flexibility, maintainability, automation etc.; Technical Build ; Build infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources, applications and platforms.; Play an active role in the development scrum team, delivering features with appropriate quality and velocity in the product backlog according to IB\u2019s DevOps practices including refining of user stories, acceptance criteria, write code, conduct unit testing, documentation and troubleshooting.; Maintenance & continuous improvement; Perform ITIL Incident, Problem, and Change Management practices in accordance to SLAs and follow processes.; Identify key problem areas within the application and implement improvements. Evaluate and improve existing data analytics systems.; Data Expertise ; Understand the IB\u2019s main business processes and how it relates to data that is generated or captured.; Understand associated data flows and dependencies between different enterprise systems.; About You; BSc\/BA in Computer Science, Engineering or relevant field.; Able to integrate multiple data sources & user-end applications with databases into one system. (to store the data and its retrieval from the databases).; Solid experience in designing and implementing robust data pipelines and ETL\/ELT framework.; Proven experience as a data warehouse architect & developer, including full implementation of data warehousing solution.; Experience in data engineering solutions built on modern data lake or Lakehouse architectures, including Delta Lake or equivalent frameworks e.g. Microsoft Fabric.; In-depth understanding of database management systems, online analytical processing (OLAP), SQL queries (Azure SQL DB).; Expertise with Azure Resource Management and templates is an added advantage.; Exposure to cloud technologies (MS Azure, AWS) & desire to learn and deliver new things on a needs-basis. (big data, BI, data science, etc.).; Strong expertise in data warehouse design methodologies and technologies, data modelling (Data Vault modelling methodology experience is preferable), data quality and metadata.; Ability to work within a fast-paced environment to meet deadlines, multitask and cope with multiple activities.; In addition to your salary, we offer an attractive range of benefits including: ; 20% employer's CPF contribution ; S$1,200 yearly flexible credits; 20 Days annual leave, plus public holidays, with the choice to buy or sell up to 3 days additional annual leave\u202fusing flexible credits; Life assurance 2x annual salary ; Flexible working hours due to nature of work; Organisation sponsored learning opportunities for professional development; Corporate passes to Singapore Zoo, River Wonders and Gardens By The Bay","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85156590","Role":"Senior Data Engineer (Networks)","Company":"Singapore Telecommunications Limited","Location":"Singapore","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85156590","job_desc":"At Singtel, we believe in the strength of a vibrant, diverse and inclusive workforce where backgrounds, perspectives and life experiences of our people help us innovate and create strong connections with our customers. We strive to ensure all our people practices are non-discriminatory and provide a fair, performance-based work culture that is diverse, inclusive and collaborative. ; Join us and experience what it\u2019s like to be with an Employer of Choice*. Together, let\u2019s create a brighter digital future for all. *Awarded at the HR Fest Awards 2020.; Make an Impact by:; Develop new and improve existing data pipeline on Big Data platform (Hadoop, mapR or equivalent).; Build new and enhance existing data application for streaming and batch datasets.; Work on Apache Airflow on data pipeline, Python, Spark, PySpark, Scala, Java, SQL, etc for data application open sources technologies.; Responsible in developing frontend dashboards and integration to back end. Using frontend and backend API Frameworks such as React, Angular Django, FastAPI, Springboot.; Perform R&D and conduct PoC (proof-of-concept) for new data solution.; Perform metadata and data management, data security.; Drive optimization, testing and tooling to improve data quality & efficiency in data lake and streaming platform.; Lead and monitor the performance of Junior Data Engineer and providing them with practical guidance, solution validation and implementation.; Lead and manage DevOps, DataOps and Streaming Operations (or equivalent) in Data Engineering.; Design high level & detailed design to ensure that the solution delivers to the business needs and align to the data & analytics architecture principles and roadmap.; Collaborate with different stakeholders from business, technical, project management and operation to design and implement the solution.; Ability to lead troubleshooting efforts for complex design and eliminate application issue faced by the project and operation team.; Skills for Success:; Bachelor degree in Computer Science, Math, Data Analytics or related field with at least 5 years of hands-on development experiences.; Knowledge in Big Data Platform such as Hadoop, mapR, Cloudera, HPE, etc.; Hands-on experience in Programming language including Python, PysSpark, SQL, noSQL, kSQL, prefer to have experience in Big Data application and Linux shell scripting.; Experience in Data API exposure (Spring Boot, Flask or equivalent) and web development.; Experience in Open Source like Apache Airflow, Zeppelin Notebook for Data Exploratory Analysis, et; Rewards that Go Beyond:; Hybrid work arrangements; Fulll suite of health and wellness benefits ; Ongoing training and development programs; Internal mobility opportunities;  Are you ready to say hello to BIG Possibilities; Take the leap with Singtel to unlock new opportunities and accelerate your growth. Apply now and start your empowering career!","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85577454","Role":"Big Data Developer","Company":"KG Sowers Group Pte Ltd","Location":"North Region","Publish_Time":"2025-07-08 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85577454","job_desc":"Roles and Responsibilites:; Developing and optimising ETL (Extract, Transform, Load) processes to ingest and transform large volumes of data from multiple sources.; Must have experience in investment banking, payment and transaction banking domains.; Developing and deploying data processing applications using Big Data frameworks such as Hadoop, Spark, Kafka, or similar technologies.; Proficiency in programming languages and scripting (e.g., Java, Scala, Python, SQL) for data processing and analysis.; Experience with cloud platforms and services for Big Data (e.g., AWS, Azure, Google Cloud); Requirements:; Primary Skills:; Designing, building, and maintaining systems that handle large volumes of data, enabling businesses to extract valuable insights and make data-driven decisions.; Creating scalable and efficient data pipelines, implementing data models, and integrating various data sources.; Developing and deploying data processing applications using Big Data frameworks such as Hadoop, Spark, Kafka; Write efficient and optimised code in programming languages like Java, Scala, Python to manipulate and analyse data; Creating scalable and efficient data pipelines, implementing data models, and integrating diverse data sources to enable businesses to extract valuable insights; Secondary Skills:; Designing, developing, and implementing scalable and efficient data processing pipelines using Big Data technologies.; Implementing a Kafka-based pipeline to feed event-driven data into a dynamic pricing model, enabling real-time pricing adjustments based on market conditions and customer; Conduct testing and validation of data pipelines and analytical solutions to ensure accuracy, reliability, and performance.; Strong experience in Spring Boot and microservices architecture.; Strong experience in distributed computing principles and Big Data ecosystem components (e.g., Hadoop, Spark, Hive, HBase).; More than 8 years of working experience in IT industry; More than 5 years of relevant experience","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"85673927","Role":"Data Architect - Technology (SAS VI)","Company":"UNIVERSAL PROCUREMENT SYSTEMS PTE LTD","Location":"Singapore","Publish_Time":"2025-07-11 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85673927","job_desc":"We are looking for a seasoned Data Architect \/ Data Management Lead with extensive experience in designing data solutions for fraud analytics , investigative platforms , or intelligence and case management systems . The successful candidate will oversee the architecture, development, and implementation of integrated data pipelines and analytics frameworks within SAS-based environments , particularly SAS Viya . This is a hands-on leadership role requiring both technical depth and strong stakeholder coordination across business and technology teams.; Responsibilities:; Partner with business analysts to understand and shape data requirements for fraud or investigative systems.; Architect end-to-end data strategies, from source acquisition and cleansing to storage, preparation, and analytics delivery.; Convert functional needs into technical deliverables across ETL, engineering, and reporting layers.; Design and manage real-time and batch ingestion workflows into SAS platforms or large-scale data lakes.; Build and maintain robust data pipelines, orchestration layers, and visualization components using SAS Viya , DS2 , Python , and other tools.; Coordinate testing, integration, and support activities, including UAT and post-deployment maintenance.; Lead documentation efforts and contribute to overall data governance, metadata, and quality frameworks.; Troubleshoot complex data issues and track project progress against delivery milestones.; Required Experience & Skills:; Minimum 10 years of experience in data architecture, analytics platforms, or BI\/data warehouse implementations.; Delivered at least 5 full-scale projects involving fraud detection, surveillance systems, or case\/investigation platforms.; Strong hands-on capabilities in:; SAS Viya , SAS DS2 , and SQL; Python , Spark , JSON , XML; Linux , job orchestration tools , and real-time technologies like Kafka or SAS ESP; Postman , SOAPUI , REST APIs , and CI\/CD frameworks ( DevOps \/ DataOps ); Familiar with:; Data modeling, source-to-target mapping, real-time processing design; Metadata and data lineage tools, orchestration frameworks; Experience with SAS Intelligent Decisioning, RTDM, PEGA, or similar decision management tools is advantageous.; Prior involvement in public sector, government, or regulatory environments is preferred.; Strong communication and stakeholder alignment skills; capable of leading technical teams.; Bachelor\u2019s degree in a relevant discipline such as Computer Science, Information Technology, or Statistics","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84822778","Role":"G08 - Data Engineer","Company":"FPT Asia Pacific Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84822778","job_desc":"We are looking for experienced data engineers to join our team who will be responsible for:; Data Engineering and Platform Integration; Design, develop, and maintain data pipelines and ETL processes using AWS services (Glue, Athena, S3, RDS); Work with data virtualisation tools like Denodo and develop VQL queries; Ingest and process data from various internal and external data sources; Perform data extraction, cleaning, transformation, and loading operations; Implement automated data collection processes including API integrations when necessary; Data Architecture; Design and implement data models (conceptual, logical, and physical) using tools like ER Studio; Develop and maintain data warehouses, data lakes, and operational data stores; Develop and maintain data blueprints; Create data marts and analytical views to support business intelligence needs using Denodo, RDS; Implement master data management practices and data governance standards; Technical Architecture and Integration; Ensure seamless integration between various data systems and applications; Implement data security and compliance requirements; Design scalable solutions for data integration and consolidation; Development and Analytics; Develop Python scripts in AWS Glue for data processing and automation; Write efficient VQL\/SQL queries and stored procedures; Design and develop RESTful APIs using modern frameworks and best practices for data services; Work with AWS Sagemaker for machine learning model deployment and integration; Manage and optimise database performance, including indexing, query tuning, and maintenance; Work in an Agile environment and participate in sprint planning, daily stand-ups, and retrospectives; Implement and maintain CI\/CD pipelines for automated testing and deployment; Participate in peer code reviews and pair programming sessions; Documentation and Best Practices; Create and maintain technical documentation for data models and systems; Follow industry-standard coding practices, version control, and change management procedures; Stakeholder Collaboration; Partner with cross-functional teams on data engineering initiatives; Gather requirements, conduct technical discussions, implement solutions, and perform testing; Collaborate with Product Managers, Business Analysts, Data Analysts, Solution Architects, UX Designers to build scalable, data-driven products; Provide technical guidance and support for data-related queries; Qualifications and Experience:; At least 3 years of experience in data engineering or similar role; Strong proficiency in Python, VQL, SQL; Experience with AWS services (Glue, Athena, S3, RDS, Sagemaker); Knowledge of data virtualisation concepts and tools (preferably Denodo); Experience with BI tools (preferably Tableau, Power BI); Understanding of data modelling and database design principles; Familiarity with data governance and master data management concepts; Experience with version control systems (Gitlab) and CI\/CD pipelines; Experience working in Agile environments with iterative development practices; Strong problem-solving skills and attention to detail; Excellent communication skills and ability to work in a team environment; Knowledge of AI technologies (AWS Bedrock, Azure AI, LLMs) would be advantageous","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85507921","Role":"Data Engineer","Company":"NOVADE SOLUTIONS PTE LTD","Location":"Singapore","Publish_Time":"2025-06-21 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85507921","job_desc":"Headquartered in Singapore, Novade is a leading field management platform designed to digitalize processes on construction and industrial sites. We help clients manage progress, quality, and safety with our cutting-edge solutions, empowering teams to achieve better performance and compliance. With millions of records processed daily, Novade transforms how teams collaborate and leverage data to drive success.; About Our Data Team; Our Data Team is at the forefront of innovation, with missions including:; Developing scalable data pipelines that process millions of records, offering powerful, customizable analytics to help clients improve their performance; Training predictive models to detect risks; Developing Generative AI use cases to push boundaries in digital transformation; Managing internal analytics to enable data-driven decisions for our teams and delivering top-tier consulting to our clients; Key Responsibilities; Design, develop, and maintain data pipelines to ensure efficient data flow and high data quality; Implement scalable data models and visualizations for our clients; Perform data analysis on client and business data; Communicate findings and insights effectively through presentations and reports; Conduct feature engineering for predictive analytics; Create beautiful and efficient dashboards to visualize data and derive actionable insights; Occasionally, train machine learning models once other tasks have been mastered; What You Need for This Position; Technical skills:; Proficiency in Python (including PySpark, Pandas, NumPy); Strong SQL skills; Experience with building ETL pipelines; Experience with BI tools, preferably Power BI; Familiarity with machine learning techniques; Strong analytical skills with an understanding of statistical principles; Knowledge of Databricks or Apache Airflow is a plus; Computer science skills are a plus; Soft skills:; Autonomy and initiative \u2014 you know when to dive deep and when to seek help; Reliability, particularly in managing production pipelines and reacting swiftly to issues; Team spirit and adaptability; Eagerness to learn and grow; Communication and presentation abilities; Experience (internship) with SaaS platforms is a plus; What You Will Get With Us; Learn and contribute to the development of a state-of-the-art, scalable data platform; Be part of a fun and rapidly growing company making waves in the industry; Work alongside a dynamic team of young but experienced professionals; Experience a culture of respect, collaboration, and innovation; Make a tangible impact\u2014join us in revolutionizing the digital landscape of the construction industry; Gain access to a unique dataset within the construction sector, unlocking invaluable learning opportunities; If you\u2019re passionate about data engineering, eager to work on impactful projects, and ready to learn from a team of experts, we\u2019d love to hear from you!","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85702527","Role":"Senior Data & Integration Architect","Company":"Singapore Telecommunications Limited","Location":"Singapore","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85702527","job_desc":"An empowering career at Singtel begins with a Hello. Our purpose, to Empower Every Generation, connects people to the possibilities they need to excel. Every \"hello\" at Singtel opens doors to new initiatives, growth, and BIG possibilities that takes your career to new heights. So, when you say hello to us, you are really empowered to say\u2026\u201cHello BIG Possibilities\u201d.; Be a Part of Something BIG!  ; The Senior Data & Integration Architect plays a critical role in designing and implementing the data and integration layer of Singtel\u2019s next-generation AI platform. This role focuses on orchestrating secure, scalable, and interoperable data architectures and API integration frameworks that support advanced AI and ML workloads across the enterprise.; You will work closely with the AI architecture, security, platform, and business teams to ensure seamless data movement, governance alignment, and real-time system interoperability for serving as the bridge between distributed data systems, cloud services, and AI-enabled applications.; Make An Impact By; Design, build and implement enterprise-wide data and API integration frameworks to support AI\/ML platforms across hybrid cloud and on-premise environments; Work with system owners and data domain leads to design and deliver scalable end-to-end data flows across operational, analytical, and AI systems; Define and develop secure, reusable API interfaces (REST, GraphQL, event-driven) and data interface (batch or streaming) that enable seamless interoperability between internal systems and AI services; Oversee and evaluate new data integration approaches and pipeline designs to ensure efficient, secure, and scalable data flow between data sources and AI platforms.; Collaborate with Security and Data Governance teams to ensure integration designs align with compliance, privacy, and policy requirements (e.g., PDPA, data classification); Design and enable data access strategies for LLMs and agent-based workflows, ensuring context-rich, real-time connectivity to distributed enterprise systems; Implement and maintain integration middleware and tooling (e.g. Kafka, Azure ML\/Foundry, Databricks, etc) to support data orchestration, synchronization, and reliability; Contribute integration expertise to data or AI experimentation, PoCs, and platform upgrades, ensuring architectural consistency and production-readiness; Define and enforce data and integration design standards, focusing on scalability, resilience, observability, and system decoupling; Work closely with business units, IT, and Networks to align integration plans with enterprise priorities and ensure successful data exchange across functional boundaries; Skills to Succee; Bachelor\u2019s in Computer Science, Engineering, Data, AI\/ML, or related field.; At least 3 years of experience in data architecture, system and API integration engineering.; Demonstrated experience in designing integration flows for large-scale, real-time systems across cloud and legacy environments.; Experience in designing and implementing data integration frameworks across hybrid cloud and on-premise environments, including building scalable and secure data pipelines for AI\/ML platforms.; Proficient in data integration design, with solid knowledge of data pipelines, data lakes, data warehouses, and data lakehouse architectures.; Good knowledge of modern data orchestration and middleware tools such as Apache Kafka, Azure Data Factory, Databricks, Airflow, and experience in managing data flow between operational, analytical, and AI environments.; Working knowledge of data security, data protection and data quality management including implementation of encryption, RBAC, masking, and alignment with regulatory frameworks such as PDPA and internal data classification policies.; Proven experience integrating data systems with AI\/ML workflows, including model training, serving, monitoring, and enabling context-aware access for LLMs and agent-based automation.; Effective collaboration skills to work across data, platform, machine learning engineering and API integration teams, with a clear communication style to bridge business and technical stakeholders; Good internal (IT, Networks, business) and external (suppliers, government) stakeholders management skills; Strong technical writing and presentation skills, with the ability to communicate complex concepts clearly to both technical and non-technical stakeholders.; Proactive and fast learner with a strong drive to stay current on emerging technologies and industry trends.; Rewards that Go Beyond; Full suite of health and wellness benefits  ; Ongoing training and development programs  ; Internal mobility opportunities; Your Career Growth Starts Here. Apply Now!; We are committed to a safe and healthy environment for our employees & customers and will require all prospective employees to be fully vaccinated.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85840488","Role":"Sr. Data Engineer","Company":"VISA WORLDWIDE PTE. LIMITED","Location":"Singapore","Publish_Time":"2025-07-17 10:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85840488","job_desc":"Company Description; Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose \u2013 to uplift everyone, everywhere by being the best way to pay and be paid.; Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa.; Job Description; Visa\u2019s Technology Organization is a community of problem solvers and innovators reshaping the future of commerce. We operate the world\u2019s most sophisticated processing networks, capable of handling more than 65k secure transactions a second across 80M merchants, 15k Financial Institutions, and billions of everyday people. You\u2019ll work on complex distributed systems and solve massive scale problems centered on new payment flows, business and data solutions, cybersecurity, and B2C platforms.; In addition, Value Added Services (VAS) - VAS Digital Marketing is a key growth strategy for Visa globally, aimed at diversifying Visa\u2019s revenue with products and solutions that differentiate its network and deliver valuable solutions across other networks.; ; The Opportunity:; We are developing and executing a shared strategic vision for Digital Marketing platforms and products that enable Visa to be the world-leading data-driven payments company. As a Senior Data Engineer, you will be part of a world-class team of Engineers to define, drive and execute on this vision. We are looking for a self-motivated, versatile and energetic individual with software engineering skills and expertise with Java, Big data & Web technologies, who embraces solving complex challenges on a global scale. The candidate will be extensively involved in hands-on activities including POCs, design, development, testing, and managing applications globally used by Visa cardholders. Candidate must be flexible and willing to switch tasks based on team's needs.; ; You will use your Java skills and experience with various technologies to design, develop, test, and deploy high-quality code that meets stringent business, security, and resiliency requirements. You will collaborate with other teams, vendors, and stakeholders to ensure the smooth delivery and operation of the application. You will have the opportunity to learn and apply new technologies and frameworks, such as AI and generative AI, to enhance the functionality and performance of the application.; Primary responsibilities will include:; Design, develop, test, document, and implement new applications and enhance existing systems to ensure high performance and reliability.; Write secure, maintainable, and efficient code that adheres to Java\/J2EE best practices, organizational and security standards.; Create and maintain comprehensive technical documentation, including design changes and architectural decisions, using Wiki or similar tools.; Participate in code and design review sessions to ensure high-quality deliverables and adherence to development standards.; Collaborate with architects, product owners, and technical stakeholders to deliver products that meet business requirements and leverage modern technologies.; Identify and recommend opportunities for process improvements, enhancements, and adoption of best practices within the development team.; Mentor and support junior developers, fostering knowledge sharing and contributing to the development of departmental procedures and standards.; Coordinate and contribute to Continuous Integration (CI) activities and the implementation of automated testing frameworks.; Develop proof-of-concepts (POCs) and prototypes to validate ideas and quickly iterate new features or enhancements.; Communicate technical solutions, project status, issues, and risks effectively to both technical and non-technical stakeholders.; Ensure the delivery of high-quality, defect-free code and take accountability for meeting project timelines and quality standards.; This is a hybrid position. Expectation of days in office will be confirmed by your Hiring Manager.; Qualifications; Preferred Qualifications; \u20223 or more years of work experience with a Bachelor\u2019s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD); \u20224\u20137 years of relevant experience in Java\/J2EE enterprise applications.; \u2022Strong skills in Core Java, J2EE, Spring Framework, Spring Boot, Hibernate, and Web services.; \u2022Proficiency in object-oriented design and software design principles.; \u2022Experience with secure coding practices.; \u2022Strong SQL skills with experience in relational (MySQL, PostgreSQL) and NoSQL (MongoDB) databases.; \u2022Understanding of data warehousing concepts and tools.; \u2022Exposure to data engineering frameworks such as Apache Spark, Hadoop, or Kafka is an advantage.; \u2022Basic understanding of ETL processes and data pipeline development.; \u2022Hands-on experience with containerization and orchestration tools (Docker, Kubernetes).; \u2022Proficiency in version control systems (Git\/Stash), build tools (Maven), and CI\/CD tools (Jenkins).; \u2022Familiarity with Unix\/Linux operating systems and shell scripting.; \u2022Experience with UI frameworks and frontend development using Angular or React, Next.js, JavaScript, HTML, and CSS.; \u2022AI and generative AI skills are highly desirable.; \u2022Experience working in all phases of the software development life cycle.; \u2022Experience with Agile methodologies (Scrum, sprints) and tools (Jira).; \u2022Understanding of DevOps practices.; \u2022Solid foundation in computer science, including data structures and algorithms.; \u2022Willingness to learn and improve coding skills, especially in Java or Scala.; Additional Information:; Skills\/Abilities; \u2022Strong analytical and problem-solving abilities.; \u2022Quick to learn and adapt to new technologies and challenges.; \u2022Excellent organizational skills with the ability to manage multiple tasks and deadlines in a fast-paced environment.; \u2022Outstanding written and verbal communication skills for conveying ideas and implementation plans to team members and stakeholders.; \u2022Highly detail-oriented, resourceful, and results-driven.; \u2022Self-motivated with a demonstrated ability to work independently and meet commitments.; \u2022Comfortable collaborating in dynamic, fast-paced, and highly interactive team settings.; \u2022Eager to learn new skills, embrace new initiatives, and contribute to team success.; \u2022Proven ability to maintain a positive attitude and have fun while working as part of a team.; Additional Information; Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85019312","Role":"Senior Data Engineer","Company":"GC ASIA DENTAL PTE LTD","Location":"Tampines","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85019312","job_desc":"Job Responsibilities; Microsoft Fabric Expertise: Serve as the primary subject matter expert for Microsoft Fabric, including but not limited to Lakehouse, Data Factory, Synapse Data Engineering (Spark), Data Warehousing, Real-Time Analytics, and Power BI integration.; Data Solution Design & Development: Lead the end-to-end design, development, and implementation of robust, scalable, and efficient data pipelines and solutions within the Microsoft Fabric ecosystem. This includes data ingestion, transformation, orchestration, and consumption layers.; Architectural Leadership: Contribute to and drive the architectural vision for our data platform on Microsoft Fabric, ensuring best practices for performance, security, reliability, and cost-effectiveness.; Independent Project Management: Take full ownership of data engineering projects, including planning, resource allocation (where applicable), timeline management, risk mitigation, and successful delivery.; Stakeholder Collaboration: Work closely with data analysts, business stakeholders, and other engineering teams to understand data requirements, translate them into technical specifications, and deliver impactful data solutions.; Data Governance & Quality: Implement and enforce data governance, quality, and security best practices within the Microsoft Fabric environment.; Performance Optimization & Troubleshooting: Proactively monitor, troubleshoot, and optimize data pipelines and data models for performance and efficiency.; Mentorship & Best Practices: Champion best practices in data engineering, data modeling, and Microsoft Fabric utilization. Potentially mentor junior team members and foster a culture of continuous learning.; Documentation: Create and maintain comprehensive technical documentation for data pipelines, data models, and architectural designs.; Job Requirements; Minimum 5+ years of experience in data engineering, with a strong focus on building and maintaining enterprise-grade data platforms.; Demonstrable expert-level proficiency in Microsoft Fabric, with hands-on experience across multiple components (Lakehouse, Data Factory, Synapse Data Engineering\/Spark, Data Warehousing, Real-Time Analytics).; Proven track record of successful project management in data-related initiatives, including planning, execution, and delivery.; Extensive experience with Spark (PySpark\/Scala) for data transformation and processing within a distributed environment.; Strong understanding of data warehousing concepts, dimensional modeling, and data lake architectures.; Proficiency in SQL for data manipulation and analysis.; Experience with Azure ecosystem components (e.g., Azure Data Lake Storage, Azure DevOps, Azure Functions) is a strong plus.; Experience with version control systems (e.g., Git).; Excellent problem-solving, analytical, and critical thinking skills.; Exceptional communication and interpersonal skills, with the ability to articulate complex technical concepts to non-technical stakeholders and work effectively in a team-oriented environment.; Highly self-motivated and able to work independently with minimal supervision, taking initiative and ownership of tasks.; Microsoft Certified: Azure Data Engineer Associate, or other relevant Microsoft Azure\/Fabric certifications.; Experience with real-time data streaming technologies.; Familiarity with CI\/CD practices for data pipelines.; Experience with Power BI for data visualization and reporting.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85430135","Role":"Data Architect \u2013 SAS VI","Company":"THAKRAL ONE PTE LTD","Location":"Singapore","Publish_Time":"2025-07-03 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85430135","job_desc":"Role; Data Architect \/ Data Management Lead \u2013 SAS (Fraud & Investigation Focus); Job Description; We are seeking a highly experienced Data Architect \/ Data Management Lead with strong domain knowledge in fraud analytics, case management, and investigation\/intelligence systems. The ideal candidate will lead the design, development, and deployment of data integration and analytics components within SAS environments, with hands-on exposure to SAS Viya, data pipelines, and real-time streaming tools. This role is ideal for someone who thrives at the intersection of data strategy, architecture, and stakeholder collaboration.; Key Responsibilities; Collaborate with business analysts to gather and interpret data-related requirements for fraud\/case management\/investigation solutions.; Define and implement a comprehensive data architecture, including data sourcing, integration, cleansing, storage, and provisioning strategies.; Translate business requirements into technical work products across the ETL, data engineering, and reporting layers.; Design and lead batch and real-time data ingestion processes from various sources into SAS or big data platforms.; Develop data pipelines, orchestration frameworks, and visualization\/reporting structures using tools such as SAS Viya, DS2, and Python.; Lead integration and testing of developed components, and support UAT activities.; Oversee documentation, project tracking, and technical troubleshooting.; Ensure compliance with data governance, metadata, and quality management standards.; Experience and Skills Requirements; 10+ years of relevant experience in Business Analytics, Data Architecture, or Data Warehousing.; Proven end-to-end delivery of at least 5 enterprise projects, preferably involving SAS solutions in fraud, surveillance, or case management domains.; Strong hands-on experience in:; SAS Viya, SAS DS2, SQL Programming; Python, Spark, JSON, XML; Job scheduling, Linux commands, data streaming tools (Kafka\/SAS ESP); Postman\/SOAPUI, REST APIs, DevOps\/DataOps; Working knowledge of:; Data model design, source-to-target mapping; Real-time event processing, metadata management, and orchestration; Background in fraud analytics, investigative systems, or intelligence\/case management frameworks is essential.; Familiarity with tools such as SAS Intelligent Decisioning, RTDM, PEGA, or similar is a strong plus.; Experience working in government, public sector, or regulated environments is highly preferred.; Strong communication, stakeholder management, and leadership skills.; Degree in Computer Science, IT, Statistics, or related field.; Number of Vacancies; 1; Philippines","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85500842","Role":"Integration Developer (WebMethods_Talend_Kafka_DevOps)","Company":"Maltem Asia Pte. Ltd.","Location":"Raffles Place","Publish_Time":"2025-07-05 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85500842","job_desc":"Maltem Singapore is seeking an Integration Developer to join our wonderful community.; Responsibilities :; Design, develop and deliver data integration\/data extraction solutions using Talend and ControlM for flow scheduling.; Migration experience from ETL IBM DataStage to Talend is plus.; Design and Develop Service Oriented Architecture SOA based architecture approaches, design methodologies and design patterns.; Develop Web Services (SOAP & REST) and complex XML schemas and data mapping; Extensive Working Experience on WebMethods Components\/concepts : WebMethods Designer, Integration Server, BPM (Business Process Model), MWS, WMDeployer, Web Services, Broker, SOA, CentraSite and Mediator; Develop Flow Services using adapters such as JDBC Adapter, Salesforce, SAP Adapter,AS400, Flat Files and XML.; Work with communication protocol like FTP, SFTP, FTP-PGP, HTTPS, AS2.; Interact with IT and business partners across global teams as required for support or projects.; Work on API gateways API portal, setting up security policies using OAUTH, SSO, JWT.; Familiar with CI\/CD tools, such as Jenkins, Maven\/Gradle, ANT script and SVN\/Git.; Good to have knowledge on Bitbucket repository and docker concepts.; Must-Have-Skillsets:; Proven track record in using Apache Kafka for managing real-time data feeds building data pipelines.; ETL Talend 8, Talend 7.x, Unix, SQL; Passion in advocating and implementing best practices in Software Engineering and DevOps.; Mandatory relevant experience in BPM & API (SOAP and REST) with Mediator & CentraSite; Experience in design, develop and support WebMethods implementation projects (WebMethods 9.x , 10.x) product suite","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"83921619","Role":"Data Architect [DSAD]","Company":"Public Service Division","Location":"Paya Lebar Air Base","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83921619","job_desc":"[What the role is]; We are seeking a strategic and technically adept Data Architect to join Workforce Singapore (WSG)\u2019s Data Strategy and Analytics Division (DSAD). In this newly established role, you will design and shape the central data platform that will power our organization\u2019s shift from manual reporting to scalable, automated insights. You will translate business needs into clear, future-proof data architecture \u2014 creating the foundation that analysts and decision-makers can rely on.; [What you will be working on]; Design, document, and evolve the architecture of our central data platform to meet both immediate reporting needs and long-term business growth.; Map data flows and define how data is collected, stored, transformed, and delivered for analysis and reporting.; Work hand-in-hand with analysts and business users to understand their needs and help shape the tools and structures that enable them.; Develop and maintain data models (conceptual, logical, and physical) that support business intelligence, self-service analytics, and automated reporting.; Support the transition from manual, Excel-based processes to platform-driven, automated reporting pipelines.; Guide technical choices for data storage, integration tools, and transformation workflows in partnership with IT and engineering teams.; Contribute to data governance, quality assurance, and metadata management to ensure trust and consistency across the organization.; Facilitate knowledge sharing and collaborate across a matrix reporting environment \u2014 working with both business and technical stakeholders.; What Success Could Look Like in Your First 6 Months:; When you join us, here\u2019s how we imagine you\u2019ll add value early on:; Current-State Data Landscape Mapped; Conduct a structured review of existing data sources, data flows, and reporting pipelines.; Document the current state, identify key pain points, and highlight areas for improvement \u2014 focusing on enabling a shift from manual reporting to platform-driven analytics.; Draft of Target Data Architecture Blueprint Proposed; Translate business needs into a draft technical architecture that supports scalable, efficient reporting and analysis.; Align this blueprint with the organization\u2019s existing enterprise architecture principles and tools selected by the CIO\u2019s office.; Tool Integration and Gap Assessment Completed; Review the division\u2019s business use cases against the capabilities of the current CIO-endorsed tech stack.; Identify where the existing tools meet business needs, and highlight any potential gaps or areas where future enhancement or complementary solutions may be required.; Provide structured recommendations for adoption, integration, or future-proofing, if any.; Data Models for Priority Use Cases Delivered; Co-develop logical and physical data models for 2\u20133 priority reporting scenarios in collaboration with business users and analysts.; Ensure these models lay the groundwork for future automation and self-service reporting.; Data Governance Starter Kit Proposed; Draft a lightweight starter framework for data ownership, quality, metadata, and version control practices, tailored to the division\u2019s needs.; Facilitate early alignment conversations to ensure consistent data practices as the platform evolves.; Cross-Team Collaboration Practices Established; Set up and lead regular technical and business syncs with analysts, IT teams, and business units to ensure the architecture design is both practical and future-ready.; Lay the groundwork for long-term collaboration habits that support a data-driven culture.; [What we are looking for]; Knowledge and Skills:; Proven experience in designing data architectures in dynamic environments, including cloud-based or hybrid data platforms.; Strong knowledge of modern data tools and concepts, including:; Data warehousing solutions (e.g., Snowflake, BigQuery, Redshift, Synapse).; Data modeling techniques (star schema, snowflake schema, dimensional modeling).; Familiarity with data integration tools and the ability to assess and adopt new tools as the platform evolves.; Proficiency in SQL and one or more scripting languages (Python preferred).; Ability to bridge business requirements with technical design, keeping both scalability and usability in mind.; Aptitudes and Abilities:; Clear, thoughtful communicator \u2014 comfortable engaging both technical teams and non-technical business users.; Experience navigating a matrix reporting structure and working across teams to drive alignment.; A collaborative mindset and a genuine interest in shaping a strong data culture.; Strong analytical mindset with an innate curiosity to make sense of complexity.; All applicants will be notified on whether they are shortlisted or not within 4 weeks of the closing date of this job posting.; Why Join Us:; Be at the Heart of WSG\u2019s Data Transformation \u2013 design the platform that will empower WSG to make smarter, faster decisions.; Influence Organisational Decision-making \u2013 provide expert guidance on data architecture to senior management directly impacting WSG\u2019s strategic initiatives and operational efficiency.; Drive Innovation in Data Management \u2013 lead initiatives to improve data literacy and analytics capabilities across the organization, promoting a culture that values data as a strategic asset.; Advance Your Career \u2013 join a dynamic team committed to building meaningful data infrastructure from the ground up, providing opportunities for professional growth and development.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85786615","Role":"Software Engineer \u2013 Oracle Fusion Applications & Integration Specialist","Company":"ANTAS PTE. LTD.","Location":"Singapore","Publish_Time":"2025-07-15 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85786615","job_desc":"We are seeking a highly skilled and hands-on Software Engineer with deep expertise in Oracle Fusion Cloud Applications and Oracle Integration Cloud (OIC) . This position is part of our core Oracle enterprise team, supporting critical finance and HR transformation initiatives across the organization. The ideal candidate must demonstrate a strong command of Oracle Cloud integration patterns, custom development on Oracle PaaS , and hands-on troubleshooting skills in a complex, cross-functional enterprise environment.; Key Responsibilities:; Oracle Fusion Application Support:; Manage end-to-end technical support for Oracle Fusion Finance modules: AP, AR, GL, FA, Procurement, and iExpense.; Perform quarterly patch assessments, regression testing, and cross-functional impact analysis.; Work with Oracle support for SR resolution and cloud enhancement rollouts.; Integration Development (OIC):; Develop and maintain OIC integrations: app-driven orchestrations, scheduled jobs, and REST\/SOAP-based flows.; Design robust error-handling and retry mechanisms to ensure high availability.; Integrate third-party applications and external systems with Oracle Fusion using WSDL, REST, and SOAP APIs.; Custom Apps & Extensions (PaaS):; Build and maintain UI extensions using Visual Builder (VBCS), App Composer, and Process Cloud (PCS).; Support Oracle Cloud PaaS-based solutions for workflow automation and approvals.; BI & Reporting:; Design and optimize BI Publisher, OTBI reports, and custom dashboards.; Extract data using SQL and automate reporting pipelines for stakeholders.; Platform Optimization:; Monitor system performance, identify integration bottlenecks, and recommend tuning opportunities.; Collaborate with DevOps for deployment automation and version control (Git, Jenkins).; Operational Support:; Follow ITIL-aligned processes: incident management, change control, and service improvement.; Ensure production stability, data integrity, and SLA compliance in a cloud-first environment.; Required Skills & Experience:; 5+ years of technical experience in Oracle Fusion Cloud Applications and Oracle Integration Cloud.; Strong hands-on experience with REST\/SOAP APIs, WSDL, and integration debugging.; Experience building integrations across Finance and HCM modules using OIC.; Practical knowledge of VBCS, PCS, and App Composer for UI\/workflow extensions.; Deep expertise in FBDI, HDL, ADFdi, HSDL for data loads and migrations.; Strong command of Oracle SQL, PL\/SQL, and Unix\/Linux shell scripting.; Good understanding of DevOps practices, version control (Git), and deployment pipelines.; Familiarity with Agile\/Scrum and ITIL frameworks.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"82131033","Role":"Platinion Principal Data\/AI Architect","Company":"THE BOSTON CONSULTING GROUP PTE. LTD.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/82131033","job_desc":"Who We AreBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963.; Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact. To succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change.; BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures\u2014and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive. About BCG Platinion BCG Platinion's presence spans across the globe, with offices in Asia, Europe, and South and North America.; We achieve digital excellence for clients with sustained solutions to the most complex and time-sensitive challenge. We guide clients into the future to push the status quo, overcome tech limitations, and enable our clients to go further in their digital journeys than what has ever been possible in the past. At BCG Platinion, we deliver business value through the innovative use of technology at a rapid pace.; We roll up our sleeves to transform business, revolutionize approaches, satisfy customers, and change the game through Architecture, Cybersecurity, Digital Transformation, Enterprise Application and Risk functions. We balance vision with a pragmatic path to change transforming strategies into leading-edge tech platforms, at scale. Practice; Area BCG Platinion launched in Germany in 2000 to add deep technical expertise to the Boston Consulting Group\u2019s existing capabilities. Today, our presence spans across the globe, with offices in Asia, Europe, and South and North America. Our; New York-based North American team began in 2014 and in 2017 acquired MAYA Design, a Pittsburgh-based digital design and innovation lab, to grow our capabilities around technology and design.  We support our clients\u2019 total digital transformation through technology, design, cybersecurity, and risk management & financial engineering capabilities. And together with BCG, BCG Platinion\u2019s interdisciplinary team of technical experts enable customized technical solutions and accelerate delivery value through new business platforms, application consolidations, and major system implementations.; What You'll DoPosition OverviewAbout this role We are seeking a highly skilled Senior Data\/AI Architect to provide strategic guidance on designing, developing, and optimizing modern data architectures that support advanced analytics, AI\/ML, and real-time data processing. This role emphasizes advisory and leadership, helping organizations define future-ready data strategies and governance frameworks that enable AI-driven use cases.; The ideal candidate will work closely with data engineers, data scientists, business analysts, and IT leaders to shape scalable, secure, and efficient data ecosystems.  What You; Will Do Data Architecture & StrategyDefine and advise on the design of modern, future-ready data architectures that align with business goals and support AI, analytics, and automation. Guide organizations in adopting cloud-native and hybrid data solutions (AWS, Azure, GCP, Snowflake, Databricks).; Provide thought leadership on best practices for data modeling, data warehousing, and lakehouse architectures to ensure scalability and performance. Shape long-term data strategies that foster flexibility, innovation, and interoperability across platforms.  Data Governance & AdvisoryLead the development of governance frameworks and policies that ensure data security, compliance, and ethical AI use.; Provide guidance on the creation and maintenance of data dictionaries, metadata management, and data cataloging, ensuring consistency, accuracy, and alignment with industry best practices. Advise on data quality management strategies, ensuring robust data lineage, accuracy, and reliability across the organization. Define governance roadmaps that support AI adoption while maintaining compliance with GDPR, CCPA, HIPAA, and other regulations.;  Cloud & Emerging TechnologiesProvide strategic recommendations on leveraging data lakes, data meshes, and serverless architectures to optimize data processing and storage. Advise on implementing real-time streaming solutions (Kafka, Kinesis, Pub\/Sub) to support AI-driven analytics. Assess and recommend AI\/ML-enabled data architectures that facilitate scalable feature engineering and model training pipelines.; Guide organizations in evaluating and adopting graph databases, NoSQL solutions, and modern data integration tools.  Collaboration & LeadershipAct as a trusted advisor to C-level executives and business leaders, translating complex data challenges into strategic initiatives. Collaborate with data scientists, engineers, and business analysts to enhance data accessibility and usability.; Drive innovation in data architecture, ensuring organizations remain competitive and AI-ready. Lead assessments of emerging data technologies and best practices to future-proof organizational data strategies.  What; You'll BringRequired Skills & QualificationsEducation: Bachelor\u2019s or Master\u2019s in Computer Science, Data Science, Information Systems, or a related field. Experience: 10-16 years in data architecture, data engineering, or cloud-based data solutions. Flexibility to travel within SEA\/Asia Pacific region Technical & Advisory Expertise:Deep knowledge of cloud data platforms (AWS Redshift, Azure Synapse, Google BigQuery, Snowflake).; Expertise in data governance, master data management (MDM), and compliance frameworks. Strong understanding of AI-ready data architectures and their impact on feature engineering and ML workflows. Ability to guide organizations on ETL\/ELT strategy, data integration, and workflow automation.; Familiarity with industry-standard data architecture frameworks (TOGAF, Zachman). Experience advising on real-time data streaming (Kafka, Kinesis, Pub\/Sub).  Preferred QualificationsCertifications in cloud data platforms (AWS Certified Data Analytics, Azure Data Engineer, GCP Professional Data Engineer).; Experience advising on Data Mesh and Data Fabric architectures. Knowledge of Graph databases and NoSQL solutions (MongoDB, Neo4j, Cassandra). Background in data ethics, responsible AI, and AI governance frameworks.;  Why Join Us? Influence enterprise data strategies at a global scale.; Work in a collaborative, innovative environment that values advisory expertise. Competitive compensation and benefits. Lead transformational data initiatives that shape AI adoption and digital innovation.;  If you are passionate about advising organizations on future-ready data architectures and driving AI-enabled data strategies, we invite you to apply! Boston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity \/ expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.; BCG is an E - Verify Employer. Click here for more information on E-Verify.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"82357566","Role":"Vice President, Azure Data Technical Lead (JRI-4391)","Company":"Sumitomo Mitsui Banking Corporation","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/82357566","job_desc":"The Japan Research Institute (JRI) Limited is a subsidiary of Sumitomo Mitsui Banking Corporation (SMBC) Group. SMBC Group is a Tokyo-based bank holding company that is ranked among the largest 25 banks globally by assets under management. JRI provides comprehensive, highly value-added information services through the coordinated application of its 3 functions i.e. information systems, consulting and think-tank. As a system integrator, JRI offers services in IT strategy planning, implementation and outsourcing to a broad range of industries and activities. JRI Singapore currently supports the overall IT functions of Sumitomo Mitsui Banking Corporation (SMBC) in the Asia Pacific region.; You will be the Azure data platform Technical Lead to plan out on-premises system migration, include migrate methodology, data requirements and compliance strategy. Also provide insightful knowledge to guide internal team better support on the building of Azure data warehouse, Databrick, data pipelines and Power BI reports. ; Job Responsibilities; Analyse the current practices, processes, and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data and Analytics Services.; Provide technical and thought leadership as a senior member of the Analytics Practice in areas such as data access & ingestion, data processing, data integration, data modelling, database design & implementation, data visualization, and advanced analytics.; Collaborate with project managers in estimating technical tasks and deliverables.; Develop best practices including reusable code, libraries, patterns, and consumable frameworks for cloud-based data warehousing and ETL.; Maintain best practice standards for the development or cloud-based data warehouse solutioning including naming standards.; Job Requirements; Bachelor\u2019s degree in information technology, Computer Science, Manage Information Science, Banking and Finance or equivalent.; Min. 10 years of experience in Data Warehousing, Data Analytics, Realtime data integration or Business Intelligence; Min. 3 years of experience as a Data Architect, Solution Architect or Technical Lead; Min. 2 years of experience in managing technical team and leading on Azure data platform implementation.; Knowledge in both traditional and modern data architecture and processing concepts such as SQL, Hadoop, Spark, Kafka and business analytics; Proficiency in Databricks is a must.; Experience in technology skillsets:; Azure database platforms e.g. Azure SQL database, Azure Databricks, Azure data Lake Gen2; Azure data integration tools e.g. Azure Synapse, Azure Data factory, Azure Event Hub.; Data visualisation tools e.g. QlikView, Power BI; Programming language: R & Python; Possess architectural sense in connecting data sources, data visualization, structured and unstructured data.; Candidates with traditional ETL knowledge may be considered.; Knowledge in financial sector technologies, products and services will be an advantage.; Able to multi-task in a challenging technical environment to deliver high quality solutions; A meticulous team player who has proactive and positive attitude; Excellent communication, interpersonal and presentation skills","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85167492","Role":"[LTA-TRO] EXECUTIVE\/ ENGINEER, ROAD DATA MANAGEMENT","Company":"Public Service Division","Location":"Singapore","Publish_Time":"2025-06-24 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85167492","job_desc":"[What the role is]; As a Data Engineer in Roads Data Management team, you will use data engineering skills and traffic domain knowledge to onboard, prepare and enhance the various datasets needed by TRO group for analytics and reporting purposes. You will also be part of a core team of GIS professionals, data engineers and data analysts who are building the next generation of user applications and data models.; [What you will be working on]; 1) Collaborate with T-Tech Subgroup, ITCD Group and LTA Contractors to ensure the data pipelines meet TRO\u2019s requirements; 2) Collaborate with Data Analysts and Users within TRO to determine the dataset views required.; 3) Build the dataset views required together with ITCD Group.; 4) Analyse and implement data cleaning and post processing methods to ensure the data meets the required standards; 5) Assist on the development and implementation of data quality standards and governance; [What we are looking for]; 1) Knowledge in Computer Science, Geography or Engineering with an analytics \/ GIS specialisation.; 2) At least 2 years of experience in data engineering \/ analytics or GIS or other related work preferred. Those with good experience can be considered for senior positions; 3) You are familiar with relational databases and have some hands-on experience coding in SQL or you are familiar with ArcGIS geodatabases and functions.; 4) You are proficient in one or more of the programming languages such as Python or R; 5) Ability to work independently and collaboratively in a team environment; As part of the shortlisting process for the role, you may be required to complete a medical declaration and \/ or undergo further assessment.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84921566","Role":"Data Engineer\/Senior Data Engineer, DXD (Digital Excellence & Products...","Company":"Public Service Division","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84921566","job_desc":"[What the role is]; The Government Technology Agency (GovTech) is the lead agency driving Singapore\u2019s Smart Nation initiatives and public sector digital transformation. As the Centre of Excellence for Infocomm Technology and Smart Systems (ICT & SS), GovTech develops the Singapore Government\u2019s capabilities in Data Science & Artificial Intelligence, Application Development, Smart City Technology, Digital Infrastructure, and Cybersecurity.; At GovTech, we offer you a purposeful career to make lives better. We empower our people to master their craft through continuous and robust learning and development opportunities all year round. Our GovTechies embody our Agile, Bold and Collaborative values to deliver impactful solutions.; GovTech aims to transform the delivery of Government digital services by taking an \"outside-in\" view, putting citizens and businesses at the heart of everything we do.; Play a part in Singapore\u2019s vision to build a Smart Nation and embark on your meaningful journey to build tech for public good. Join us to advance our mission and shape your future with us today!; Learn more about GovTech at tech.gov.sg.; [What you will be working on]; ; \"To Mould the Future of Our Nation\"; At MOE, we believe in enabling every learner to thrive in a rapidly changing world. As part of our mission, we are building internal AI capabilities to improve student learning outcomes, enhance educator productivity, and strengthen our ability to innovate sustainably. Through the responsible and meaningful application of AI, we aim to advance personalised learning, support teaching, and transform educational operations.; As a Data Engineer, you will play a key role in shaping MOE\u2019s AI capabilities by leading the evaluation, optimisation, and deployment of AI models for education. You will partner closely with product managers, engineers, curriculum specialists, and policy teams to design solutions that are pedagogically relevant, technically robust, and ready for scale.; Our Team; You will be part of the Digital Excellence & Products Division (DXD), a cross-functional team driving MOE\u2019s digital transformation across platforms, policies, and products. Our Forward-Deployed AI\/Data Science Team focuses on rapidly applying AI to real-world problems in education \u2014 from personalised learning and curriculum support to school operations.; What you will be working on:; Translate data requirements from business users into technical specifications.; Collaborate with partner agency\u2019s IT teams on technology stack, infrastructure and security alignment.; Build out data product as part of a data team:; Architect and build ingestion pipelines to collect, clean, merge, and harmonize data from different source systems.; Day-to-day monitoring of databases and ETL systems, e.g., database capacity planning and maintenance, monitoring, and performance tuning; diagnose issues and deploy measures to prevent recurrence; ensure maximum database uptime;; Construct, test, and update useful and reusable data models based on data needs of end users.; Design and build secure mechanisms for end users and systems to access data in data warehouse.; Research, propose and develop new technologies and processes to improve agency data infrastructure.; Collaborate with data stewards to establish and enforce data governance policies, best practices and procedures.; Maintain data catalogue to document data assets, metadata and lineage.; Implement data quality checks and validation processes to ensure data accuracy and consistency.; Implement and enforce data security best practices, including access control, encryption, and data masking, to safeguard sensitive data; [What we are looking for]; A Bachelor\u2019s Degree, preferably in Computer Science, Software Engineering, Information Technology, or related disciplines. ; Deep understanding of system design, data structure and algorithms, data modelling, data access, and data storage.; Demonstrated ability in using cloud technologies such as AWS, Azure, and Google Cloud.; Experience in architecting data and IT systems.; Experience with orchestration frameworks such as Airflow, Azure Data Factory.; Experience with distributed data technologies such as Spark, Hadoop.; Proficiency in programming languages such as Python, Java, or Scala.; Proficiency in writing SQL for databases\\; Familiarity with building and using CI\/CD pipelines.; Familiarity with DevOps tools such as Docker, Git, Terraform.; Preferred requirements:; Experience in designing, building, and maintaining batch and real-time data pipelines. ; Experience with Databricks.; Experience with implementing technical processes to enforce data security, data quality, and data governance.; Familiarity with government systems and government's policies relating to data governance, data management, data infrastructure, and data security.; Our employee benefits are based on a total rewards approach, offering a holistic and market-competitive suite of perks. These include leave benefits to meet your work-life needs and employee wellness programmes. ; We champion flexible work arrangements (subject to your job role) and trust that you will manage your own time to deliver your best, wherever you are, and whatever works best for you. ; Learn more about life inside GovTech at go.gov.sg\/GovTechCareers.; Stay connected with us on social media at go.gov.sg\/ConnectWithGovTech.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85308711","Role":"AI Data Engineer","Company":"InnoCellence Systems Pte Ltd","Location":"Central Region","Publish_Time":"2025-07-01 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85308711","job_desc":"We are looking for a skilled and experienced AI Data Engineer to join our team. The ideal candidate will be responsible for designing, building, and maintaining robust data pipelines to support the processing and analysis of clinical study and digital device sensor data. As a Data Engineer, you will work closely with data scientists and software engineers to ensure the efficient and reliable flow of data from source systems to analytical tools and platforms.; Responsibilities:; Design, develop, and maintain scalable data pipelines to ingest, transform, and load clinical study data from various sources, including digital device sensors.; Optimize data storage and retrieval processes in cloud-based platforms to ensure high performance and reliability.; Collaborate with data scientists to integrate data processing pipelines with AI-powered algorithms and third-party analytical tools or platforms.; Implement data quality checks and monitoring mechanisms to ensure the integrity and accuracy of the data.; Troubleshoot and resolve issues related to data pipeline performance, reliability, and scalability.; Work closely with software developers, system architects and other cross-functional teams to develop data-driven business solutions.; Stay up-to-date with emerging technologies in AI & Cloud computing and best practices in data engineering to continuously improve data processing pipelines and infrastructure.; Requirements:; Bachelor's or Master's degree in Computer Science, Engineering, or a related field.; Proven experience in designing and building data pipelines using ETL tools and frameworks such as Apache Spark, Apache Beam, or Apache Airflow.; Proficiency in programming languages such as Python, Java, or Scala.; Strong understanding of database systems, data warehousing concepts, SQL and NoSQL.; Experience with AI and Cloud Computing: Hands-on experience with cloud platforms like AWS and familiarity with AI solutions in these environments.; Excellent problem-solving and troubleshooting skills with a strong attention to detail and quality.; Effective communication and collaboration skills with the ability to work in a team environment.; Preferred Qualifications:; Experience with containerization and orchestration tools such as Docker and Kubernetes.; Familiarity with big data technologies such as Hadoop, Hive, or Presto.; Knowledge of distributed computing frameworks such as Apache Hadoop or Apache Spark.; Familiarity with ElasticSearch or AWS OpenSearch is plus; Prior experience working with healthcare or clinical data is a plus.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85603113","Role":"Platform Engineer - Data & AI","Company":"Equinix Asia Pacific","Location":"Singapore","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85603113","job_desc":"Who are we?; Equinix is the world\u2019s digital infrastructure company\u00ae, operating over 260 data centers\u202facross the globe. Digital leaders harness Equinix's trusted platform to bring together and interconnect foundational infrastructure at software speed. Equinix enables organizations to access all the right places, partners and possibilities to scale with agility, speed the launch of digital services, deliver world-class experiences and multiply their value, while supporting their sustainability goals. ; Our culture is based on collaboration and the growth and development of our teams.\u202f We hire hardworking people who thrive on solving\u202fchallenging\u202fproblems and give them opportunities to hone new skills and try new approaches, as we grow our product portfolio with new software and network architecture solutions. We embrace diversity in thought and contribution and are committed to providing\u202fan equitable work environment that is foundational to our core values as a company and is vital to our success.; Job Summary; We\u2019re looking for a Senior Platform Engineer with a strong foundation in data architecture, distributed systems, and modern cloud-native platforms to architect, build, and maintain intelligent infrastructure and systems that power our AI, GenAI and data-intensive workloads.; You\u2019ll work closely with cross-functional teams, including data scientists, ML & software engineers, and product managers & play a key role in designing a highly scalable platform to manage the lifecycle of data pipelines, APIs, real-time streaming, and agentic GenAI workflows, while enabling federated data architectures. The ideal candidate will have a strong background in building and maintaining scalable AI & Data Platform, optimizing workflows, and ensuring the reliability and performance of Data Platform systems.; Responsibilities; Platform & Cloud Engineering; Develop and maintain real-time and batch data pipelines using tools like Airflow, dbt, Dataform, and Dataflow\/Spark; Design and develop event-driven architectures using Apache Kafka, Google Pub\/Sub, or equivalent messaging systems; Build and expose high-performance data APIs and microservices to support downstream applications, ML workflows, and GenAI agents; Architect and manage multi-cloud and hybrid cloud platforms (e.g., GCP, AWS, Azure) optimized for AI, ML, and real-time data processing workloads; Build reusable frameworks and infrastructure-as-code (IaC) using Terraform, Kubernetes, and CI\/CD to drive self-service and automation; Ensure platform scalability, resilience, and cost efficiency through modern practices like GitOps, observability, and chaos engineering; Data Architecture & Governance; Lead initiatives in data modeling, semantic layer design, and data cataloging, ensuring data quality and discoverability across domains; Implement enterprise-wide data governance practices, schema enforcement, and lineage tracking using tools like DataHub, Amundsen, or Collibra; Guide adoption of data fabric and mesh principles for federated ownership, scalable architecture, and domain-driven data product development; AI & GenAI Platform Integration; Integrate LLM APIs (OpenAI, Gemini, Claude, etc.) into platform workflows for intelligent automation and enhanced user experience; Build and orchestrate multi-agent systems using frameworks like CrewAI, LangGraph, or AutoGen for use cases such as pipeline debugging, code generation, and MLOps; Experience in developing and integrating GenAI applications using MCP and orchestration of LLM-powered workflows (e.g., summarization, document Q&A, chatbot assistants, and intelligent data exploration); Hands-on expertise building and optimizing vector search and RAG pipelines using tools like Weaviate, Pinecone, or FAISS to support embedding-based retrieval and real-time semantic search across structured and unstructured datasets; Engineering Enablement; Create extensible CLIs, SDKs, and blueprints to simplify onboarding, accelerate development, and standardize best practices; Streamline onboarding, documentation, and platform implementation & support using GenAI and conversational interfaces; Collaborate across teams to enforce cost, reliability, and security standards within platform blueprints; Work with engineering by introducing platform enhancements, observability, and cost optimization techniques; Foster a culture of ownership, continuous learning, and innovation; Qualifications; 5+ years of hands-on experience in Platform or Data Engineering, Cloud Architecture, AI Engineering roles; Strong programming background in Java, Python, SQL, and one or more general-purpose languages; Deep knowledge of data modeling, distributed systems, and API design in production environments; Proficiency in designing and managing Kubernetes, serverless workloads, and streaming systems (Kafka, Pub\/Sub, Flink, Spark); Experience with metadata management, data catalogs, data quality enforcement, and semantic modeling & automated integration with Data Platform; Proven experience building scalable, efficient data pipelines for structured and unstructured data; Experience with GenAI\/LLM frameworks and tools for orchestration and workflow automation; Experience with RAG pipelines, vector databases, and embedding-based search; Familiarity with observability tools (Prometheus, Grafana, OpenTelemetry) and strong debugging skills across the stack; Experience with ML Platforms (MLFlow, Vertex AI, Kubeflow) and AI\/ML observability tools; Prior implementation of data mesh or data fabric in a large-scale enterprise; Experience with Looker Modeler, LookML, or semantic modeling layers; Why You\u2019ll Love This Role; Drive technical leadership across AI-native data platforms, automation systems, and self-service tools; Collaborate across teams to shape the next generation of intelligent platforms in the enterprise; Work with a high-energy, mission-driven team that embraces innovation, open-source, and experimentation; Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability.  If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.; Equinix is an Equal Employment Opportunity and, in the U.S., an Affirmative Action employer.  All qualified applicants will receive consideration for employment without regard to unlawful consideration of race, color, religion, creed, national or ethnic origin, ancestry, place of birth, citizenship, sex, pregnancy \/ childbirth or related medical conditions, sexual orientation, gender identity or expression, marital or domestic partnership status, age, veteran or military status, physical or mental disability, medical condition, genetic information, political \/ organizational affiliation, status as a victim or family member of a victim of crime or abuse, or any other status protected by applicable law.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85549955","Role":"AD, Data & AI Platform Enablement","Company":"Singapore Telecommunications Limited","Location":"Singapore","Publish_Time":"2025-07-07 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85549955","job_desc":"An empowering career at Singtel begins with a Hello. Our purpose, to Empower Every Generation, connects people to the possibilities they need to excel. Every \"hello\" at Singtel opens doors to new initiatives, growth, and BIG possibilities that takes your career to new heights. So, when you say hello to us, you are really empowered to say\u2026\u201cHello BIG Possibilities\u201d.; Be a Part of Something BIG! ; This position plays a pivotal technical role in AI & Data Analytics (AIDA) who is responsible for leading a cross-functional team of platform, data, and operations engineers to deliver a secure, scalable, and cost-efficient hybrid cloud AI infrastructure.; The role will have to work closely with architects and AI engineering teams to build a robust platform that supports a wide range of AI use cases across multiple business units.; You will collaborate with data source and platform teams from both Networks and IT to design and implement integrated data solutions that empower users to efficiently develop and scale AI applications.; Make An Impact By; Lead, manage and grow a cross functional team consisting of platform engineers, data engineers, DataOps, DevSecOps engineers, FinOps, operations and delivery managers, ensuring the successful delivery and sustainable AI platform.; Foster innovative, agile and user focused team culture to accelerate delivery of AI and advance analytics use cases; Coordinate workload within team and integration efforts with various departments across Singtel SG; Evaluate Singtel existing and latest tools available in market to build best-in-class telco data and AI tech stack; Plan unified data layer to enable availability of cross-domain data sources in single location for AI use; Design integration architecture to existing and upcoming systems across Singtel Singapore; Deliver and implement hybrid cloud AIDA platform; Monitor platform performance, availability and utilization to ensure stability; Operate and maintain data and AI platform to maximize availability and platform           ; Manage implementation timeline to meet use case delivery targets; Integrate data sources across Singtel SG efficiently to allow effective cross-domain AI and data use cases; Responsible for data quality monitoring, cataloguing, CII & PII data and sensitivity classification for AIDA; Set-up and operate AIDA\u2019s DevSecOps platform for efficient, traceable development and deployment; Constantly update and upgrade pipelines and security policies to align with latest libraries and cybersecurity recommendations; Implement solutions to continuously optimize compute resource and data transfer cost; Manage platform and cloud cost (FinOps) for cost effective AI operations; Skills for Success:; Bachelor\u2019s degree in computing, engineering or relevant fields; 5+ years experience in design, implementation and operation of hybrid cloud data engineering platform; 1-2 years of team leadership or delivery management experience; Capable of designing hybrid cloud data and AI system; Experience in operation of hybrid cloud data and AI systems; Proficient in data ingestion and integration development (Spark, Kafka, Hadoop, Azure Storage, etc.); Experience in workload optimization and FinOps to minimize computing cost; Good knowledge of DevSecOps processes and tools; Demonstrated good project management skills in implementation of data\/system projects; Rewards that Go Beyond; Full suite of health and wellness benefits ; Ongoing training and development programs ; Internal mobility opportunities; Are you ready to say hello to BIG Possibilities?; Take the leap with Singtel to unlock new opportunities and accelerate your growth. Apply now and start your empowering career!","salary":"","work_type":"","country":"singapore"}
{"Job_ID":"85381719","Role":"Data Platform Engineer - RCIC","Company":"Beyondsoft International (Singapore) Pte Ltd","Location":"Singapore","Publish_Time":"2025-07-02 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85381719","job_desc":"COMPANY DESCRIPTION; Beyondsoft International (Singapore) Pte. Ltd. was set up in 2007 and established as the regional headquarters for the Southeast Asia (SEA) and European markets in September 2015. Based on our vision of \"Using technology to promote social progress, economic development and become a global customer preferred partner\" and our concept of \"Beyond your expectations\", Beyondsoft is committed to provide our customers in countries along the \"Belt and Road\" with comprehensive solutions and products and creating commercial value for customers to realizing continuous businesses development.; Our core business includes:; IT development services providing customers with IT consulting, software research and development, software and hardware testing, system integration and operation and maintenance, data analysis and other services;; New retail solutions and products through intelligent products, helping small and medium-sized enterprises (SMEs) realize the digital transformation of their daily operations;; Internet of Things (IoT) platform and solutions comprehensive use of IoT, artificial intelligence, big data, cloud computing and other technologies to provide IoT solutions for intelligent upgrades in cities, parks, buildings and industries, to create a smart future.; For more information, please visit www.beyondsoft.com.; RESPONSIBILITIES; Design, implement, and maintain platform infrastructure to support data products and automation workflows.; Automate operational workflows to improve system efficiency and reduce manual tasks.; Collaborate with cross-functional teams to support the Tableau upgrade and Glean-related initiatives.; Support Tableau server upgrades and assist in user migration, dashboard performance tuning, and configuration.; Develop and maintain scripts\/tools using Python and SQL for automation and data operations.; Build and enhance CI\/CD pipelines to streamline deployment processes.; Ensure operational stability and performance of data platforms through proactive monitoring and continuous improvement.; Document processes, contribute to platform standards, and support audit\/compliance requirements; QUALIFICATIONS; Bachelor\u2019s degree in computer science, Engineering, or a related field.; Minimum 5 years of experience with platform setup and automation of operational workflows.; Strong proficiency in Python, SQL, and experience with CI\/CD pipelines.; Strong hands-on experience with Tableau; Excellent analytical and problem-solving skills.; Beyondsoft Technology (Singapore) Pte. Ltd is committed to being an equal opportunity employer and provides equal employment opportunities to all employees and applicants. We strive to cultivate a workplace that celebrates diversity and inclusion, where individuals of all backgrounds\u2014regardless of nationality, ethnicity, religion, age, gender identity, sexual orientation, or any other distinguishing trait\u2014can succeed and thrive. We prohibit discrimination and harassment of any type with regard to race, color, religion, age, national origin, disability status, genetics, sexual orientation, gender identity, or expression. This policy applies to all terms and conditions of employment, including recruiting, hiring, and the entire employee lifecycle. We are focused on creating an environment where everyone can reach their full potential.;  Employment offers from Beyondsoft Technology (Singapore) Pte. Ltd. are contingent upon the successful completion of any required pre-employment processes, in line with applicable laws and regulations. Beyondsoft Technology (Singapore) Pte. Ltd. does not ask for any recruitment fees, nor does it request any unauthorized payments from candidates as part of the hiring process.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85600186","Role":"Data Engineer Intern","Company":"Innowave Tech Pte Ltd","Location":"Paya Lebar","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85600186","job_desc":"About Innowave Tech; Innowave Tech is an Artificial Intelligence (AI) company offering solutions for the Semiconductor and Advanced Manufacturing industry. Utilizing deep industrial domain knowledge, proven experience, and innovation, we provide expert AI solutions and systems to address various industry pain points.; Job Description; We are seeking a highly motivated and detail-oriented Data Engineer Intern to join our data team. In this role, you will assist in designing, building, and maintaining data pipelines and infrastructure that support data analytics and decision-making across the organization. This is an excellent opportunity to gain hands-on experience with real-world data engineering tools, workflows, and cloud platforms.; Key Responsibilities; \u00b7 Assist in developing and maintaining data pipelines using ETL\/ELT tools.; \u00b7 Support data integration from various internal and external sources into data warehouses.; \u00b7 Work with structured and unstructured data to transform it into usable formats.; \u00b7 Help ensure data quality, consistency, and availability across systems.; \u00b7 Collaborate with data scientists, analysts, and engineers to support data needs.; \u00b7 Document data workflows, schemas, and system processes.; \u00b7 Monitor data pipelines and resolve any issues or failures.; Requirements; \u00b7 Currently pursuing a degree in Computer Science, Data Science, Engineering, or a related field.; \u00b7 Basic knowledge of SQL and experience with a programming language such as Python, Java, or Scala.; \u00b7 Familiarity with relational databases (e.g., MySQL, PostgreSQL) and\/or data warehousing solutions (e.g., BigQuery, Redshift, Snowflake).; \u00b7 Experience in C# development.; \u00b7 Understanding of ETL concepts and data pipeline architecture.; \u00b7 Strong analytical thinking and problem-solving skills.; \u00b7 Willingness to learn and work in a team-oriented environment.; \u00b7 Internship duration should be at least 3 months full time.; \u00b7 Resume should indicate your forecasted internship dates.; Preferred Qualifications:; \u00b7 Exposure to cloud platforms like AWS, GCP, or Azure.; \u00b7 Experience with data processing frameworks (e.g., Apache Spark, Airflow).; \u00b7 Knowledge of version control tools (e.g., Git).","salary":"$800 \u2013 $1,000 per month (SGD)","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"84915025","Role":"Vice President, Data Platform Lead, Technology Service Delivery Group","Company":"Sumitomo Mitsui Banking Corporation","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84915025","job_desc":"Job Responsibilities; \u2022    Oversee the planning and delivery of data platform projects and system changes following the Software Development Lifecycle.; \u2022    Serve as a data architect involved in logical and physical data modeling, collaborating with cross-functional teams to collect requirements, design solutions, and implement data strategies utilizing Azure services such as Data Lake, Synapse, and Databricks.; \u2022    Build data models to support data marts\/enterprise data warehouse.; \u2022    Manage data pipelines and ETL processes to ensure data quality and availability.; \u2022    Ability to influence and steer technical direction.; \u2022    Front technical reviews with technical team.; \u2022    Involve in solutioning discussions with stakeholders.; \u2022    Provide guidance and mentorship to data engineers and analysts.; \u2022    Identify and assess new data technologies and tools, making recommendations for adoption.; \u2022    Ensure adherence to data governance and security policies.; \u2022    Monitor and optimize the performance and scalability of the data platform.; \u2022    Effectively communicate project progress and outcomes to stakeholders.; \u2022    Collaborate with the data management office to identify governance requirements and ensure integration with existing platforms.; \u2022    Implement data management best practices, including data cataloguing, lineage tracking, and metadata management within Azure.; \u2022    Oversee budgeting for data initiatives, ensuring resource allocation aligns with organizational goals.; \u2022    Provide ongoing maintenance and L3 support. ; Job Requirements; \u2022    Bachelor\u2019s degree in information technology, Computer Science, Data Science or equivalent; master\u2019s degree is a plus.; \u2022    Min. 8 years of working experience in management information systems, regulatory reporting, data management or data analytics role within Banks\/Financial Institutions. ; \u2022    Experience in leading mid-sized project implementation.; \u2022    Understand bank product, services, regulatory environment and customer needs;   \u2022    Understand bank traditional product and services for all commercial banking product; \u2022    Proficient in System Development Life Cycle (SDLC)\/Agile project delivery framework.; \u2022    Demonstrated ability to design and implement scalable data solutions on Azure.; \u2022    Excellent analytical, problem-solving, and communication skills.; \u2022    Relevant certifications in Azure (e.g., Microsoft Certified: Azure Data Engineer Associate); \u2022    Experience leading cross-functional teams and managing stakeholder relationships.; \u2022    Experience in Microsoft Azure, data management, data warehousing, data mart, data visualization, design and implementation will be advantageous.; \u2022    Knowledge in Financial Accounting, Management Accounting & Regulatory Reporting, Risk Management, Capital \/ Profitability Management would be a plus.; \u2022    Certifications such as PMP, PRINCE2, SCRUM, ITIL is a plus.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85207528","Role":"Data Engineer (Intern)","Company":"LHN Group Pte Ltd","Location":"East Region","Publish_Time":"2025-06-25 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85207528","job_desc":"We are seeking a highly motivated and inquisitive Data Engineering Intern to assist in the design, development, and maintenance of a new data warehouse on the AWS cloud platform. You will play a crucial role in building and optimizing data pipelines to extract, transform, and load (ETL) data from various sources. This is an excellent opportunity to gain hands-on experience with real-world data engineering challenges and contribute to the growth of a dynamic company.; Key Responsibilities:; \u00b7 Assist in the design and development of the data warehouse architecture on AWS.; \u00b7 Develop and maintain data pipelines using AWS services like AWS Glue, AWS S3, AWS Redshift\/Aurora.; \u00b7 Extract, transform, and load data from various sources (NetSuite, Salesforce, SharePoint, other SaaS & internal systems) into the data warehouse.; \u00b7 Ensure data quality and integrity throughout the data pipeline.; \u00b7 Collaborate with data analysts and business users to understand their data needs and requirements.; \u00b7 Assist in the development of data quality checks and monitoring processes.; \u00b7 Learn and apply best practices in data engineering and cloud computing.; \u00b7 Document all data pipelines and processes.; \u00b7 Support the development and maintenance of data models.; Requirements; \u00b7 Currently pursuing a Bachelor's or Master's degree in Computer Science, Data Science, or a related field.; \u00b7 Strong understanding of data warehousing concepts and principles.; \u00b7 Experience with SQL and a scripting language like Python.; \u00b7 Basic understanding of cloud computing concepts and AWS services (preferred).; \u00b7 Familiarity with data modeling and data visualization tools (a plus).; \u00b7 Excellent analytical and problem-solving skills.; \u00b7 Strong communication and interpersonal skills.; \u00b7 Ability to work independently and as part of a team.; \u00b7 Passion for learning new technologies and solving challenging problems.","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"83923444","Role":"Data Engineer, ITD (1 year contract)","Company":"Public Service Division","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83923444","job_desc":"[What the role is]; About EDB; The Singapore Economic Development Board (EDB), a government agency under the Ministry of Trade and Industry, is responsible for strategies that enhance Singapore\u2019s position as a global centre for business, innovation, and talent. We undertake investment promotion and industry development, and work with international businesses, both foreign and local, by providing information, connection to partners and access to government incentives for their investments. Our mission is to create sustainable economic growth, with vibrant business and good job opportunities for Singapore.; For more information on EDB, please visit www.edb.gov.sg; Why join EDB?; As a Data Engineer, you will be assisting in the maintenance and support of EDB\u2019s data products. You will be working closely with our divisions on their needs to leverage data for strategy formulation, policy implementation and decision making.; The work streams that you could be involved include:; \u2022 Data Science: You will work closely with our Data Scientist(s) to procure and prepare the data, and to convert them into operating models for businesses\u2019 day-to-day use; \u2022 Business Intelligence: You will assist in the integration and structuring of data from various sources to create interactive, real-time dashboards for decision making.; \u2022 Data Architecture and Governance: You will assist in defining scalable data architecture for EDB\u2019s analytics and reporting needs, building data pipelines and related elements of the architecture, and developing the governance to ensure data quality.; [What you will be working on]; Your roles and responsibilities would include the following:; Support the daily operations of the data platform (e.g. handling error notifications, job monitoring & recovery, testing data pipelines);; Investigate and troubleshoot reported incidents related to technical setup (e.g. connectivity failure, API timeout, service failure);; Document changes to existing setup (e.g. data sources, pipelines, accounts);; Research, propose and document technical requirements;; Review and implement fixes for reported security vulnerabilities;; Collaborate with the infrastructure team on the data team requests;; Support product managers in cloud transformation journey for data products;; Provide technical support and consultancy to business users;; Develop reports to monitor usage, performance and security events;; Generate mockup data and create unit tests;; Set up DevOps pipelines;; Optimise performance of data pipelines;; Review data pipelines to ensure adherence to data management standards, policies and procedures.; JOB REQUIREMENTS; To meet the challenges of this role, you must have\/ be:; Minimum of Bachelor\u2019s Degree in Computer Science, Computer Engineering, or related disciplines;; 5-8 years of work experience in Data Engineering; AWS experience in implementing or operating a data management solution for analytics; SQL scripting experience to analyze, transform and integrate data sources;; Proficient in building a data pipeline using Python and pySpark; Ability to work effectively under time constraints and potentially changing priorities, while maintaining a high level of attention to details;; Ability to work independently; and; Singaporean.; ; Good to have:; Experience in developing dashboards;; Experience IT infrastructure (server, database, network administration experience is an advantage);; Experience or certification in Tableau Server administration;; Experience or certification in Talend administration;; Experience or certification in MS SQL Server administration;; Proficient in PowerShell;; Experience in SHIP-HATS or DevOps tools;; Proficient in Terraform or IaC;; Experience in dashboard UX design;; Experience with agile or other rapid application development methodologies;; [What we are looking for]","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84995480","Role":"Senior Data Engineer - A25054","Company":"Activate Interactive Pte Ltd","Location":"Central Region","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84995480","job_desc":"About the job; Activate Interactive Pte Ltd (\"Activate\") is a leading technology consultancy headquartered in Singapore with a presence in Malaysia and Indonesia. Our clients are empowered with quality, cost-effective, and impactful end-to-end application development, like mobile and web applications, and cloud technology that remove technology roadblocks and increase their business efficiency.; ; We believe in positively impacting the lives of people around us and the environment we live in through the use of technology. Hence, we are committed to providing a conducive environment for all employees to realise their full potential, who in turn have the opportunity to continuously drive innovation.; ; We are searching for our next team members to join our growing team.; ; If you love the idea of being part of a growing company with exciting prospects in mobile and web technologies that create positive impact on people's lives, then we would love to hear from you.; ; Technology Solutions Office is looking for Senior Data Engineer; ; Internal Code: A25054; ; What will you do?; Lead a team of data engineers to design and develop robust data architectures that meet key business needs; Design, build, and maintain scalable data pipelines to handle large volumes of data; Collaborate with cross-functional teams to define data requirements and deliver quality solutions; Implement data governance and data quality methodologies to ensure data integrity; Utilize advanced analytics and data transformation techniques to derive insights and provide strategic recommendations; Mentor and train junior data engineers to enhance their skills and knowledge in data technologies; Requirements; ; What are we looking for?; At least 5 years of experience in data engineering, with a proven track record of leading data projects; Strong proficiency in data engineering tools and technologies including AWS, Azure, SQL, Python, and Spark; Extensive experience with data modeling, ETL processes, and big data technologies; Familiarity with data visualization tools like Tableau, Power BI, or similar; Experience with machine learning concepts and frameworks is a plus; Demonstrated ability to communicate effectively with technical and non-technical stakeholders; Strong problem-solving skills and ability to work in a fast-paced environment; Bachelor's or Master's degree in Computer Science, Data Science, or a related field; Benefits; ; What do we offer in return?; Fun working environment; Employee Wellness Program; Does it sound like something you are interested in exploring further? Please be in touch with our team for an initial chat at careers@activate.sg; ; Activate Interactive Singapore is an equal opportunity employer. Employment decisions will be based on merit, qualifications and abilities. Activate Interactive Pte Ltd does not discriminate in employment opportunities or practices on the basis of race, colour, religion, national origin, age, disability, marital status or any other characteristics protected by law.; ; Protecting your privacy and the security of your data are longstanding top priorities for Activate Interactive Pte Ltd.; ; Your personal data will be processed for the purposes of managing Activate Interactive Pte Ltd's recruitment related activities, which include setting up and conducting interviews and tests for applicants, evaluating and assessing the results, and as is otherwise needed in the recruitment and hiring processes.; ; Please consult our Privacy Notice (https:\/\/www.activate.sg\/privacy-policy) to know more about how we collect, use, and transfer the personal data of our candidates. Here you can find how you can request for access, correction and\/or withdrawal of your Personal Data.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85632190","Role":"Principal Cloud Engineer - Data & AI","Company":"Equinix Asia Pacific","Location":"Queenstown","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85632190","job_desc":"Who are we?; Equinix is the world\u2019s digital infrastructure company, operating over 260 data centers across the globe. Digital leaders harness Equinix's trusted platform to bring together and interconnect foundational infrastructure at software speed. Equinix enables organizations to access all the right places, partners and possibilities to scale with agility, speed the launch of digital services, deliver world-class experiences and multiply their value, while supporting their sustainability goals.; ; Our culture is based on collaboration and the growth and development of our teams. We hire hardworking people who thrive on solving challenging problems and give them opportunities to hone new skills and try new approaches, as we grow our product portfolio with new software and network architecture solutions. We embrace diversity in thought and contribution and are committed to providing an equitable work environment that is foundational to our core values as a company and is vital to our success.; Job Summary; We\u2019re looking for a Principal Cloud Engineer with a strong foundation in Multi-Cloud & multi region deployment, data architecture, distributed systems, and modern cloud-native platforms to architect, build, and maintain intelligent infrastructure and systems that power our AI, GenAI and data-intensive workloads.; You\u2019ll work closely with cross-functional teams, including data scientists, ML & software engineers, and product managers & play a key role in designing a highly scalable platform to manage the lifecycle of data pipelines, APIs, real-time streaming, and agentic GenAI workflows, while enabling federated data architectures. The ideal candidate will have a strong background in building and maintaining scalable AI & Data Platform, optimizing workflows, and ensuring the reliability and performance of Data Platform systems.; Responsibilities; Cloud Architecture & Engineering; Deep expertise in designing, implementing, and managing architectures across multiple cloud platforms (e.g., AWS, Azure, GCP); Proven experience in architecting hybrid and multi-cloud solutions, including interconnectivity, security, workload placement, and DR strategies; Strong knowledge of cloud-native services (e.g., serverless, containers, managed databases, storage, networking); Experience with enterprise-grade IAM, security controls, and compliance frameworks across cloud environments; AI & GenAI Platform Integration; Integrate LLM APIs (OpenAI, Gemini, Claude, etc.) into platform workflows for intelligent automation and enhanced user experience; Build and orchestrate multi-agent systems using frameworks like CrewAI, LangGraph, or AutoGen for use cases such as pipeline debugging, code generation, and MLOps; Experience in developing and integrating GenAI applications using MCP and orchestration of LLM-powered workflows (e.g., summarization, document Q&A, chatbot assistants, and intelligent data exploration); Hands-on expertise building and optimizing vector search and RAG pipelines using tools like Weaviate, Pinecone, or FAISS to support embedding-based retrieval and real-time semantic search across structured and unstructured datasets; Engineering Enablement; Create extensible CLIs, SDKs, and blueprints to simplify onboarding, accelerate development, and standardize best practices; Streamline onboarding, documentation, and platform implementation & support using GenAI and conversational interfaces; Collaborate across teams to enforce cost, reliability, and security standards within platform blueprints.; Work with engineering by introducing platform enhancements, observability, and cost optimization techniques; Foster a culture of ownership, continuous learning, and innovation; Automation, IaC, CI\/CD; Mastery of Infrastructure as Code (IaC) tools \u2014 especially Terraform, Terragrunt, and CloudFormation \/ ARM \/ Deployment Manager; Experience building and managing cloud automation frameworks (e.g., using Python, Go, or Bash for orchestration and tooling); Hands-on experience with CI\/CD pipelines (e.g., GitHub Actions) for cloud resource deployments; Expertise in implementing policy-as-code & Compliance-as-code (e.g., Open Policy Agent, Sentinel); Security, Governance & Cost; Strong background in implementing cloud security best practices (network segmentation, encryption, secrets management, key management, etc.).; Experience with multi-account \/ multi-subscription \/ multi-project governance models, including landing zones, service control policies, and organizational structures; Ability to design for cost optimization, tagging strategies, and usage monitoring across cloud providers; Monitoring & Operations; Familiarity with cloud monitoring, logging, and observability tools (e.g., CloudWatch, Azure Monitor, GCP Operations Suite, Datadog, Prometheus); Experience with incident management and building self-healing cloud architectures; Platform & Cloud Engineering; Develop and maintain real-time and batch data pipelines using tools like Airflow, dbt, Dataform, and Dataflow\/Spark; Design and develop event-driven architectures using Apache Kafka, Google Pub\/Sub, or equivalent messaging systems; Build and expose high-performance data APIs and microservices to support downstream applications, ML workflows, and GenAI agents; Architect and manage multi-cloud and hybrid cloud platforms (e.g., GCP, AWS, Azure) optimized for AI, ML, and real-time data processing workloads; Build reusable frameworks and infrastructure-as-code (IaC) using Terraform, Kubernetes, and CI\/CD to drive self-service and automation; Ensure platform scalability, resilience, and cost efficiency through modern practices like GitOps, observability, and chaos engineering; Leadership & Collaboration; Experience leading cloud architecture reviews, defining standards, and mentoring engineering teams; Ability to work cross-functionally with security, networking, application, and data teams to deliver integrated cloud solutions; Strong communication skills to engage stakeholders at various levels, from engineering to executives; Qualifications; 15+ years of hands-on experience in Platform or Data Engineering, Cloud Architecture, Multi-Cloud Multi-Region Deployment & Architecture, AI Engineering roles; Strong programming background in Java, Python, SQL, and one or more general-purpose languages; Deep knowledge of data modeling, distributed systems, and API design in production environments; Proficiency in designing and managing Kubernetes, serverless workloads, and streaming systems (Kafka, Pub\/Sub, Flink, Spark); Experience with metadata management, data catalogs, data quality enforcement, and semantic modeling & automated integration with Data Platform; Proven experience building scalable, efficient data pipelines for structured and unstructured data; Experience with GenAI\/LLM frameworks and tools for orchestration and workflow automation; Experience with RAG pipelines, vector databases, and embedding-based search; Familiarity with observability tools (Prometheus, Grafana, OpenTelemetry) and strong debugging skills across the stack; Experience with ML Platforms (MLFlow, Vertex AI, Kubeflow) and AI\/ML observability tools; Prior implementation of data mesh or data fabric in a large-scale enterprise; Experience with Looker Modeler, LookML, or semantic modeling layers; Preferred Certifications; AWS Certified Solutions Architect \u2013 Professional; Google Professional Cloud Architect; Microsoft Certified: Azure Solutions Architect Expert; HashiCorp Certified: Terraform Associate; Other relevant certifications (CKA, CKS, CISSP cloud concentration) are a plus.; Why You\u2019ll Love This Role; Drive technical leadership across AI-native data platforms, automation systems, and self-service tools; Collaborate across teams to shape the next generation of intelligent platforms in the enterprise; Work with a high-energy, mission-driven team that embraces innovation, open-source, and experimentation; Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.; Equinix is an Equal Employment Opportunity and, in the U.S., an Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to unlawful consideration of race, color, religion, creed, national or ethnic origin, ancestry, place of birth, citizenship, sex, pregnancy \/ childbirth or related medical conditions, sexual orientation, gender identity or expression, marital or domestic partnership status, age, veteran or military status, physical or mental disability, medical condition, genetic information, political \/ organizational affiliation, status as a victim or family member of a victim of crime or abuse, or any other status protected by applicable law.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85156727","Role":"Senior Data Architect (Networks)","Company":"Singapore Telecommunications Limited","Location":"Singapore","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85156727","job_desc":"At Singtel, we believe in the strength of a vibrant, diverse and inclusive workforce where backgrounds, perspectives and life experiences of our people help us innovate and create strong connections with our customers. We strive to ensure all our people practices are non-discriminatory and provide a fair, performance-based work culture that is diverse, inclusive and collaborative. Join us and experience what it\u2019s like to be with an Employer of Choice*. Together, let\u2019s create a brighter digital future for all. *Awarded at the HR Fest Awards 2020.; Singtel Networks, the most established telecommunications infrastructure provider in Singapore is transforming to enable the digital generation of tomorrow. We are introducing new capabilities in 5G, Cloud, Analytics, Digital Commerce, Software Engineering, Cyber Security to enhance our core competencies and deliver innovative and differentiated Mobile and Fixed services (Broadband, TV and Telephony) for our customers. We are committed to celebrating inclusion and diversity and is a strong believer to upskill and nurture all individuals. Come join us today as we build Singtel\u2019s Networks of tomorrow, and Empower Every Generation to live, work and play in new ways!; Make an Impact by:; Lead and manage cloud data lake or solution initiative including design and determine the SaaS or software to be used for the data processing and pipeline for ETL, Streaming, analytics, AI\/ML and APIs.; Establish and lead the Day 2 operation process, SLO\/SLA, data off-premise clearance and security governance for cloud data pipeline.; Manage Networks data governance for the department and support in Group data governance and data protection framework.; Perform as Tier 3 Systems SME\uf0a7    Accountable for overall System Performance and Design.\uf0a7    Accountable for Change Management outcomes, executing minor to major software upgrades as well as solution changes independently.\uf0a7    Responsible to manage vendors and technically debate on optimum solution performance while ensuring robust and cost-efficient architecture. ; Lead and manage Tier 2 Systems Administration & Operation Support.; Accountable for System Security\uf0a7    Management of Anti-Malware systems and perform monthly scanning for any security threats and system administration and perform monthly scanning for systems.\uf0a7    Analyse security reports from Anti-Malware scans, determining best course of action.\uf0a7    Administrator for the firewalls and perform the quarterly review for the rules to ensure the system defence-in-depth and security.; Responsible for Information Security (InfoSec) governance, serving as the Security representative for the department or division. ; Responsible for architecting network and IP address designs, as well as implementing data protection and security measures.; Lead Incident Management and provide timely update to the Management and accountable for the RCA of the managed platforms.; Conduct research and development (R&D) or proof of concept (POC) on new technologies or proposals provided by the vendor.; Ensure operational processes for the respective systems are well documented. This includes system inventories, solution doc, IP\/Network design, SOPs etc.; Lead system audits, oversee security review submissions, and manage the Business Continuity Management (BCM) for the department.;  Skills for Success:; Degree in Engineering or IT.; At least 5 years\u2019 experience in data solution and administration.; Experience in Cloud Data solution (AWS, Microsoft Azure, etc), On-premise data platform on HPE Ezmeral, Stream data platform in Kafka and Confluent, On-premise system implementation, System.; Able to handle Data Architect, mapR, Hadoop and Spark (or equivalent).; Has knowledge in Linux\/Unix, Ansible automation, Shell Scripting, Kubernetes, Docker, serverless functions, APIs and Kafka bus, Network, IP Address and Security design.; Rewards that Go Beyond:; \u2022    Hybrid work arrangements; \u2022    Full suite of health and wellness benefits ; \u2022    Ongoing training and development programs ; \u2022    Internal mobility opportunities; Are you ready to say hello to BIG Possibilities?; Take the leap with Singtel to unlock new opportunities and accelerate your growth. Apply now and start your empowering career!","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85706732","Role":"Senior Data Engineer, AI\/Machine Learning Lab","Company":"Changi Airport Group (Singapore) Pte. Ltd.","Location":"Changi","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85706732","job_desc":"About the job; As a Machine Learning Data Engineer at CAG, you will be responsible for designing, implementing, and maintaining the data pipelines and infrastructure that support our machine learning projects. You will work closely with data scientists, machine learning engineers, cloud engineer and other cross-functional teams to ensure the availability, reliability, and performance of our data systems. Your role will be critical in enabling the development and deployment of advanced machine learning models that drive key business insights and innovations.; This role requires a blend of technical expertise, project management skills, and the ability to deliver robust, scalable data solutions in a fast-paced environment.;   Responsibilities:; Architect and implement scalable data solutions to address complex business challenges, leveraging advanced analytics, statistical methods, and machine learning techniques. Apply advanced data preprocessing, transformation, and enrichment techniques to ensure high-quality inputs for machine learning models.; Partner with data scientists and ML engineers to translate data requirements into actionable insights, optimizing feature engineering processes and model deployment strategies.; Construct and manage modern data infrastructure, including data warehouses and data lakes, to facilitate seamless data access for analysis and model training.; Continuously optimize data pipelines for performance, scalability, and cost-effectiveness, considering factors such as data volume, processing speed, and resource utilization.; Collaborate closely with DevOps and IT teams to ensure smooth deployment, monitoring, and maintenance of data pipelines in production environments.; Work cross-functionally to ensure adherence to data governance, security, and privacy regulations.; Stay at the forefront of data engineering and machine learning advancements, driving the adoption of best practices within the team.; Mentor junior team members and contribute to the overall data strategy of the organization.; Requirements:; Bachelor's or Master's degree in Computer Science, Engineering, or a related field with at least 5 years\u2019 work experience; Extensive hands-on experience with cloud platforms, particularly AWS and GCP, including their data services and analytics offerings.; Strong coding skills with proficiency in:; Infrastructure as Code (e.g., Terraform, CloudFormation); Shell scripting; Python; SQL; Deep understanding of big data technologies, distributed computing, and modern data architecture patterns. Proven track record in designing and implementing large-scale data solutions, including data pipelines, data warehouses, and data lakes.; Demonstrated ability to successfully deliver projects, meet milestones, and drive initiatives from conception to production.; Experience with data streaming technologies (e.g., Kafka, Kinesis) and batch processing frameworks (e.g., Spark, Hadoop).; Familiarity with containerization and orchestration technologies (e.g., Docker, Kubernetes).; Strong problem-solving skills and ability to translate complex business requirements into technical solutions.; Excellent communication skills with the ability to collaborate effectively across cross-functional teams.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85041841","Role":"Full Stack Developer (AI\/ML & Data Engineering)","Company":"Websparks Pte Ltd","Location":"East Region","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85041841","job_desc":"[Contract Duration: 12 months]; Position Overview; We are seeking a motivated Junior Full Stack Developer with an interest in AI\/ML and data engineering to join our dynamic team. The ideal candidate will contribute to developing and maintaining web applications whilst learning to integrate AI\/ML components and handle data pipelines.; Key Responsibilities; \u2022 Develop and maintain web applications using modern frameworks and technologies, working across both frontend and backend development; \u2022 Assist in building and optimising data pipelines for machine learning models; \u2022 Collaborate with data scientists and ML engineers to implement AI\/ML solutions into production environments; \u2022 Write clean, maintainable, and efficient code following best practices and coding standards; \u2022 Participate in code reviews and contribute to technical documentation; \u2022 Support the testing and debugging of applications across different environments; Required Skills & Qualifications; \u2022 Bachelor's degree in Computer Science, Software Engineering, or related field; \u2022 Proficiency in at least one modern programming language (Python, JavaScript\/TypeScript, Java); \u2022 Basic understanding of web development frameworks (e.g., React, Angular, or Vue.js for frontend; Django, Node.js, or Flask for backend); \u2022 Familiarity with version control systems (Git) and collaborative development workflows; \u2022 Basic understanding of database systems (SQL and NoSQL); \u2022 Knowledge of RESTful APIs and web services; Preferred Skills; \u2022 Familiar AI\/ML RAG (Retrieval-Augmented Generation) MCP (Multi-Channel Processing) concepts; \u2022 Understanding of data processing libraries (Pandas, NumPy); \u2022 Familiarity with cloud platforms (AWS, GCP, or Azure); \u2022 Knowledge of containerisation (Docker) and orchestration tools; \u2022 Experience with CI\/CD pipelines; \u2022 Basic understanding of data structures and algorithms; Personal Qualities; \u2022 Strong problem-solving abilities and analytical mindset; \u2022 Eager to learn new technologies and adapt to changing requirements; \u2022 Excellent communication skills and ability to work in a team environment; \u2022 Self-motivated with good time management skills; \u2022 Attention to detail and commitment to code quality","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"80701492","Role":"Data Engineer (Credit Assessment) (In Partnership with IMDA)","Company":"Phillip Securities Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/80701492","job_desc":"Responsibilities:; Design and implement data pipelines to collect, store, and process data required.; Ensure data quality and integrity.; Develop APIs for integrating the credit assessment system with other applications.; Work with platform developers and product owners for the integration.; Requirements:; Degree in Computer Science, Data Science, Mathematics or a related IT field; Excellent time management, prioritization, and multitasking skills.; Strong interpersonal and communication skills.; Team-oriented, self-motivated and adaptable.; If you are looking for an environment of growth and opportunities, please write in with a detailed resume stating the position applied and expected salaries to the HR department via recruitment@phillip.com.sg.; We regret that only shortlisted candidates will be notified.; Brought to you by Phillip Securities Pte Ltd (A member of PhillipCapital)","salary":"","work_type":"","country":"singapore"}
{"Job_ID":"83649507","Role":"Senior Data Engineer","Company":"Mediacorp Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83649507","job_desc":"Job Description; PURPOSE OF THIS ROLE; The purpose of the Senior Data Engineer role is to provide strategic leadership in data engineering, overseeing the development and maintenance of data infrastructure, and ensuring the availability, reliability, and performance of data solutions. This position plays a critical role in supporting data-driven decision-making across the organization.; Key responsibilities include:; Providing strategic direction and technical leadership in data engineering.; Leading the design, development, and deployment of ETL processes and data pipelines.; Integrating data from various sources and transforming it for analytics.; Maintaining data quality and implementing data governance best practices.; Managing and mentoring a team of data engineers for professional growth.; Collaborating with stakeholders to understand and fulfil data requirements.; Documenting data processes, architectures, and best practices.; Challenges in this role may include:; Ensuring data security and compliance in a rapidly evolving regulatory environment.; Optimizing data infrastructure for performance and scalability.; Resolving data-related issues efficiently.; Managing a dynamic team in a fast-paced data environment.; FOUNDATIONAL\/LEADERSHIP COMPETENCIES; Strong leadership and team management skills.; Excellent problem-solving and communication skills.; FUNCTIONAL COMPETENCIES; Proficiency in programming languages such as Java, or Scala, SQL, Python.; Extensive experience with ETL tools, data integration, and data transformation.; In-depth knowledge of data storage technologies (relational databases, NoSQL, distributed file systems).; Expertise in data modelling, database design and data warehousing.; Familiarity with data governance, security, and compliance standards.; Experience with big data technologies (e.g., Hadoop, Spark, Hive, Azure, Databricks) is a plus.; Experience in container orchestration framework like Kubernetes is a plus.; Experience in Infrastructure as Code and DevOps, MLOps and DataOps is a plus.; Job Requirements; Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.; Relevant certifications in data engineering and Cloud computing are advantageous.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85044166","Role":"Data Analytics Engineer","Company":"Singapore University of Social Sciences","Location":"Singapore","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85044166","job_desc":"Who We Are; As Singapore's first institute for lifelong learning, the Singapore University of Social Sciences (SUSS) champions inclusivity to bring education to all and ensure that they are given equal opportunities to develop to their fullest potential in our diverse learning environment.; We advocate for the same for our people. We believe everyone should have equal opportunities and develop to their fullest potential in their careers.; Embark on an exciting lifelong journey with us in making a positive difference in your career and serving our society.; For more information on Singapore University of Social Sciences, please visit www.suss.edu.sg; About The Job; We are seeking a versatile and motivated individual to join our team as a Data Analytics Engineer (Entry Level). In this role, you will build and maintain scalable data pipelines, develop and deploy machine learning (ML) models, and support the university\u2019s data-driven initiatives using tools such as Microsoft Fabric, Azure Machine Learning, and Power BI. In addition to data and ML development, you will also serve as an administrator of Microsoft Fabric, the university\u2019s cloud analytics platform\u2014ensuring efficient operations, governance, and user support. This position is ideal for individuals who enjoy working across the full data and ML lifecycle\u2014from wrangling raw datasets to training models and supporting strategic decisions through analytics. You will be part of a collaborative, in-house data team addressing meaningful challenges in education and operations.; What You Will Be Doing; Key Responsibilities:; Data Engineering & Machine Learning Development; Design, build, and maintain scalable data pipelines using Microsoft Fabric components (e.g., Data Pipelines, Dataflows) and PySpark.; Ingest, clean, and transform data from diverse sources such as APIs, flat files, and databases.; Operate within the Lakehouse architecture to ensure reliable, well-governed data delivery.; Design, train, and evaluate models for classification, prediction, and segmentation use cases.; Perform feature engineering, model tuning, and validation.; Deploy models in collaboration with analytics specialists and contribute to building reusable ML feature stores.; Ensure data quality, documentation, and lineage are maintained across workflows.; Microsoft Fabric Administration & Analytics Support; Act as the primary administrator for Microsoft Fabric, overseeing workspace, capacity, and permission management.; Monitor usage, performance, and cost metrics; troubleshoot and optimise resource allocation.; Support onboarding of university teams to Microsoft Fabric and maintain security and compliance standards.; Manage workspace hygiene, archival, and governance enforcement across all Fabric artefacts.; Collaborate with the data warehouse team, analytics specialists, AI engineers, and domain users to deliver structured datasets and model outputs.; Assist in building and refining Power BI datasets and dashboards for decision-making support.; Job Requirements; Possess a degree in Data Science, Business Analytics or related.; Proficiency in SQL and Python, including libraries such as Pandas, Scikit-learn, and PySpark.; Strong interest or hands-on experience in end-to-end ML development (from data prep to deployment).; Familiarity with Microsoft Fabric components (e.g., Lakehouse, Data Pipelines, Dataflows).; Exposure to Power BI or equivalent BI\/visualisation tools.; Microsoft Fabric certification (or willingness to obtain one).; Exposure to Azure Machine Learning or similar ML model lifecycle platforms.; Practical experience (via internships, coursework, or projects) in data engineering or ML model development.; Understanding of higher education data or student analytics scenarios.; Curious and self-driven with a growth mindset.; Able to clearly explain technical concepts to both technical and non-technical audiences.; Strong attention to detail and a methodical, structured approach to solving problems.; What We Offer; At SUSS, we advocate the Spirit of Learning and pride ourselves as lifelong learners. You will gain access to various learning platforms and plenty of development opportunities to support your growth in a meaningful career!; Besides that, you will also get:; Competitive Pay Package; Hybrid Work Arrangement (Subject to Job Role); Medical Benefits; Flex Benefits; Family Care Leaves; Volunteer Service Leaves; Wellness & Recreation Activities; Lifelong Learning Opportunities; Career Development Opportunities through Internal Job Postings and Transfers","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"83482854","Role":"Data Engineer","Company":"SMRT Corporation Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83482854","job_desc":"The duties and responsibilities for Data Engineer, are as listed below. The list is not comprehensive and related duties and responsibilities may be assigned from time to time.; Data Engineering & Processing:; Develop and maintain data pipelines for efficient data ingestion and transformation.; Work with structured and unstructured data to ensure optimal storage and retrieval.; Perform data analysis and report on results.; Database Design & Management:; Design and implement relational and NoSQL database schemas for scalability.; Optimize database performance through indexing, partitioning, and query tuning.; Implement data security and compliance best practices.; API Development & Backend Engineering:; Design and develop APIs for data access and application integration.; Implement authentication, authorization, and API security best practices.; Cloud Infrastructure & Deployment (Supporting Role):; Assist in design Azure cloud architectures; Work with IT infrastructure team to set up cloud infrastructure for application hosting, data storage and processing. ; Collaboration & Best Practices:; Collaborate with internal stakeholders to understand their business needs.; Work with software engineers, data scientist, frontend developer to understand the data requirement and design architecture of the data platform.; Implement CI\/CD pipelines for automated testing, deployment and monitoring.; Write testable and maintainable code and documentation to deploy to production.; Engage continuously with end-user for feedback and improvements.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85041853","Role":"Software Developer (Automation and Integration), EDDC","Company":"A*STAR Research Entities (A*STAR)","Location":"Singapore","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85041853","job_desc":"Overview: EDDC is the national platform for drug discovery, committed to work with the Singapore ecosystem to translate scientific discoveries into life-changing therapeutics for patients. We leverage state-of-the-art computational and machine learning approaches to uncover insights from large-scale and multidimensional data sources, and to tackle complex and unmet medical challenges in disease areas such as oncology, inflammatory and autoimmune diseases; .; We are seeking a skilled Software Developer to join the computational sciences team to contribute significantly to building an organizational-wide ML\/AI-ready data foundation, focusing on laboratory automation, integration solutions, and software development. The role involves close collaboration with wet-lab scientists, computational scientists\/engineers, and IT teams to design, develop, and implement cost-effective, robust solutions utilizing a combination of commercial software and in-house development. Leveraging modern tech stacks and APIs, this position will facilitate seamless laboratory operations and data management in a multi-disciplinary environment with both biological and chemical data.; Key Responsibilities:; 1. Application Development and Integration:; Develop and maintain software solutions to integrate laboratory informatics systems with automated hardware systems and robotic laboratory equipment.; Automate workflows related to sample management, inventory tracking, assay preparation, and data analytics.; Collaborate with scientists and engineers to understand requirements and translate them into efficient software solutions.; 2. Legacy System Modernization; Assess existing systems, recommending and implementing modernization strategies that improve functionality, scalability, and ease of maintenance.; Utilize modern software frameworks, cloud-based technologies, and AI-driven coding tools, if relevant, to streamline system modernization.; 3. Data Integration and Automation; Develop API-driven integrations and automated workflows connecting laboratory software, hardware, and internal\/external databases.; Ensure robust, real-time synchronization of data across various laboratory systems.; Develop APIs and integration layers to connect applications cross different systems (e.g., chemical structure databases, property databases, and regulatory systems).; 4. ML\/AI-Ready Data Foundation Development:; Collaborate with computational scientists and data engineers to design and implement an organizational-wide ML-ready data foundation.; Develop tools and pipelines to ensure data is clean, well-structured, and accessible for machine learning and analytics.; Integrate data from diverse sources (e.g., compound registration, inventory tracking, laboratory systems, and external databases) into a unified data infrastructure.; 5. Communication and Collaboration; Work closely with wet-lab scientists, computational scientists, data engineers, and IT team to clearly identify requirements and collaboratively develop solutions.; Provide technical documentation, training, and support to users and stakeholders.; Work closely with the cross-functional colleagues and data engineer to ensure applications are compatible with the organization\u2019s data infrastructure and Single Source of Truth (SSOT) initiatives.; Required Skills\/Qualifications:; Bachelor\u2019s or Master\u2019s degree in Computer Science, Software Engineering, Automation Engineering, Bioinformatics or a related field.; 2-3 years of experience in software development, scripting, or automation-focused roles.; Strong proficiency in programming\/scripting languages (eg. Python, Java, SQL, etc.) and experience with RESTful API integration.; Experience in laboratory automation systems and developing integrations involving biological or chemical informatics.; Experience with legacy system modernization and cloud-based solutions.; Strong problem-solving skills and ability to work in a multidisciplinary environment.; Excellent communication and teamwork skills, capable of bridging computational and laboratory teams.; Preferred Skills\/Qualifications:; Familiarity with open-source integration platforms and workflow management tools (e.g., KNIME, Apache Airflow, SiLA2).; Experience using AI-assisted coding tools (e.g., GitHub Copilot, Cursor) to enhance productivity and streamline development workflows.","salary":"","work_type":"Kontrak\/Temporer, Full time","country":"singapore"}
{"Job_ID":"85072685","Role":"Intermediate DevOps Engineer (Capital Markets Front-to-Back Office, AWS...","Company":"ANTAES ASIA PTE. LTD.","Location":"Marina South","Publish_Time":"2025-06-20 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85072685","job_desc":"As an Intermediate DevOps Engineer, you will be immersed in real-life projects, shaping the future of capital markets software. You will have the support and guidance of an identified subject matter expert and participate in various communities.; Capital Markets IT involves technology solutions and systems used in financial markets for trading, investment, and related activities. This includes electronic trading platforms, risk management systems, market risk, counterparty risk, algorithmic trading, data analytics, and Regulatory measures. The use of advanced technologies like blockchain and artificial intelligence is also becoming increasingly prevalent in capital markets to enhance efficiency and decision-making processes; The Engineer will work on the main roles.; Industrialization: Implement all necessary tools to manage the environments, the continuous integration, the continuous delivery and the processes execution.; Environments: Manage and administrate environments from assembly to production (rules included), infrastructure implementation, operational usage.; Operations: Execute the maintenance operations, delivery and environment monitoring.; L3: Operate as L3 on non-production environments for delivery teams and also on production for support teams.; Job Responsibilities:; Participate to the automation of the deployment solution.; Participate in environment preparation for testing phases.; Participate in developing tools to simplify day-to-day activities on the program.; Facilitate coordination between program developers and infrastructure engineers.; Design, develop and test code using a modern CI-CD pipeline.; Implement proactive measures to enhance system reliability and performance.; Provide investigation help while fostering knowledge and sharing best practices with team members.; Stay updated on industry trends, emerging technologies, and regulatory changes relevant to capital markets.; Document processes and ensure their properly followed.; The position requires autonomy and reliability in performing duties while maintaining close communication with rest of project\/support team.; The position requires autonomy and reliability in performing duties while maintaining close communication with the rest of the project\/support team.; Job Requirements: Experience & Education Requirements; At least more than 5 years of experience in DevOps or development.; Master or Bachelor\u2019s degree in Computer Science\/ Information Technology\/ Programming & Systems Analysis\/ Science (Computer Studies) faculties.; AWS or GCP Cloud Certified; Technical; Experience in DevOps methodology & tools like GIT, Maven\/Graven\/Nuget\/Ansible, Jenkins\/TeamCIty, Ansible, CI\/CD pipeline.; Any Object-oriented language: Java, .Net; Strong knowledge in UNIX platform and any relational DB and language ( SQL, Oracle, Sybase, BigData); Proficiency in scripting languages (Python, Shell script, PowerShell, SQL) for automation and monitoring.; Valuable exposure to tools & technologies like Elastic Search, Grid computing, Grafana, Prometheus, Kibana, Control-M, KAFKA, Confluence, Jira, Tableau, PowerBI, MQ Series.; Experience with Docker\/Kurbernetes and Liquibase.; Functional; Experience in supporting capital market applications and trading systems, ideally within the dynamic landscape of Market Risk\/Front Office operations with a commendable grasp of financial products (Treasury, FX, Credit, IRD, Bonds, RSF etc.)","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85182819","Role":"DevOps Engineer (Developer) - Singapore","Company":"LUXOFT INFORMATION TECHNOLOGY (SINGAPORE) PTE. LTD.","Location":"Central Region","Publish_Time":"2025-06-26 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85182819","job_desc":"Project Description:; Our client is the corporate and investment banking arm of The Group, world's 12th largest bank by total assets.; We work daily with international branches located in 30 markets by:; Envisioning and preparing the Bank's futures information systems; Partnering and supporting core banking flagships and transverse areas in their large scale development projects.; Providing premium In-house Banking applications,; This unique positioning empowers us to bring our core banking business a sustainable competitive advantage on the market.; We seek innovative and agile people sharing our mindset to support ambitious and forthcoming technological challenges.; We are seeking a talented Engineer to join our dynamic Capital Markets IT Department!; You will be responsible for designing, implementing, and maintaining our infrastructure and automation tools. You will work closely with development teams to ensure smooth deployment and operation of our applications. You will be a key contributor to our continuous improvement efforts, ensuring our environments are always reliable, secure, and efficient.; You will be responsible for design, develop and implement comprehensive test strategy and test cases based on requirements and design documentation. Develop automated test systems to ensure reusability and efficiency and promote usage of testing methodologies aiming to identify and address defects early in the development lifecycle.; Capital Markets IT involves technology solutions and systems used in financial markets for trading, investment, and related activities. This includes electronic trading platforms, risk management systems, market risk, counterparty risk, algorithmic trading, data analytics, and regulatory measures. The use of advanced technologies like API's, artificial intelligence and cloud solutions are also becoming increasingly prevalent in capital markets to enhance efficiency and decision-making processes.; We are starting the decommissioning of our Kondor Plus trading platform for our Treasury business to transfer this activity to our main front office target platform (Orchestrade or OT). Orchestrade is already implemented for other asset classes.; The DeKOT project (decommissioning of Kondor+ to migrate into Orchestrade) will migrate our worldwide cross asset treasury platform (all products) booked in several instances of Kondor Plus. We are creating a team in Singapore to take in charge some part of the project (e.g. Inbound and outbound flows of the platform for various systems or modules, OT API and format such as Json, Protobuf, CIBML...). Performance and latency of those interfaces will be key for the success of the project.; With strong interactions with our Paris Head office team, the developer would put in place the first foundations of a development team based in Asia in Singapore. The developer joins a future team of Front Office developers that will grow and will be key in the future for our technology hub in Singapore. The team will be fully allocated to this project and will be part of a multi sites project team.; Responsibilities:; Research, design, and develop computer software or specialised utility programs.; Develop and maintain automation tools for infrastructure provisioning, configuration management, and deployment and quality assurance.; Collaborate with development teams to implement CI\/CD pipelines and automate deployment as well as test processes.; Work on the industrialization of test management.; Work on the management of OT DeKOT environments.; Work on the preparation\/industrialization of the transition to Run mode of Orchestrade for Treasury.; Monitor and troubleshoot infrastructure and application performance issues.; Implement security best practices and ensure compliance with industry standards.; Contribute to the development and improvement of our DevOps culture and processes.; Design and develop comprehensive quality assurance strategies and frameworks.; Implement automated testing systems to ensure reusability and efficiency.; Design and implement comprehensive test plans and test cases based on requirements and design documentation. Develop automated test systems to ensure reusability and efficiency.; Promote and implement testing methodologies, aiming to identify and address defects early in the development lifecycle.; Provide technical support to other teams, assisting with problems encountered internally, such as system malfunctions. Propose solutions, suggest improvements, and contribute to data analysis.; Document all testing activities, including test results, discovered defects, and any relevant observations. Prepare detailed reports for management and the Delivery Team; Stay up-to-date with the latest DevOps technologies and trends.; This position will be an important pillar of Support Orchestrade for Treasury. Gradually, this position will perform application support for users (Front to Back Office).; Mandatory Skills Description:; 5+ years of total working experience; Development in C# .net; Good exposure to DevOps tools & technologies like Gitlab, Ansible, Jenkins, Maven, Elastic Search, Grafana, Prometheus, Kibana, Control-M, KAFKA, Confluence, Jira, and MQ Series; Experience with Docker\/Kurbernetes; Knowledge of Cloud platforms and services; .net and Azure devops; Excellent communication and interpersonal skills to effectively collaborate with diverse teams.; Excellent problem-solving and analytical skills.; Ability to work under pressure.; Appetite to follow technology trend and participate to communities.; Eagerness to learn and adapt to new technologies.; Strong perseverance and diligence towards attaining goals and effective time management; Passion for sharing expertise and grow team members' skills.; Autonomous, self-motivated and excellent team player; Ability and flexibility to work with cross-geographical teams operating in different time zones.; Nice-to-Have Skills Description:; Exposure to test automation tools like Selenium (and other test automation frameworks), cucumber etc.; Experience with automation frameworks and libraries.; Proficiency in scripting languages such as Python, Shell script and PowerShell.; Good knowledge in UNIX platform and database management systems such as SQL, Oracle, Sybase.; Experience in supporting banking applications\/trading systems; Experience in supporting capital market applications and trading systems, ideally within the dynamic landscape of Front Office operations with a commendable grasp of financial products (Treasury, FX, Credit, IRD, Bonds, RSF etc.); Domain-Driven design and Microservices: Springboot","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85482196","Role":"Intern, Geospatial Data Engineering & Platform team","Company":"Public Service Division","Location":"Singapore","Publish_Time":"2025-07-03 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85482196","job_desc":"[What the role is]; The interns will be supporting the Geospatial Data Engineering & Platform team in the data operations revolving around the SLA Enterprise Data Platform. The operations involve: (1) onboarding of SLA data sets onto EDP Data Warehouse for publishing of data sets on EDP Data Portal (2) development of data engineering workload (data transformation pipelines) and dashboards\/reports for monitoring of system operating performance, auditorial insights, data quality and performance metrics.; [What you will be working on]; Assist in the development of building robust data ingestion pipelines to collect, clean, and merge data from diverse source systems; Develop, test, and maintain efficient, scalable, and reusable code for data pipelines; Develop, test, and maintain dashboards\/reports to serve the daily data operational needs.; Implement comprehensive validation processes and data quality checks to ensure data accuracy, consistency, and reliability.; Contribute to the documentation of data processes; [What we are looking for]; Pursuing tertiary qualifications in Data Science, Computer Science, or a related technical field; Strong analytical skills with demonstrable experience in data analysis tools, preferably Python and SQL; Ability to write efficient, well-documented code and think critically about edge cases and error handling; Familiarity with data management concepts, data engineering techniques, and ETL processes; Strong communication skills and ability to work effectively in a team environment; Able to commit between July 2025 to December 2025; Please include your availability in your CV.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85186601","Role":"Azure DevOps Engineer Skilled with C# (5~9 years of experience)","Company":"LUXOFT INFORMATION TECHNOLOGY (SINGAPORE) PTE. LTD.","Location":"Central Region","Publish_Time":"2025-06-26 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85186601","job_desc":"Responsibilities:; Research, design, and develop computer software or specialised utility programs.; Develop and maintain automation tools for infrastructure provisioning, configuration management, and deployment and quality assurance.; Collaborate with development teams to implement CI\/CD pipelines and automate deployment as well as test processes.; Work on the industrialization of test management.; Work on the management of OT DeKOT environments.; Work on the preparation\/industrialization of the transition to Run mode of Orchestrade for Treasury.; Monitor and troubleshoot infrastructure and application performance issues.; Implement security best practices and ensure compliance with industry standards.; Contribute to the development and improvement of our DevOps culture and processes.; Design and develop comprehensive quality assurance strategies and frameworks.; Implement automated testing systems to ensure reusability and efficiency.; Design and implement comprehensive test plans and test cases based on requirements and design documentation. Develop automated test systems to ensure reusability and efficiency.; Promote and implement testing methodologies, aiming to identify and address defects early in the development lifecycle.; Provide technical support to other teams, assisting with problems encountered internally, such as system malfunctions. Propose solutions, suggest improvements, and contribute to data analysis.; Document all testing activities, including test results, discovered defects, and any relevant observations. Prepare detailed reports for management and the Delivery Team; Stay up-to-date with the latest DevOps technologies and trends.; This position will be an important pillar of Support Orchestrade for Treasury. Gradually, this position will perform application support for users (Front to Back Office).; Mandatory Skills Description:; 5+ years of total working experience; Development in C# .net; Good exposure to DevOps tools & technologies like Gitlab, Ansible, Jenkins, Maven, Elastic Search, Grafana, Prometheus, Kibana, Control-M, KAFKA, Confluence, Jira, and MQ Series; Experience with Docker\/Kurbernetes; Knowledge of Cloud platforms and services; .net and Azure devops; Excellent communication and interpersonal skills to effectively collaborate with diverse teams.; Excellent problem-solving and analytical skills.; Ability to work under pressure.; Appetite to follow technology trend and participate to communities.; Eagerness to learn and adapt to new technologies.; Strong perseverance and diligence towards attaining goals and effective time management; Passion for sharing expertise and grow team members' skills.; Autonomous, self-motivated and excellent team player; Ability and flexibility to work with cross-geographical teams operating in different time zones.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85176997","Role":"Product Solution Architect (Edge Cloud)","Company":"BYTEDANCE PTE. LTD.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85176997","job_desc":"Product Solution Architect (Edge Cloud); Singapore Regular Product Job ID: A133569A; Responsibilities; About the team The ByteDance edge cloud serves as the world's premier edge cloud computing service, offering enterprise users with worldwide content distribution, edge security, edge AI, and lightweight computing services. In line with our commitment to excellence, we are in search of a senior product solution architect to construct competitive product solutions for clients, expedite commercial expansion, and heighten the influence of products in the market as well as ultimately customer satisfaction. Responsibilities: - Be responsible for the architectural design and research and development of edge cloud product solutions, manage the full life cycle of edge cloud solutions. - Ensure high-quality delivery of edge cloud projects, coordinating pipeline building and project delivering. - Develop and implement operational strategies and processes that enhance commercialization processes and optimize resource utilization. - Based on monitoring data and operational metrics, driving continuous improvement in service delivery and customer experience.; Qualifications; Minimum Requirements: - Proven years of experience in CDN, Edge Computing, Networking, Security, or related fields, with a deep understanding of public cloud products. - Excellent client-facing skills with the ability to articulate commercial and technical solutions to international audience. - Self-motivated and optimistic, with a strong drive to collaborate with sales and product and development teams to facilitate customer conversion. Preferred qualifications: - Strong familiarity with global market demands, particularly in specific regions such as Vietnam or the Philippines market; Job Information; Inspiring creativity is at the core of ByteDance's mission. Our innovative products are built to help people authentically express themselves, discover and connect \u2013 and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and enrich life - a mission we work towards every day.; As ByteDancers, we strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. By constantly iterating and fostering an \"Always Day 1\" mindset, we achieve meaningful breakthroughs for ourselves, our Company, and our users. When we create and grow together, the possibilities are limitless. Join us.; Diversity & Inclusion; ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Apply; Share to","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"82179488","Role":"Full Stack Developer \/ Engineer","Company":"Rapsodo Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/82179488","job_desc":"Rapsodo is a Sports Technology company with offices in the USA, Singapore, Turkey & Japan. We develop sports analytics products that are data-driven, portable and easy-to-use to empower athletes at all skill levels to analyse and improve their performance. From Major League Baseball star pitchers to Golf tour players, athletes use Rapsodo technology to up their game across the world. Trusted by coaches and players from youths to professionals, Rapsodo provides real-time insights for all-time performance.; We are innovative, focused, and rapidly growing. We are continuously looking for team players who will stop at nothing to deliver state-of-the-art solutions as part of Team Rapsodo.; As a Full Stack Developer, you will design, develop, and deploy robust, secure, and user-centric applications while leveraging the power of cloud technologies. You will work across the entire tech stack, ensuring our applications are scalable, efficient, and aligned with business goals.; Location:; Singapore; Key Responsibilities:; Develop Full-Stack Applications: Design, build, and maintain responsive front-end interfaces and secure, scalable back-end services.; Cloud Integration: Leverage cloud platforms (AWS, Azure, Google Cloud) to develop and deploy cloud-native solutions, ensuring optimal scalability and performance.; Collaborate Across Teams: Work closely with product managers, designers, and DevOps engineers to deliver seamless user experiences.; Optimize Performance: Ensure applications perform reliably under high usage, implementing best practices for scalability and security.; Innovate: Stay ahead of industry trends and bring new ideas to enhance our offerings.; Requirements; 8+ years in full-stack development with expertise in front-end frameworks (React, Angular, or Vue.js) and back-end technologies (Node.js, Python, Go, etc.).; Hands-on experience with cloud platforms such as AWS, Azure, or Google Cloud.; Strong understanding of CI\/CD pipelines and DevOps tools.; Proficiency in building RESTful APIs and microservices architecture.; Familiarity with containerization (Docker, Kubernetes) and serverless computing.; Experience with both SQL and NoSQL databases.; Excellent problem-solving and analytical abilities.; Strong communication skills to work effectively with cross-functional teams.; Self-motivated, team-oriented, and driven to innovate.; A natural curiosity for new technologies and trends in cloud computing and software development.; We are a global leader in sports vision technology, powered by a team that believes in failing fast, learning faster, and winning as a team. At Rapsodo, you'll thrive in a culture driven by customer focus, achieving more with less, and redefining what's possible. If you are eager to work independently while contributing to a dynamic, innovative, and passionate team, we encourage you to submit your application.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85068751","Role":"Cloud Solution Architect","Company":"Upskills Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-19 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85068751","job_desc":"Raffles Quay, Singapore | Posted on 06\/17\/2025; KLAARA specializes in providing AI-driven solutions tailored to the needs of customers in the Capital Markets, Insurance, Reinsurance, and various other organizations. Our cutting-edge platform empowers businesses to transform their unstructured data into actionable intelligence, fueling better decision-making and driving competitive advantage.; We are seeking a highly-skilled Solution Architect to lead the Infrastructure and Cloud Architecture of our AI-driven platform, particularly in the financial and banking sectors. In this role, you will be responsible for designing scalable, secure, and resilient cloud-native environments that support complex AI\/ML workloads within the firm and at customer sites, ensuring optimal instrumentation, scalability, and compliance with security standards.; You will collaborate closely with cross-functional teams including Machine Learning Engineering, Security, Software Engineers, Business Analysts, and Customers to ensure seamless delivery, performance testing, and documentation of our solutions. This is a hands-on role requiring strong technical acumen, cross-functional teamwork, and occasional code fixes. You are expected to:; Design, implement, and manage scalable cloud infrastructure (AWS, Azure, or GCP) tailored for AI\/ML workloads.; Lead and execute the implementation of software deployment packages at customer sites, ensuring robust instrumentation and scalable performance.; Design, develop, and execute load and scalability tests to validate system reliability under various conditions.; Implement and maintain monitoring and alerting systems to proactively identify and resolve issues in development, staging, and production environments.; Participate in incident response, root cause analysis, and contribute to continuous improvement of system reliability.; Develop and maintain automation scripts and tools to streamline deployment, infrastructure provisioning, and routine operational tasks.; Create and maintain clear, comprehensive documentation for customers on deployment, configuration, and operations.; Collaborate with internal development teams, business analysts, and customers to align technical solutions with business requirements.; Troubleshoot and resolve deployment and integration issues, occasionally contributing fixes in TypeScript or Rust.; Ensure compliance with security and regulatory requirements, particularly in Banking environments.; Maintain and optimize CI\/CD and MLOps pipelines and deployment automation using Jenkins and Atlassian tools.; Manage and maintain development, staging, and production environments, ensuring consistency and high availability.; Support and manage infrastructure components using Linux, Docker, and Kubernetes.; Integrate and manage application components such as Kong, OpenTelemetry, Kafka, RabbitMQ, and MySQL.; Work with systems designed using microservice architecture, ensuring seamless deployment and integration across services.; Utilize Infrastructure as Code (IaC) tools such as Terraform, Ansible, or Helm to provision and manage infrastructure effectively.; Requirements; Ph.D. or Master's Degree in Information Technology, Computer Science, Engineering, or related field.; Minimum of 10 years of experience in Cloud Operations, Infrastructure Engineering, and Automation, with at least 5 years in AWS or similar Cloud operations (Azure, GCP), preferably within Banking or Financial Services industry.; Proven experience with CI\/CD tools such as Jenkins and the Atlassian suite (Bitbucket, Jira, Confluence).; Solid understanding of mainstream cloud products and services including AWS, Azure, GCP, and OpenShift.; Hands-on experience with Linux, Docker, Kubernetes, and cloud-native deployment practices.; Solid understanding of microservice architecture and deploying and managing distributed systems.; Experience with monitoring and observability tools, especially OpenTelemetry, and managing alerts and incident response processes.; Proficiency in automation and scripting (e.g., Bash, Python, or similar) for deployment and infrastructure tasks.; Experience in building and implementing Infrastructure as Code (IaC) tools such as Terraform or Open Tofu.; Experience with API and Microservices architecture patterns for deploying ML models on cloud.; Familiarity with API gateways (e.g., Kong), message brokers (Kafka, RabbitMQ), and databases (MySQL, PostgreSQL).; Ability to design and execute performance, load, and scalability tests.; Basic proficiency in TypeScript and\/or Rust, sufficient for reading code and implementing minor fixes.; Strong understanding of security, compliance, and risk management practices in financial services or banking.; Excellent communication and collaboration skills; able to interact with technical and non-technical stakeholders.; Skill set; AWS, Azure, GCP, Linux, OpenShift, Redhat, SQL, Solution Architect, Cloud Computing, AI, Fintech, Banking, Infrastructure, Java, MLOps.; #J-18808-Ljbffr","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85832331","Role":"Cloud Engineer (Intern)","Company":"MSD","Location":"Singapore","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85832331","job_desc":"Job Description; Job description; Design & develop robust, scalable, and serverless solutions to meet business needs; Utilise data visualisation tools to transform raw data into meaningful insights; Create efficient database models to support application requirements; Develop and sustain automated processes and deployment pipelines to ensure smooth and continuous integration and delivery; Contribute to technical documentation and perform testing throughout the software development lifecycle.; Apply Agentic AI solutions to address specific use cases related to cloud cost insights; Requirements; Currently pursuing an undergraduate degree in Computer Science, Information Systems, or a related field.; Proficient in Python programming.; Skilled in using data visualisation tools such as Power BI or Spotfire.; Familiar with various databases, including SQL, NoSQL, and DynamoDB.; Basic knowledge of front-end languages like JavaScript, HTML, and CSS is a plus.; Interested in cloud computing platforms such as AWS and Azure.; Familiarity with Agentic AI solutions is a plus.; Experienced with PowerPoint, Word, Excel, and other Office 365 products.; Excellent verbal, written, and documentation skills.; Strong analytical and problem-solving skills.; Demonstrates a continuous learning attitude and thrives in an agile work environment.; Fast and independent learner; Able to commit to at least 6 months for this internship; Learning outcomes for the intern; Gain valuable exposure and hands-on experience in the cloud computing and FinOps domains.; Experience working in an agile environment and a global setup, enhancing your adaptability and collaboration skills.; Receive ongoing training on various skills, competencies, and tools to support your professional growth.; Engage with a wide range of technologies, including serverless architectures, Infrastructure as Code, DevOps practices, APIs, AI, and more.; Current Employees apply HERE; Current Contingent Workers apply HERE; Search Firm Representatives Please Read Carefully ; Merck & Co., Inc., Rahway, NJ, USA, also known as Merck Sharp & Dohme LLC, Rahway, NJ, USA, does not accept unsolicited assistance from search firms for employment opportunities. All CVs \/ resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company.  No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position specific. Please, no phone calls or emails. ; Employee Status:; Intern\/Co-op (Fixed Term); Relocation:; VISA Sponsorship:; Travel Requirements:; Flexible Work Arrangements:; Hybrid; Shift:; Valid Driving License:; Hazardous Material(s):; Required Skills:; Amazon Web Services (AWS), Audit Management, Business, Business Administration, Business Management, Business Process Improvements, Cloud Technology, Computer Science, Data Modeling, Governance Management, Informatics, Information Systems Strategy, Management Process, NoSQL, Python (Programming Language), Quality Assurance (QA), Social Collaboration, Software Testing, Software Testing Life Cycle (STLC), Stakeholder Relationship Management, Technical Writing Documentation, TIBCO Spotfire;  Preferred Skills:; Job Posting End Date:; 12\/31\/2025; *A job posting is effective until 11:59:59PM on the day BEFORE the listed job posting end date. Please ensure you apply to a job posting no later than the day BEFORE the job posting end date.; ; Requisition ID:R357652","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85054557","Role":"Data Engineer","Company":"Assurity Trusted Solutions Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85054557","job_desc":"Assurity Trusted Solutions (ATS) is a wholly owned subsidiary of the Government Technology Agency (GovTech). As a Trusted Partner over the last decade, ATS offers a comprehensive suite of products and services ranging from infrastructure and operational services, authentication services, governance and assurance services as well as managed processes. In a dynamic digital and cyber landscape, where trust & collaboration are key, ATS continues to drive mutually beneficial business outcomes through collaboration with GovTech, government agencies and commercial partners to mitigate cyber risks and bolster security postures.; We are seeking a Data Engineer to join our dynamic team to develop and strengthen our data ecosystem for the maritime sector. This role is pivotal in bridging the gap between business\/regulatory needs and our maritime data ecosystem, so that we enhance Singapore\u2019s position as a leading global maritime hub. The ideal candidate will leverage stakeholder insights and agile methodologies to develop data ecosystem products that will be relevant for a range of stakeholders in our maritime ecosystem, which would include our port operators, international shipping lines, technology companies, among others.; The maritime sector in Singapore faces significant challenges, as well as opportunities. It is critical for MPA to position Singapore to capture benefits from growing maritime trade, while addressing various challenges including our manpower constraints and global pressures for maritime decarbonisation. This position offers a unique opportunity to enhance Singapore\u2019s global positioning as a leading maritime hub by advancing new value proposition that can be unlocked via data for our maritime ecosystem.; Responsibilities:; Design, Develop, Test, Deploy and Maintain data pipelines (ETL) on the Enterprise Data Warehouse and Big Data Platform; Design and Develop the API \/Web Services framework for curation of new datasets whether internal or external (Internet), and to interface with other systems (both internal and external); Explore and source new data sets to address emerging business use case needs; Support stakeholder engagement, development, implementation and maintenance of systems for data collection, storage, access, and analytics at scale.; Develop and manage continuous improvement of data architecture and ensure alignment with business requirements, data management and governance policies.; Design, develop, and maintain interactive dashboards that provide insights and data to support business decision-making.; Support the design and definition of the data architecture framework, standards, and principles, including modelling, metadata, privacy, security, reference data and master data; Requirements; 3+ years of related work experience as a Data Engineer; Good grasp of Software Engineering principles such as Requirements Gathering (both functional and non-functional), Modular & Re-usable Design.; Proficient in ETL using programming language \/tools such as Python and\/or SSIS and\/or Informatica Power Centre; Able to develop data applications including integration with ICT systems, build APIs and web applications via .Java and\/or Python; Familiarity with MS SQL, PostgreSQL or Oracle is preferred.; Proficient in Data Modelling and Data Mining.; Experience in designing and building scalable database schema for applications.; Understanding of Object-Oriented Design.; Knowledge of or prior work experience on Big Data platforms such as Hadoop or using Spark.; Experience in the cloud environment setup; Excellent organizational, analytical, and problem-solving skills.; Experience collaborating with business and product teams.; Join us and discover a meaningful and exciting career with Assurity Trusted Solutions!; The remuneration package will commensurate with your qualifications and experience. Interested applicants, please click \"Apply Now\".; We thank you for your interest and please note that only shortlisted candidates will be notified.; By submitting your application, you agree that your personal data may be collected, used and disclosed by Assurity Trusted Solutions Pte. Ltd. (ATS), GovTech and their service providers and agents in accordance with ATS\u2019s privacy statement which can be found at: https:\/\/www.assurity.sg\/privacy.html or such other successor site.; Benefits; A wholly-owned subsidiary of GovTech.; We promote a learning culture and encourage you to grow and learn.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85608833","Role":"Senior Solution Architect \/ Solution Architect (Contract)","Company":"Monetary Authority of Singapore (MAS)","Location":"Central Region","Publish_Time":"2025-07-09 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85608833","job_desc":"You will be part of a dynamic team within Supervision Platforms Division under Information Technology Department. In this role, the officer is expected to undertake the following areas of work:; (i) Application Architecture; Design the system\u2019s application architecture based on requirements.; Manage non-functional requirements like scalability, reliability, and security.; Decompose monolithic applications into microservices.; Design services that can be independently deployed and scaled.; Design scalable UI components and architecture.; (ii) Data Architecture; Define Data model strategies (Structured vs semi-structured).; Define Data storage strategies (e.g., relational, NoSQL, GraphQL).; Ensure data consistency, security, and accessibility.; (iii) Security Architecture; Define security architecture for application based on system classification.; Design security controls, such as encryption, authentication, and authorization.; Ensure compliance with regulatory standards (e.g., IM8).; (iv) Stakeholder management; Work with business teams and product owners to ideate Solution Architecture and Design.; Coordinate and work with other technical teams (e.g. Infrastructure, Enterprise, Applications, Security) to set up infrastructure, CI\/CD pipelines, application integrations and resolve deployment and integration issue.; (v) Engineering and Operations; Design scalable and resilient infrastructure.; Support development teams by providing advice and guiding the engineers in solving technical problems, code review.; Improve software quality using cloud-native and Agile development practices such as TDD, automated CI\/CD.; Work with application teams to understand RCA for issues, incidents, provide interim and long term solution.; Define logging, tracing, and observability practices to quickly identify issues and bottlenecks.; (vi) Reusable components; Advocate and build reusable components and libraries to be shared across different application development teams.; Create and govern guidelines for design, coding, database and best practices.; You will be working in a fast-paced environment that would require the ability to manage multiple priorities and needs of stakeholders, as well as the agility to respond to changes and developments.; Requirements :; Bachelor Degree or Master Degree with minimally 8 years of relevant working experience in application development and design, and business analysis; Strong knowledge of solution architectures and integration patterns; Ability to design and develop large scale applications to solve complex business problems; Proficient in .Net, Java, React.js, Node.js, MYSQL and MongoDB; Familiar with multi-paradigm programming languages; Experience in software development lifecycle in an Agile Scrum context; Experience in OAuth2\/OpenID connect; Experience in containers, microservices and DevSecOps technologies; Familiar with cloud-native technology; Experience in designing and developing applications in AWS cloud environment; Certification on AWS cloud technology is preferred; Good understanding of SRE\/Service\/Security \/Compliance Management process including change, incident, problem on cloud platform; Good analytical skills, and able to multi-task and deliver results in a timely manner; Ability to resolve complex problems creatively; Self-driven, creative and team-oriented person with good interpersonal and organizational skills; As part of the shortlisting process for this role, you may be required to complete a medical declaration and\/or undergo further assessment.; This contract ends in Dec 2029. All applicants will be notified on whether they are shortlisted or not within 4 weeks of the closing date of this job posting.","salary":"","work_type":"Kontrak\/Temporer","country":"singapore"}
{"Job_ID":"83179323","Role":"VP, Data Management & Analytics, Data Management Office (DMO)","Company":"Sumitomo Mitsui Banking Corporation","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83179323","job_desc":"The Role; As VP of Data Management & Analytics, you will collaborate with various business units and our regional offices to support data initiatives, focusing on aligning data utilization with business objectives and championing the use of data analytics to facilitate strategic decision-making.  You will focus on understanding business requirements and use cases and identify opportunities to leverage data for enhanced business insights, enhance operational efficiencies and enable grow opportunities through the delivery of effective data solutions.  In addition, you will work closely with the business units to resolve data quality issues, improve data availability, usability and literacy to achieve the desired business outcomes.; Job Responsibilities; Engage stakeholders to identify and prioritise opportunities for data-driven improvements and efficiencies.; Drive the development and implementation of data analytics solutions to address specific business challenges.; Develop and conduct design workshops to collaboratively co-design use-centric solutions aligned to business goals.; Design and build intuitive dashboards to communicate actionable insights that can drive decision making.; Ensure data solutions adhere to data management and data governance policies and best practices.; Drive the adoption of BI and analytics tools and guiding on the integration of analytics into strategic planning and operational processes.; Collaborate with business units to define and specify data requirements for analytics projects.; Oversee the data pipelines for the central data HUB and working with IT to maintain the roadmap.; Advocate the use for Data HUB as our centralised governed data assets to support critical business reporting and analytics needs.; Identify data quality issues and working with cross functional teams to resolve the issues.; Improve data proficiency through hands-on support and training to ensure the users can leverage data effectively and drive continuous improvement.; Job Requirements; Bachelor\u2019s degree with min. 8 years of experience in Data Science, Data Analytics, Data Governance, Data Management or MIS\/Reporting.; Subject Matter Expertise along with extensive hands-on experience in driving the development and implementation of data analytics solutions specifically within banking and financial institutions. ; Strong business acumen along with advanced technical competencies and a track record in delivering strategic data analytics initiatives.; Proficient in BI tools such as QlikView, Tableau, Power BI etc with proven experience in developing interactive, effective and insight-driven management dashboards and business reports.; Strong Python\/R programming skills and expertise in developing machine learning models.; Experience in data management, data integration, data governance and ability to work across departments and business units\/functions effectively.; Experience in conducting data discovery, performing root cause analysis and making recommendations for data quality issues resolution.; Experience in managing metadata and master data management.; Strong knowledge of data management and data governance framework, UI\/UX principles and data analytics best practices.; Strong experience on data governance tool such as Collibra, Informatica, Alation etc will be an added advantage.; Excellent strategic thinking, analytical and problem-solving skills.; Effective communication, presentation and influencing skills.; Strong collaboration and project management skills.; Work location: One@ChangiCity.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84222715","Role":"Staff Cloud DevOps\/Kubernetes Engineer","Company":"Abbott Laboratories Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84222715","job_desc":"JOB DESCRIPTION:; Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritional and branded generic medicines. Our 114,000 colleagues serve people in more than 160 countries.;       The Opportunity; At Abbott, we believe people with diabetes should be empowered to enjoy healthy and happy lives. That\u2019s why we\u2019re focused on helping people with diabetes manage their health more effectively and comfortably, with life-changing products that provide accurate data to drive better-informed decisions. We\u2019re revolutionizing the way people monitor their glucose levels with our new sensing technology.; Interested in applying your wealth of technical knowledge and experience towards an opportunity in the medical field where you can improve the lives of people with diabetes? ; The candidate will be responsible for performing DevOps activities across multiple Cloud Service Providers in eleven global regions.  Candidate will establish configuration management, automate infrastructure, implement continuous integration, and apply DevOps best practices to achieve a continuously deployable system.  Candidate will support building scalable, highly available, efficient, and secure cloud infrastructure for a medical device SaaS. Candidate will work closely with Business, Software Engineers and Security Engineers to collaborate on a best-in-class healthcare platform for improving the lives of the hundreds of millions living with Diabetes. #software; What You'll Do; Provide engineering expertise to plan, analyze, design, test, and deploy secure, scalable, and highly available cloud infrastructure expressed as code.; Evaluation of new technology alternatives and implementation of new cloud-based initiatives, providing associated training as required; Employ exceptional problem-solving skills, with the ability to see and solve issues before they affect business productivity; Strive for continuous improvement and build continuous integration, continuous development, and constant deployment pipeline (CI\/CD Pipeline); Participate in all aspects of the software development life cycle for Cloud solutions, including planning, requirements, development, testing, and quality assurance collaboratively with Software Engineering; Work collaboratively with InfoSec to ensure that infrastructure is safe and secure against cybersecurity threats including adherence to Center for Internet Security (CIS) benchmarks.; Perform infrastructure cost analysis and optimization; Management of creation, release, and configuration of production systems. Optimize existing development and release processes through automation; ; Required Qualifications; Bachelor's Degree in Computer Science, Information Technology or other relevant technical fields.; Minimum 8 total years of experience; At least 2-4 years of experience building and maintaining AWS infrastructure (VPC, EC2, Security Groups, IAM, ECS, Code Deploy, CloudFront, S3) and creating highly automated environments with Infrastructure as Code (Ansible, Terraform, CloudFormation); Experience with container orchestration services (Kubernetes experience needed); Strong foundation of networking and Linux administration and experience with a variety of open-source technologies; Preferred Qualifications; Previous exposure to medical devices, biomedical or high technology industry.; Experience working in an agile environment.; The base pay for this position is; N\/A; In specific locations, the pay range may vary from the range posted.; JOB FAMILY:; Product DevelopmentDIVISION:; ADC Diabetes CareLOCATION:; Singapore > Singapore : DUO TowerADDITIONAL LOCATIONS:; WORK SHIFT:; StandardTRAVEL:; NoMEDICAL SURVEILLANCE:; NoSIGNIFICANT WORK ACTIVITIES:; Continuous sitting for prolonged periods (more than 2 consecutive hours in an 8 hour day)","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85627338","Role":"Junior Full Stack Developer \u2013 Cloud Based Learning","Company":"Adventus","Location":"North Region","Publish_Time":"2025-07-10 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85627338","job_desc":"Adventus Pte Ltd is an award-winning ICT solutions and services provider headquartered in Singapore. Renowned for our innovation, reliability, and enterprise-grade support across IT, cloud, and cybersecurity, we are now venturing into the development of cloud-based learning platforms as part of a new strategic initiative.; Key Responsibilities; Design, develop, and integrate both front-end and back-end components for a prototype cloud learning platform.; Build responsive user interfaces using HTML, CSS, JavaScript, and modern frameworks such as React or Vue.; Develop and maintain server-side logic, APIs, and data structures using Node.js, Python, or similar technologies.; Translate UI\/UX designs and wireframes into functional web features.; Ensure smooth user experiences through testing, debugging, and iterative refinement.; Collaborate with internal teams, stakeholders, and designers in an agile, feedback-driven development environment.; Deploy and manage applications in cloud or web-hosted environments.; Requirements; 1\u20132 years of hands-on experience in full stack development (including internships or freelance projects).; Proven experience in building and deploying at least one complete web-based application\u2014ideally within a learning or training context.; Proficient in HTML, CSS, JavaScript, and familiar with front-end frameworks like React, Vue, or Angular.; Skilled in back-end technologies such as Node.js, Python, or equivalent.; Exposure to or interest in cloud-based educational tools, learning platforms (LMS), or e-learning systems.; Strong problem-solving ability, attention to detail, and eagerness to learn.; Based in Singapore (Singaporeans or Permanent Resident only).; Fluent in English and Mandarin to effectively communicate with Mandarin-speaking clients; Good to Have; Experience with databases (SQL, MongoDB) and RESTful API development.; Familiarity with cloud platforms (AWS, Azure, Google Cloud).; Understanding of CI\/CD pipelines, version control (e.g., Git), and basic DevOps practices.; Knowledge of accessibility standards (e.g., WCAG), responsive design, or mobile-first development.; Awareness of learning technology standards such as SCORM, xAPI, or LTI.; Interest in UX design, digital learning trends, or instructional technology.","salary":"$4,800 \u2013 $7,000 per month (SGD)","work_type":"Full time","country":"singapore"}
{"Job_ID":"85146428","Role":"Senior Software Developer \/ Software Developer (Remote)","Company":"MLION CORPORATION PTE. LTD.","Location":"Singapore","Publish_Time":"2025-06-24 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85146428","job_desc":"Job Description; Design and develop high performance web applications; Collaborate with a team to define, design, and ship new features; Define web architectures and solutions from business requirements; Collaborate to provide estimates and timeline, and deliver the solution; Troubleshoot development and production problems across multiple environments and operating platforms; Ensure application performance, quality, and responsiveness; Provide advice, guidance, and coach junior team members; Job Requirement; Bachelor's degree in Computer Science or equivalent educational background; 4+ years of experience in software development; Strong proficiency in JavaScript, Node.js, and Express.js; Working knowledge of front-end technologies such as Flutter, Vue, or React, along with HTML5 and CSS3; Experience in developing RESTful APIs and microservices for web and mobile platforms (iOS\/Android); Familiarity with AWS cloud services; Experience with relational and NoSQL databases such as MySQL\/MariaDB and MongoDB; Proficient in Docker and containerizing applications; Hands-on experience with Git, CI\/CD pipelines, and tools like Ansible; Understanding of Agile development methodologies; Ability to work independently as well as collaboratively in a team environment; Strong communication skills for effective coordination with team members and end users; Experience with user authentication and authorization across multiple systems and environments; Ability to integrate multiple data sources and databases into unified systems; Familiarity with implementing unit tests, end-to-end tests, and integrating monitoring tools (e.g. Sentry, New Relic, AWS CloudWatch); Exposure to ERP, MRP, or CMS system development is a plus; Experience with PHP\/Laravel or Flutter application development is an advantage; Remote or On-site is both welcomed","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"80717636","Role":"Manager, Digital Transformation Office (Salesforce Engineer)","Company":"Public Service Division","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/80717636","job_desc":"The Digital Transformation Office (DTO) is a strategic division within the corporate group dedicated to driving and overseeing digital transformation initiatives across IMDA. The DTO plays a pivotal role in developing and implementing comprehensive strategies that align with IMDA\u2019s goals and objectives through the innovative use of emerging technology and data. By spearheading digital transformation initiatives, the DTO aims to revolutionize processes, elevate customer experiences, and foster a culture of innovation.; Through collaboration with various departments, the DTO ensures that digital initiatives are integrated seamlessly across the organization, positioning IMDA to be at the forefront in the digital age.; We are seeking experienced Salesforce Engineers, specializing in Enterprise Applications and CRM, to oversee and drive the successful implementation, management, and architectural integrity of our Salesforce platform.; Responsibilities; Design, develop, and customize Salesforce solutions, including custom objects, workflows, Apex triggers, Lightning components, and Visualforce pages.; Integrate Salesforce with other internal and external systems using REST\/SOAP APIs, middleware, and other integration tools.; Collaborate with stakeholders to gather business requirements, translate them into technical specifications, and implement solutions aligned with IMDA\u2019s business needs.; Ensure system performance, scalability, and availability by implementing best practices in architecture, development, and deployment.; Maintain data integrity and security by managing roles, permissions, and access controls within Salesforce.; Develop and execute unit tests and oversee quality assurance processes to ensure defect-free functionality.; Create and maintain technical documentation for systems and processes.; Troubleshoot and resolve issues across Salesforce environments, ensuring minimal downtime.; Stay updated with the latest Salesforce features, technologies, and industry trends, and identify opportunities to enhance Salesforce system; Requirements; Bachelor's degree in Computer Science, Engineering, or a related field, or equivalent experience.; 5+ years of experience in Salesforce development and administration.; Expertise in Apex, SOQL, SOSL, Lightning Web Components (LWC); Strong understanding of Salesforce platform capabilities, including Sales Cloud, Service Cloud, and Marketing Cloud.; Hands-on experience with Salesforce integration tools and APIs (REST, SOAP).; Solid knowledge of data modeling, workflows, validation rules, and automation tools like Flow.; Experience with DevOps tools and methodologies, including CI\/CD pipelines for Salesforce; Salesforce certifications (e.g., Platform Developer I\/II, Administrator, Architect).; Knowledge of Agile\/Scrum methodologies.; Familiarity with version control systems like Git.; #LI-IT2","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85015360","Role":"Site Reliability Engineer, Traffic Platform - Traffic SRE","Company":"BYTEDANCE PTE. LTD.","Location":"Singapore","Publish_Time":"2025-06-18 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85015360","job_desc":"Site Reliability Engineer, Traffic Platform - Traffic SRE; Singapore Regular R&D Job ID: A136692; Responsibilities; The Traffic Infrastructure Global Engineering (TIGE)-Traffic Platform team at ByteDance builds and operates multi-cloud based large scale network services around the world that we use to accelerate and optimize network traffic for Tiktok and a variety of application services for ByteDance internal customers, which include but are not limited to layer 4 loadbalancing, layer 4\/7 acceleration, global ingress, CMAF, FaaS and WAF, etc. By joining us, you can work within a brilliant team and learn how to build Tiktok scale network traffic platform which serves billions of users globally. Responsibilities; Design and develop features of traffic software (DNS Server, L4 and L7 Proxy, Web Caching, and FaaS Runtime), integrate based on our traffic platform to process terabyte-scale data in real-time.; Build data pipelines and develop telemetry systems to support datadriven traffic control.; Develop API acceleration and other networking services that run on top of our multi-cloud based traffic platform.; Problem solving and performance tuning for online traffic.; Research new technologies for more efficient and scalable traffic processing.; Qualifications; Minimum Qualifications; Experience in developing network systems in Rust, C, C++, and\/or; Go, developing skills in Linux environment.; Bachelor's degree in Computer Science, Electrical Engineering, Computer Engineering or related majors.; Familiarity with network protocols such as TCP\/IP, HTTP\/HTTPs, and DNS.; Familiarity with Microservice architecture.; Familiarity with container and orchestration technologies such as Docker and Kubernetes.; Preferred Qualifications; Experience in building large scale network services on cloud (AWS, GCP, OCI).; Experience in designing and developing high performance network loadbalancer products.; Experience in developing proxy software such as Nginx and Envoy is a big plus.; Experience in System Programming using low level system calls such as epoll, io-uring, etc., is a big plus.; Experience in developing Web Caching software such as Apache Traffic Server and Varnish, etc.; Experience in Edge Computing and FaaS Runtime development.; Experience in building distributed or cloud service based management system.; Proficiency in networking newer protocols such as HTTP2, HTTP3\/QUIC, TLS1.3, etc.; Job Information; Inspiring creativity is at the core of ByteDance's mission. Our innovative products are built to help people authentically express themselves, discover and connect \u2013 and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and enrich life - a mission we work towards every day.; As ByteDancers, we strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. By constantly iterating and fostering an \"Always Day 1\" mindset, we achieve meaningful breakthroughs for ourselves, our Company, and our users. When we create and grow together, the possibilities are limitless. Join us.; Diversity & Inclusion; ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Apply; Share to","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85817058","Role":"AWS Cloud Administrator","Company":"Cognizant Technology Solutions Asia Pacific Pte Ltd","Location":"Singapore","Publish_Time":"2025-07-16 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85817058","job_desc":"We are seeking a skilled AWS Cloud Administrator to join our team. The successful candidate will be responsible for managing client's cloud infrastructure and collaborating with their IT department to develop scalable applications. An AWS Cloud Administrator\u2019s responsibilities include management of cloud resources, maintenance of cloud applications, and implementation of cloud security measures. Our ideal candidate is familiar with the AWS Cloud ecosystem and has a working knowledge of cloud service architecture, deployment, and operations.; Key Responsibilities; Experienced in Tableau implementation, administration, and maintenance.; Platform infrastructure reliability and maintenance. (ALM\/TLM).; Application support (Covering data engineering pipelines, integrations, AMS L3).; Working administration knowledge of databases (Redshift clusters, MySQL, PostgreDB).; Working knowledge of MWAA, Control-M, Automation tools (Spydr), CICD, Kubernetes, Application Gateway, IAM.; Familiar with CloudX (e.g. policy controls, S3).; Familiar with ISRM related topics such as Platform security and access control.; Manage and monitor all installed AWS systems and infrastructure.; Configure, test, and maintain application software and system management tools.; Ensure the highest levels of systems and infrastructure availability.; Monitor and test application performance for potential bottlenecks, identify possible solutions, and work with developers to implement those fixes.; Maintain security, backup, and redundancy strategies.; Participate in the design of information and operational support systems.; Provide guidance and technical expertise on AWS infrastructure services.; Implement and control the flow of data to and from AWS.; Design, manage, and maintain tools to automate operational processes.; Monitor and manage billing and cost optimization strategies.; Ensure data integrity and access controls when using the AWS platform.; Implement continuous integration\/continuous delivery (CI\/CD) in AWS.; Identify potential issues and implement solutions when issues threaten to delay the project.; Document and design AWS architectures and convey this information to stakeholders.; Requirements; Experience with AWS services such as EC2, S3, RDS, VPC, IAM, CloudFormation, and CloudWatch.; Knowledge of automation and orchestration tools.; Excellent problem-solving skills and attention to detail.; Strong communication and collaboration skills.; Relevant AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified SysOps Administrator) are a plus.","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85163455","Role":"Microsoft Cloud (Azure), Data and Apps Business Development Director -...","Company":"SoftwareONE Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-25 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85163455","job_desc":"Why SoftwareOne?; Discover the heartbeat of SoftwareOne! Our 7 core values aren't just words \u2013 they're the beating heart of our company culture. Join us in a journey that unveils the essence of how we work, connect, and succeed. Watch the video to feel the values shaping our everyday interactions, customer relations, and team spirit.; Please note that SoftwareOne does not accept unsolicited resumes from recruiters or employment agencies. In the absence of a signed Services Agreement (Job-Specific per our global standard) with the agency\/recruiter, SoftwareOne will not consider or agree to payment of any referral compensation or recruiter fee.; ; The role; Our Hiring Leader:; Hi, My name is Alex Tay and I am the Business Development Director (Cloud, Apps and data) at SoftwareOne Southeast Asia.; \"We at SoftwareOne are looking for Sales Professionals that model a positive mindset and remain curious in all activities that they are involved in. Professionals that seek to maintain a joint-venture relationship with our customers, partners and internal support teams. Professionals who have a curious mindset and a hunger for knowledge for both our customers and our own business. Finally, they need to know how to have fun and recognise our customers' and team members' contributions.\"; Eager to meet our Dynamic leader? Feel free to check out his LinkedIn Profile:; A BDD (Individual Contributor) is a sales expert against customer problems\/ business needs. The BDD is responsible for accelerating time to value for our customers and supporting them in their cloud and digital transformation by aligning our solutions. Good technical understanding and the ability to transform our customers challenges into commercial solutions. The BDD identifies, develops, and lands opportunities for defined portfolio elements in cooperation with Account Management team. A highly motivated collaborator to hunt and win deals.; Key Responsibilities: Cloud (Azure), Data, Application and AI Services business growth in the Singapore.; Location : Singapore; Accountable for growing new Cloud (Azure), Data, Application and AI Services Opportunities along with Field Sales ensuring that the customers\u2019 needs are met or exceeded. Drive the entire Sales Cycle from initial Customer Engagement till Contract Closing for new & existing customers.; Establish relationships with new and existing customers and secure new business in the assigned portfolio element(s).; Work with Account Managers to ensure that the overall account strategy and goals are followed and achieved.; Maintain a very detailed level of relevant knowledge on the assigned portfolio element(s) in order to have meaningful and relevant conversations with customers and prospects; Work with Technical Architects \/ Practice Leaders to ensure that we design the right solutions for our customers.; Work with Partners, i.e. Microsoft, to grow the services around Microsoft technology.; Provide feedback to Account Management on ways to decrease the Sales Cycle, enhance Sales, and improve company brand and reputation.; Provide feedback to the service delivery team to ensure that the service delivered meets or overachieve the satisfaction level of the client.; Construct service contracts and associated commercials\/cost model based on scope and customer\u2019s desired outcome.; ; What we need to see from you; Existing Full-Time Work Rights in Singapore; Ability to commute to our Singapore office and visit clients in Singapore; Technical Qualifications:; 10+ years enterprise technology strategic sales\/pre-sales experience with a good knowledge on selling cloud and digital transformation solutions, specifically around Microsoft Azure.; Able to articulate use cases of cloud transformation specific to the customers industry and size and understand where the customer is on their journey.; Engage with stakeholders from IT all the way to C-level, understand the Customers business requirement & challenges, create an IT transformation roadmap covering (not limited to) Cloud, Data, Application and AI Services and position the right support model and articulate the business value of the offering.; Position Cloud. Data, Application and AI Services advisory and\/or professional services to customer depending on their requirements.; Understanding of the Microsoft Azure Cloud, Data, Application and AI Services technologies and Funding program, drive SoftwareOne services.; Have strategic sales\/pre-sales experience with a good knowledge on selling Data or Application transformation solutions, specifically around Microsoft Azure.; Have experience around selling professional services, managed services and consulting services and structuring go to market product services.; Functional understanding of key technologies and trends in the cloud domain, Application Modernization, Data & Analytics, containerization, cloud operating models, Cloud economics, Finops.; Experience preparing, presenting formal proposals to customers. Leading negotiations, coordinating complex decision-making process, and overcoming objections to closure.; Strong knowledge in public cloud market in Asia and strong understanding of cloud consumption economics.; Strong Knowledge on domain arounds Data and Application development using Microsoft technology.; Expertise in enterprise solution selling techniques and selling cloud-based solutions.; Effective territory\/account management and leading sales teams: planning, opportunity qualification and creation, stakeholder and executive communication, needs analysis, value engineering, services\/partner engagement, opportunity management and proposal response, pipeline management, large dollar licensing and deal negotiation required.; Experience and expertise selling to c-suite and executive business decision makers by aligning & reinforcing the value of Cloud transformation to the customer's overall business and\/or strategic opportunities and decision criteria.; Experience leading large cloud engagements, especially those involving infrastructure modernization and migration.; executive level speaking and presentation skills, and good written communication skills, exceptional demonstrated decision-making, conflict resolution, problem solving and negotiation skills.; Have a strong collaboration skill to engage internal and external.; ; Job Function; Sales","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"85177018","Role":"Senior Software Engineer - Traffic Infrastructure","Company":"BYTEDANCE PTE. LTD.","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/85177018","job_desc":"Senior Software Engineer - Traffic Infrastructure; Singapore Regular R&D Job ID: A38414; Responsibilities; ByteDance will be prioritizing applicants who have a current right to work in Singapore, and do not require ByteDance's sponsorship of a visa. ByteDance Founded in 2012, ByteDance's mission is to inspire creativity and enrich life. With a suite of more than a dozen products, including TikTok, Helo, and Resso, as well as platforms specific to the China market, including Toutiao, Douyin, and Xigua, ByteDance has made it easier and more fun for people to connect with, consume, and create content.; Why Join Us Creation is the core of ByteDance's purpose. Our products are built to help imaginations thrive.; This is doubly true of the teams that make our innovations possible. Together, we inspire creativity and enrich life - a mission we aim towards achieving every day. To us, every challenge, no matter how ambiguous, is an opportunity; to learn, to innovate, and to grow as one team.; Status quo? Never. Courage?; Always. At ByteDance, we create together and grow together. That's how we drive impact - for ourselves, our company, and the users we serve.; Join us. Traffic Infrastructure Global Engineering Team The Traffic Infrastructure Global Engineering (TIGE) team at ByteDance operates a large network of POPs around the world that we use to accelerate site traffic and cache CDN content, and we own all layer 4 and layer 7 traffic management for Tiktok Edge.; By joining us, you can learn how to build content delivery networks and Edge Computing Platform within Tiktok's Edge. To better support Tiktok, the TIGE team is seeking experienced software engineers who can help improve our Kubernetes based Cloud Native Traffic Platform. The traffic platform balances, manages and processes Tiktok application traffic across all Tiktok's edge clusters.; Also, the traffic platform contains varied network services in order to orchestrate the delivery of bits from our servers to your phone. Responsibilities; Design and develop features of traffic software (DNS Server, L4 and L7 Proxy, Web Caching, and FaaS Runtime), integrate based on our traffic platform to process terabyte-scale data in real-time; Build data pipeline and develop telemetry systems to support datadriven traffic control; Develop API acceleration and other networking services that run on top of our traffic platform; Problem solving and performance tuning for online traffic; Research new technologies for more efficient and scalable traffic processing; Qualifications; Minimum Qualifications:; 3+ years experience in developing network systems in Rust, C, C++, and\/or; Go, strong developing skills in Linux environment.; Master\u2019s degree (or Bachelor's degree with addtional 2+ years of experience) in Computer Science, Electrical Engineering, Computer Engineering or related majors.; Familiarity with network protocols such as TCP\/IP, HTTP, and DNS.; Familiarity with Microservice architecture.; Familiarity with container and orchestration technologies such as Docker and Kubernetes; Strong understanding of software deployment fundamentals and automation.; Good understanding of concepts in operating system, remote process communication, high availability etc.; Preferred Qualifications:; Experience in System Programming using low level system calls such as epoll, io-uring, etc., is a big plus.; Experience in developing HTTP proxy such as Nginx and Envoy is a big plus.; Experience in developing Web Caching software such as Apache Traffic Server and Varnish, etc.; Experience in Edge Computing and FaaS Runtime development.; Experience in building distributed or cloud service based management system; Proficiency in networking newer protocols such as HTTP2, HTTP3\/QUIC, TLS1.3, etc.; ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.; Apply; Share to","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"83926166","Role":"Senior Engineer, Plan and Spec - Data Center HVAC","Company":"Carrier Singapore (Pte) Limited","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/83926166","job_desc":"Job ID 30180435 Job Category Sales; Country:; Singapore; Location:; #08-01\/02, Perennial Business City, 1 Venture Avenue, Singapore 608521; Position Overview:; We are seeking an experienced Senior Engineer, Plan and Spec to collaborate closely with data center design consultants and developers in the region. The ideal candidate will have a strong understanding of HVAC needs and will be responsible for creating technical and budgetary proposals as well as conducting life cycle analysis. This role involves establishing and developing relationships with data center HVAC consulting firms while implementing plan and specification strategies tailored to promote our solutions.; Key Responsibilities:; - Develop and maintain strong relationships with data center design consultants and owners.; - Understand and analyze HVAC requirements to create compelling technical and budgetary proposals.; - Conduct life cycle analysis to ensure the long-term efficiency and effectiveness of proposed solutions.; - Regularly track and update the pipeline of prospective projects and implement strategic plan and spec initiatives.; - Promote and pitch Carrier products and solutions to HVAC consulting firms and data center owners.; - Coordinate across regions and work closely with cross-functional teams including factory, engineering, and data center core business leaders.; - Provide regular updates to the Data Center core team on plan and spec activities and maintain accurate records of the pipeline.; Desired Attributes:; - Strategic thinker with the ability to develop and implement effective HVAC solutions for data centers.; - Proactive approach to tracking industry trends and integrating them into strategic proposals.; - Strong problem-solving skills and the ability to manage multiple projects simultaneously.; - Outgoing personality with a thirst to network.; Minimum Qualifications:; - Strong knowledge and expertise in HVAC systems with an emphasis on data center applications.; - 5 to 10 years of experience in engaging with consultants in the HVAC field and data center industry.; - Proficient understanding of applicable HVAC and Data Center codes and standards.; - Demonstrated ability to work effectively with diverse teams across various regions.; - Excellent presentation, communication and interpersonal skills to foster strong relationships with stakeholders.; Carrier is An Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.; Job Applicant's Privacy Notice:; Click on this link to read the Job Applicant's Privacy Notice","salary":"","work_type":"Full time","country":"singapore"}
{"Job_ID":"84918415","Role":"Cloud Infrastructure Engineer (Compute)","Company":"Assurity Trusted Solutions Pte Ltd","Location":"Singapore","Publish_Time":"2025-06-17 17:03:39","URL":"https:\/\/id.jobstreet.com\/id\/job\/84918415","job_desc":"Assurity Trusted Solutions (ATS) is a wholly owned subsidiary of the Government Technology Agency (GovTech). As a Trusted Partner over the last decade, ATS offers a comprehensive suite of products and services ranging from infrastructure and operational services, authentication services, governance and assurance services as well as managed processes. In a dynamic digital and cyber landscape, where trust & collaboration are key, ATS continues to drive mutually beneficial business outcomes through collaboration with GovTech, government agencies and commercial partners to mitigate cyber risks and bolster security postures.; We are seeking for Cloud Infrastructure Engineer to join our team to manage and operate hybrid cloud infrastructure for Whole of Government digital services. This role involves managing hyperconverged infrastructure, physical servers, backup services and implementing cloud solutions across multiple Cloud Service Providers (Azure, AWS).; Responsibilities:; Design, mplement and maintain the infrastructure solutions across on-premises and cloud platforms (Azure, AWS), ensuring optimal performance and reliability for Whole of Government digital services; Serve as technical subject matter expert for compute, storage, backup and virtualization technologies, providing architectural guidance and best practices for infrastructure solutions; Develop and maintain Infrastructure as Code (IaC) using tools such as Terraform, CloudFormation and Azure Resource Manager templates as well as implementing robust CI\/CD pipelines for infrastructure deployment; Lead the implementation of security controls and resource optimisation across Windows Server and Linux environments, ensuring compliance with government technology standards and policies; Provide technical leadership in troubleshooting complex infrastructure issues and collaborate with development teams, stakeholders and vendors; Create and maintain comprehensive technical documentation including architecture diagrams, operational procedures and disaster recovery plans; Participate in on-call rotation to provide critical infrastructure support and ensure service reliability; Requirements; Possess knowledge or experience in Computer Science, Information Technology, Electronics Engineering or related field; 3-5 years of relevant experience in infrastructure operations and engineering, demonstrating strong expertise in virtualisation platform (VMware\/Nutanix) and enterprise backup solutions; Practical experience with Clouds platform such as Azure and AWS, supported by relevant certifications; Proficiency in Infrastructure as Code tools (Terraform, CloudFormation, ARM templates) and configuration management tools (Ansible, Chef Infra); Strong problem-solving and analytical skills; Excellent communication skills and ability to work with diverse stakeholders; Experience in public sector projects and understanding of government security compliance frameworks is a plus; Candidates without direct experience but with relevant certification are also welcome to apply; Join us and discover a meaningful and exciting career with Assurity Trusted Solutions!; The remuneration package will commensurate with your qualifications and experience. Interested applicants, please click \"Apply Now\".; We thank you for your interest and please note that only shortlisted candidates will be notified.; By submitting your application, you agree that your personal data may be collected, used and disclosed by Assurity Trusted Solutions Pte. Ltd. (ATS), GovTech and their service providers and agents in accordance with ATS\u2019s privacy statement which can be found at: https:\/\/www.assurity.sg\/privacy.html or such other successor site.; Benefits; A wholly-owned subsidiary of GovTech.; We promote a learning culture and encourage you to grow and learn.","salary":"","work_type":"Full time","country":"singapore"}
